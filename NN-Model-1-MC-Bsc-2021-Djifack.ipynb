{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bachelorarbait-2021\n",
    "# Author: Michel Bosris Djifack\n",
    "# Matrikelnummer:7103963"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A sentiment analysis program will be designed to make predictions about the english written expressions to rank them and \n",
    "# determine which ones are in favor of the coronavirus vaccine and which are against.\n",
    "# Method: NN (Neural Network)\n",
    "\n",
    "# ===> three classes (Multiclass) with NN\n",
    "\n",
    "\n",
    "# NN-Prototype-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m------------------- All libraries have been successfully imported.------------------- \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "import all libraries (Math-function, diagram-visualisation, regex, document and NLP functions)\n",
    "\n",
    "\"\"\"\n",
    "# NLP Libraries\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, LSTM, Embedding, Dropout, Activation, BatchNormalization,Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "\n",
    "# Math, documents and visualisation Libraries\n",
    "import numpy as np\n",
    "import preprocessor as p\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import colorama\n",
    "from colorama import Fore\n",
    "\n",
    "print(f\"{Fore.MAGENTA}------------------- All libraries have been successfully imported.------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m------------------- The document has been successfully uploaded. ------------------- \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "upload The dataset, open it and check it.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# upload the DataSet\n",
    "file = open('covidVaccineAdvice_mldata_d1.csv',encoding=\"utf-8\")\n",
    "data = pd.read_csv(file,delimiter=\";\")\n",
    "print(f\"{Fore.MAGENTA}------------------- The document has been successfully uploaded. ------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m -------------------  overview of the dataset ------------------- \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>We need to be vaccinated to protect all person...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>it is a pleasure to see how the govement are w...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>The most popular vaccine that i know is Modern...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Of course we need to be vaccinated if we want ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            message sentiment\n",
       "0   1  We need to be vaccinated to protect all person...  Positive\n",
       "1   2  it is a pleasure to see how the govement are w...  Positive\n",
       "2   3                                          Negative   Negative\n",
       "3   4  The most popular vaccine that i know is Modern...  Positive\n",
       "4   5  Of course we need to be vaccinated if we want ...  Positive"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the document header.\n",
    "print(f\"{Fore.MAGENTA} -------------------  overview of the dataset ------------------- \")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m -------------------  The document has 1023 rows and 3 columns ------------------- \n"
     ]
    }
   ],
   "source": [
    "#count the data set\n",
    "print(f\"{Fore.MAGENTA} -------------------  The document has\", data.shape[0], \"rows and\", data.shape[1],\"columns ------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m------------------- the number and percentage of missing values in the data set. ------------------- \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>message</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count  Percentage\n",
       "id             0         0.0\n",
       "message        0         0.0\n",
       "sentiment      0         0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check missing values\n",
    "count =data.isnull().sum().sort_values(ascending=False)\n",
    "percentage =((data.isnull().sum()/len(data)*100)).sort_values(ascending=False)\n",
    "missing_data =pd.concat([count,percentage],axis=1,keys=['count','Percentage'])\n",
    "\n",
    "print(f\"{Fore.MAGENTA}------------------- the number and percentage of missing values in the data set. ------------------- \")\n",
    "missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#check the Distributin of Sentiments\n",
    "category = ['Negative','Neutral','Positive']\n",
    "values = [data.sentiment.str.count(\"Negative\").sum(),data.sentiment.str.count(\"Neutral\").sum(),data.sentiment.str.count(\"Positive\").sum()]\n",
    "plt.pie(values, labels= category,autopct ='%0.2f%%')\n",
    "plt.title('------------------- percentage Distribution by Sentiment Category -------------------',fontsize=20,color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m------------------- Special characters and punctuation cleaning operations completed. ------------------- \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "We will now clean the data by removing the special characters.\n",
    "\n",
    "\"\"\"\n",
    "#set up punctuations we want to be replaced\n",
    "REPLACE_NO_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\')|(\\?)|(\\,)|(\\\")|(\\|)|(\\()|(\\))|(\\[)|(\\])|(\\%)|(\\$)|(\\>)|(\\<)|(\\{)|(\\})|(\\=)|(\\#)|(\\ยง)\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s/><br\\s/?)|(-)|(/)|(:).\")\n",
    "print(f\"{Fore.BLUE}------------------- Special characters and punctuation cleaning operations completed. ------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m------------------- preparation of the cleaning functions completed. ------------------- \n"
     ]
    }
   ],
   "source": [
    "# custum function to clean the dataset (combining tweet_preprocessor and reguar expression)\n",
    "def clean_tweets(df):\n",
    "  tempArr = []\n",
    "  for line in df:\n",
    "    # send to tweet_processor\n",
    "    tmpL = p.clean(line)\n",
    "    # remove puctuation\n",
    "    tmpL = REPLACE_NO_SPACE.sub(\"\", tmpL.lower()) # convert all tweets to lower cases\n",
    "    tmpL = REPLACE_WITH_SPACE.sub(\" \", tmpL)\n",
    "    tempArr.append(tmpL)\n",
    "  return tempArr\n",
    "\n",
    "print(f\"{Fore.BLUE}------------------- preparation of the cleaning functions completed. ------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m------------------- The message cleaning operation is complete. ------------------- \n"
     ]
    }
   ],
   "source": [
    "# Cleaning up tweets\n",
    "clean_tweet = clean_tweets(data[\"message\"])\n",
    "print(f\"{Fore.BLUE}------------------- The message cleaning operation is complete. ------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m------------------- The clean data column has been successfully added to the dataset. ------------------- \n"
     ]
    }
   ],
   "source": [
    "# append cleaned tweets to the training data\n",
    "clean_tweet = pd.DataFrame(clean_tweet)\n",
    "data[\"clean\"] = clean_tweet\n",
    "print(f\"{Fore.BLUE}------------------- The clean data column has been successfully added to the dataset. ------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m------------------- overview of the dataset with the clean_data column. ------------------- \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>We need to be vaccinated to protect all person...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>we need to be vaccinated to protect all person...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>it is a pleasure to see how the govement are w...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>it is a pleasure to see how the govement are w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>The most popular vaccine that i know is Modern...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>the most popular vaccine that i know is modern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Of course we need to be vaccinated if we want ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>of course we need to be vaccinated if we want ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            message sentiment  \\\n",
       "0   1  We need to be vaccinated to protect all person...  Positive   \n",
       "1   2  it is a pleasure to see how the govement are w...  Positive   \n",
       "2   3                                          Negative   Negative   \n",
       "3   4  The most popular vaccine that i know is Modern...  Positive   \n",
       "4   5  Of course we need to be vaccinated if we want ...  Positive   \n",
       "\n",
       "                                               clean  \n",
       "0  we need to be vaccinated to protect all person...  \n",
       "1  it is a pleasure to see how the govement are w...  \n",
       "2                                           negative  \n",
       "3  the most popular vaccine that i know is modern...  \n",
       "4  of course we need to be vaccinated if we want ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare the cleaned and uncleaned tweets\n",
    "print(f\"{Fore.BLUE}------------------- overview of the dataset with the clean_data column. ------------------- \")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function who help to count unique words\n",
    "\n",
    "def wordCount(text):\n",
    "    count = Counter()\n",
    "    for i in text.values:\n",
    "        for word in i.split():\n",
    "            count[word]+=1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m------------------- The column 'clean' contains:  2540  unique words ------------------- \n"
     ]
    }
   ],
   "source": [
    "# count the number of unique words contained in the set of cleaned expressions. \n",
    "text= data.clean\n",
    "counter = wordCount(text)\n",
    "print(f\"{Fore.BLUE}------------------- The column 'clean' contains: \",len(counter),\" unique words ------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive [0 0 1]\n",
      "Positive [0 0 1]\n",
      "Negative [1 0 0]\n",
      "Positive [0 0 1]\n",
      "Positive [0 0 1]\n",
      "Neutral [0 1 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert sentiment into numeric value\n",
    "y = pd.get_dummies(data['sentiment']).values\n",
    "[print(data['sentiment'][i], y[i]) for i in range(0,6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m------------------- The data was successfully split. ------------------- \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "In this section, we will divide the file (the 'clean' column) \n",
    "into two parts: one part for training and one part for testing.\n",
    "\n",
    "X_train ==> train_sentences\n",
    "X_test ==> test_sentences\n",
    "y_train ==> train_labels\n",
    "y_test ==> test_labels\n",
    "\n",
    "\"\"\"\n",
    "X = data['clean']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "print(f\"{Fore.GREEN}------------------- The data was successfully split. ------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m------------------- Operations completed. ------------------- \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "We will now define the maximum length of a sentence in terms of the number of words it can contain.\n",
    "But first, we define the word count as the number of unique words.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# define the number of words.\n",
    "num_words = len(counter)\n",
    "# maximum number of words in a sentence.\n",
    "max_length = 42\n",
    "print(f\"{Fore.GREEN}------------------- Operations completed. ------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m------------------- tokenization process complete. ------------------- \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "We will now tokenize the text ('clean' column):\n",
    "This means that a unique number is associated with each unique word in the text.\n",
    "\"\"\"\n",
    "\n",
    "tokenizer = Tokenizer(num_words=num_words, split=\" \")\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "print(f\"{Fore.GREEN}------------------- tokenization process complete. ------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m------------------- visualization of the result obtained after tokenization. ------------------- \n",
      "\u001b[30m {'the': 1, 'to': 2, 'i': 3, 'vaccine': 4, 'is': 5, 'not': 6, 'and': 7, 'of': 8, 'a': 9, 'it': 10, 'vaccinated': 11, 'in': 12, 'for': 13, 'covid': 14, 'are': 15, 'vaccines': 16, 'be': 17, 'that': 18, 'this': 19, 'get': 20, 'will': 21, 'do': 22, 'my': 23, 'have': 24, 'am': 25, 'so': 26, 'we': 27, 'you': 28, 'with': 29, 'no': 30, 'as': 31, 'all': 32, 'people': 33, '19': 34, 'us': 35, 'but': 36, 'they': 37, 'at': 38, 'me': 39, 'on': 40, 'if': 41, 'first': 42, 'or': 43, 'pfizer': 44, 'vaccination': 45, 'who': 46, 'want': 47, 'good': 48, 'effects': 49, 'take': 50, 'can': 51, 'about': 52, 'think': 53, 'more': 54, 'side': 55, 'against': 56, 'has': 57, 'these': 58, 'there': 59, 'was': 60, 'because': 61, 'dose': 62, 'should': 63, 'by': 64, 'our': 65, 'why': 66, 'been': 67, 'virus': 68, 'today': 69, 'just': 70, 'like': 71, 'doses': 72, 'getting': 73, 'their': 74, 'when': 75, 'everyone': 76, 'after': 77, 'very': 78, 'any': 79, 'from': 80, 'now': 81, 'does': 82, 'one': 83, 'go': 84, 'than': 85, 'what': 86, 'your': 87, 'an': 88, 'would': 89, 'going': 90, 'still': 91, 'got': 92, 'make': 93, 'let': 94, 'lives': 95, 'without': 96, 'those': 97, 'many': 98, 'know': 99, 'free': 100, 'only': 101, 'how': 102, 'need': 103, 'coronavirus': 104, 'never': 105, 'two': 106, 'world': 107, 'some': 108, 'had': 109, 'stop': 110, 'life': 111, 'received': 112, 'well': 113, 'even': 114, 'up': 115, 'health': 116, 'time': 117, 'trust': 118, 'other': 119, 'did': 120, 'them': 121, 'out': 122, 'wait': 123, 'save': 124, 'being': 125, 'thing': 126, 'see': 127, 'companies': 128, 'risk': 129, 'really': 130, 'effective': 131, 'biontech': 132, 'thank': 133, 'much': 134, 'day': 135, 'disease': 136, 'also': 137, 'were': 138, 'injection': 139, 'enough': 140, 'case': 141, 'cannot': 142, 'years': 143, 'most': 144, 'believe': 145, 'protect': 146, 'nothing': 147, 'vaccinate': 148, 'important': 149, 'receive': 150, 'prices': 151, 'its': 152, 'children': 153, 'done': 154, 'yes': 155, 'say': 156, 'thanks': 157, 'pandemic': 158, 'way': 159, 'bad': 160, 'soon': 161, 'end': 162, 'moderna': 163, 'sure': 164, 'corona': 165, 'money': 166, 'new': 167, 'again': 168, 'which': 169, 'afraid': 170, 'long': 171, 'others': 172, 'safe': 173, 'choice': 174, 'happy': 175, 'caign': 176, 'since': 177, 'use': 178, 'live': 179, 'allergic': 180, 'far': 181, 'then': 182, 'prevent': 183, 'please': 184, 'great': 185, 'year': 186, 'yet': 187, 'care': 188, 'whether': 189, 'second': 190, 'better': 191, 'real': 192, 'pharmaceutical': 193, 'covid19': 194, 'must': 195, 'science': 196, 'vaccinations': 197, 'laboratories': 198, 'ones': 199, 'consequences': 200, 'find': 201, 'family': 202, 'useful': 203, 'too': 204, 'best': 205, 'anyone': 206, 'problem': 207, 'person': 208, 'necessary': 209, 'news': 210, 'severe': 211, 'myself': 212, 'already': 213, 'shot': 214, 'before': 215, 'finally': 216, 'point': 217, 'population': 218, 'able': 219, 'big': 220, 'said': 221, 'taking': 222, 'young': 223, 'less': 224, 'possible': 225, 'here': 226, 'million': 227, 'days': 228, 'immunity': 229, 'serious': 230, 'reactions': 231, 'country': 232, 'g': 233, 'safety': 234, 'maybe': 235, 'last': 236, 'right': 237, 'made': 238, 'into': 239, 'cure': 240, 'order': 241, 'decision': 242, 'feeling': 243, 'future': 244, 'remain': 245, 'excited': 246, 'st': 247, 'old': 248, 'makes': 249, 'propaganda': 250, 'reaction': 251, 'taken': 252, 'same': 253, 'astrazeneca': 254, 'could': 255, 'course': 256, 'given': 257, 'scientists': 258, 'least': 259, 'africa': 260, 'give': 261, 'hope': 262, 'encourage': 263, 'developed': 264, 'question': 265, 'solution': 266, 'approved': 267, 'work': 268, 'available': 269, 'negative': 270, 'week': 271, 'public': 272, 'turn': 273, 'danger': 274, 'media': 275, 'normal': 276, 'tests': 277, 'both': 278, 'drug': 279, 'emergency': 280, 'effectiveness': 281, 'always': 282, 'back': 283, 'frankly': 284, 'yourself': 285, 'cases': 286, 'almost': 287, 'fed': 288, 'variant': 289, 'fear': 290, 'rather': 291, 'deaths': 292, 'come': 293, 'down': 294, 'die': 295, 'supermarket': 296, 'charge': 297, 'he': 298, 'own': 299, 'part': 300, 'hours': 301, 'injected': 302, 'supply': 303, 'millions': 304, 'according': 305, 'until': 306, 'arrived': 307, 'term': 308, 'weeks': 309, 'data': 310, 'information': 311, 'administered': 312, 'risks': 313, 'reduce': 314, 'his': 315, 'months': 316, 'put': 317, 'five': 318, 'respect': 319, 'ive': 320, 'government': 321, 'anti': 322, 'natural': 323, 'clear': 324, 'food': 325, 'stock': 326, 'mind': 327, 'personally': 328, 'lot': 329, 'fine': 330, 'idea': 331, 'immune': 332, 'system': 333, 'avoid': 334, 'form': 335, 'exle': 336, 'seen': 337, 'between': 338, 'kind': 339, 'another': 340, 'grateful': 341, 'set': 342, 'wonder': 343, 'matter': 344, 'yesterday': 345, 'interested': 346, 'off': 347, 'doctors': 348, 'around': 349, 'countries': 350, 'shows': 351, 'share': 352, 'alone': 353, 'authorities': 354, 'patients': 355, 'adverse': 356, 'explain': 357, 'gates': 358, 'might': 359, 'conspiracy': 360, 'thats': 361, 'offering': 362, 'next': 363, 'residents': 364, 'test': 365, 'making': 366, 'night': 367, 'employees': 368, 'programme': 369, 'positive': 370, 'working': 371, 'look': 372, 'every': 373, 'mean': 374, 'rollout': 375, 'loved': 376, 'social': 377, 'reason': 378, 'panic': 379, 'tell': 380, 'including': 381, 'follow': 382, 'mrna': 383, 'morning': 384, 'lie': 385, 'fact': 386, 'administering': 387, 'contagious': 388, 'fake': 389, 'testing': 390, 'favour': 391, 'travel': 392, 'approves': 393, 'few': 394, 'company': 395, 'opinion': 396, 'using': 397, 'change': 398, 'ever': 399, 'price': 400, 'cost': 401, 'everything': 402, 'story': 403, 'developing': 404, 'healthcare': 405, 'im': 406, 'help': 407, 'infected': 408, 'likely': 409, 'took': 410, 'humanity': 411, 'prefer': 412, 'third': 413, 'longer': 414, 'feel': 415, 'home': 416, 'works': 417, 'opportunity': 418, 'friends': 419, 'quickly': 420, 'hospital': 421, 'arrive': 422, 'hospitals': 423, 'refuse': 424, 'themselves': 425, 'consumer': 426, 'human': 427, 't': 428, 'while': 429, 'gives': 430, 'mass': 431, 'confinement': 432, 'thinking': 433, 'ourselves': 434, 'dying': 435, 'research': 436, 'anyway': 437, 'doubt': 438, 'vaccin': 439, 'present': 440, 'protein': 441, 'ready': 442, 'global': 443, 'self': 444, 'kiss': 445, 'lose': 446, 'doing': 447, 'business': 448, 'barrier': 449, 'gestures': 450, 'pfizers': 451, 'receiving': 452, 'stand': 453, 'taxpayers': 454, 'drugs': 455, 'continue': 456, 'politicians': 457, 'approve': 458, 'ahead': 459, 'americans': 460, 'him': 461, 'bill': 462, 'evil': 463, 'rich': 464, 'nice': 465, 'realy': 466, 'causing': 467, 'biontechs': 468, 'rights': 469, 'imagine': 470, 'announced': 471, 'freedom': 472, 'conditions': 473, 'otherwise': 474, 'advised': 475, 'fda': 476, 'mask': 477, 'quality': 478, 'hesitate': 479, 'ridiculous': 480, 'sick': 481, 'authorized': 482, 'access': 483, 'means': 484, 'raise': 485, 'private': 486, 'goes': 487, 'authorizes': 488, 'gov': 489, 'via': 490, 'each': 491, 'usa': 492, 'wear': 493, 'naturally': 494, 'therefore': 495, 'tested': 496, 'update': 497, 'vaccinating': 498, 'products': 499, 'helps': 500, 'difficult': 501, 'where': 502, 'spread': 503, 'especially': 504, 'treatment': 505, 'injections': 506, 'rid': 507, 'waiting': 508, 'easier': 509, 'contamination': 510, 'community': 511, 'state': 512, 'nurse': 513, 'she': 514, 'cancer': 515, 'fight': 516, 'word': 517, 'diseases': 518, 'allow': 519, 'concern': 520, 'workers': 521, 'view': 522, 'start': 523, 'show': 524, 'rate': 525, 'death': 526, 'develop': 527, 'create': 528, 'number': 529, 'possibility': 530, 'reliable': 531, 'trials': 532, 'gets': 533, 'cause': 534, 'actually': 535, 'etc': 536, 'herd': 537, 'ago': 538, 'contribute': 539, 'through': 540, 'guinea': 541, 'compulsory': 542, 'stay': 543, 'rna': 544, 'control': 545, 'scientific': 546, 'fighting': 547, 'type': 548, 'keep': 549, 'lets': 550, 'over': 551, 'difference': 552, 'decide': 553, 'hesitation': 554, 'breaking': 555, 'begin': 556, 'latest': 557, 'something': 558, 'happened': 559, 'three': 560, 'affraid': 561, 'strong': 562, 'told': 563, 'bullshit': 564, 'allowed': 565, 'capitalism': 566, 'joe': 567, 'biden': 568, 'false': 569, 'problems': 570, 'technology': 571, 'beginning': 572, 'someone': 573, 'stable': 574, 'away': 575, 'true': 576, 'says': 577, 'body': 578, 'produce': 579, 'spike': 580, 'experimental': 581, 'month': 582, 'her': 583, 'bosses': 584, 'six': 585, 'certainly': 586, 'needs': 587, 'worried': 588, 'despite': 589, 'leave': 590, 'industry': 591, 'situation': 592, 'during': 593, 'variants': 594, 'governments': 595, 'majority': 596, 'citizen': 597, 'may': 598, 'little': 599, 'ingredients': 600, 'angry': 601, 'advise': 602, 'mother': 603, 'coming': 604, 'china': 605, 'pharma': 606, 'called': 607, 'room': 608, 'christmas': 609, 'harmful': 610, 'scams': 611, 'useless': 612, 'roll': 613, 'preserve': 614, 'such': 615, 'moment': 616, 'happening': 617, 'indeed': 618, 'whats': 619, 'batch': 620, 'allergy': 621, 'special': 622, 'moderne': 623, 'happens': 624, 'dubai': 625, 'autoimmune': 626, 'peace': 627, 'kits': 628, 'face': 629, 'sent': 630, 'united': 631, 'adapt': 632, 'grocery': 633, 'god': 634, 'power': 635, 'light': 636, 'tunnel': 637, 'knows': 638, 'run': 639, 'theres': 640, 'proven': 641, 'tired': 642, 'profit': 643, 'market': 644, 'shape': 645, 'understand': 646, 'try': 647, 'forever': 648, 'thankful': 649, 'producing': 650, 'arm': 651, 'speed': 652, 'started': 653, 'read': 654, 'agree': 655, 'press': 656, 'specialy': 657, 'begins': 658, 'favor': 659, 'none': 660, 'scammers': 661, 'gene': 662, 'therapy': 663, 'adolescents': 664, 'common': 665, 'affected': 666, 'frightening': 667, 'local': 668, 'seems': 669, 'warning': 670, 'careful': 671, 'senior': 672, 'fast': 673, 'european': 674, 'program': 675, 'socially': 676, 'staff': 677, 'contact': 678, 'probably': 679, 'definitely': 680, 'sell': 681, 'proud': 682, 'except': 683, 'ways': 684, 'parents': 685, 'empty': 686, 'biggest': 687, 'things': 688, 'quite': 689, 'antibodies': 690, 'advice': 691, 'hot': 692, 'water': 693, 'prevention': 694, 'rest': 695, 'calling': 696, 'toll': 697, 'currently': 698, 'region': 699, 'prevents': 700, 'hospitalized': 701, 'afterwards': 702, 'worse': 703, 'wouldnt': 704, 'sudden': 705, 'hand': 706, 'sanitizer': 707, 'bacterial': 708, 'resistant': 709, 'leading': 710, 'treated': 711, 'increasing': 712, 'older': 713, 'canada': 714, 'sunday': 715, 'saved': 716, 'hell': 717, 'wont': 718, 'cant': 719, 'traditional': 720, 'african': 721, 'medicines': 722, 'lockdown': 723, 'lucky': 724, 'pigs': 725, 'decided': 726, 'wish': 727, 'london': 728, 'certainty': 729, 'protects': 730, 'reliability': 731, 'experts': 732, 'beautiful': 733, 'summary': 734, 'sufficiently': 735, 'measures': 736, 'awareness': 737, 'whole': 738, 'wiser': 739, 'convinced': 740, 'controlled': 741, 'hands': 742, 'assume': 743, 'trump': 744, 'administration': 745, 'scare': 746, 'pseudo': 747, 'transmitting': 748, 'johnson': 749, 'medical': 750, 'history': 751, 'obligation': 752, 'pity': 753, 'women': 754, 'direct': 755, 'production': 756, 'russia': 757, 'russian': 758, 'saturated': 759, 'putting': 760, 'peoples': 761, 'lost': 762, 'mandatory': 763, 'delta': 764, 'used': 765, 'hear': 766, 'honest': 767, 'unnecessary': 768, 'plants': 769, 'confidence': 770, 'nonsense': 771, 'ok': 772, 'scary': 773, 'comes': 774, 'refused': 775, 'offered': 776, 'worst': 777, 'personal': 778, 'tetanus': 779, 'interesting': 780, 'invented': 781, 'caught': 782, 'epidemic': 783, 'protected': 784, 'everybody': 785, 'dangerous': 786, 'found': 787, 'rodents': 788, 'tells': 789, 'site': 790, 'low': 791, 'harm': 792, 'legacy': 793, 'registered': 794, 'inject': 795, 'response': 796, 'tomorrow': 797, 'together': 798, 'consent': 799, 'inspire': 800, 'thermally': 801, 'flexible': 802, 'broken': 803, 'jennifer': 804, 'haller': 805, 'known': 806, 'holiday': 807, 'passport': 808, 'seem': 809, 'protection': 810, 'dont': 811, 'historic': 812, 'grandmother': 813, 'glad': 814, 'basic': 815, 'idiot': 816, 'early': 817, 'saves': 818, 'assure': 819, 'compared': 820, 'heres': 821, 'newly': 822, 'stopped': 823, 'respecting': 824, 'asked': 825, 'experience': 826, 'nd': 827, 'respected': 828, 'measure': 829, 'barier': 830, 'pure': 831, 'deeply': 832, 'scam': 833, 'relatives': 834, 'inflated': 835, 'hesitating': 836, 'call': 837, 'appointment': 838, 'procurement': 839, 'pay': 840, 'r': 841, 'd': 842, 'manufacturing': 843, 'makers': 844, 'crisis': 845, 'affect': 846, 'economy': 847, 'kills': 848, 'requires': 849, 'gonna': 850, 'illness': 851, 'anyways': 852, 'honestly': 853, 'ppe': 854, 'hiv': 855, 'popular': 856, 'hostile': 857, 'anything': 858, 'participate': 859, 'commercial': 860, 'involved': 861, 'responsible': 862, 'stepping': 863, 'later': 864, 'distancing': 865, 'ensure': 866, 'doctor': 867, 'zero': 868, 'damage': 869, 'europe': 870, 'full': 871, 'investor': 872, 'paywall': 873, 'usually': 874, 'destroy': 875, 'imperative': 876, 'react': 877, 'pharmacists': 878, 'june': 879, 'created': 880, 'nobody': 881, 'potential': 882, 'unsafe': 883, 'west': 884, 'chain': 885, 'agreement': 886, 'hearing': 887, 'questions': 888, 'alaskan': 889, 'suffers': 890, 'minutes': 891, 'disadvantages': 892, 'step': 893, 'large': 894, 'talk': 895, 'neighbours': 896, 'touch': 897, 'post': 898, 'publicity': 899, 'warned': 900, 'remains': 901, 'option': 902, 'damn': 903, 'task': 904, 'force': 905, 'announces': 906, 'dr': 907, 'vaxxers': 908, 'school': 909, 'bar': 910, 'times': 911, 'january': 912, 'spirit': 913, 'listen': 914, 'impossible': 915, 'beware': 916, 'fraudulent': 917, 'treatments': 918, 'development': 919, 'distributed': 920, 'resuscitation': 921, 'fresh': 922, 'apparently': 923, 'suffering': 924, 'poison': 925, 'ass': 926, 'paul': 927, 'gain': 928, 'credible': 929, 'acquired': 930, 'suffered': 931, 'interest': 932, 'trying': 933, 'wants': 934, 'sheep': 935, 'pleasure': 936, 'substance': 937, 'per': 938, 'suspicious': 939, 'looking': 940, 'stocks': 941, 'choose': 942, 'judgment': 943, 'based': 944, 'changed': 945, 'listening': 946, 'chip': 947, 'simply': 948, 'worker': 949, 'offer': 950, 'talking': 951, 'shown': 952, 'expected': 953, 'man': 954, 'support': 955, 'knew': 956, 'hopefully': 957, 'regarding': 958, 'stories': 959, 'beat': 960, 'fully': 961, 'success': 962, 'evening': 963, 'unbelievably': 964, 'clearconfirmed': 965, 'multinational': 966, 'fuss': 967, 'u': 968, 'becoime': 969, 'leaky': 970, 'transmission': 971, 'shed': 972, 'quiet': 973, 'tend': 974, 'ignoramuses': 975, 'charlatans': 976, 'theorists': 977, 'yay': 978, 'congratulations': 979, 'safest': 980, 'polyethylene': 981, 'glycol': 982, 'urgently': 983, 'needed': 984, 'bothered': 985, 'competition': 986, 'recipe': 987, 'disappear': 988, 'efficient': 989, 'australia': 990, 'outbreak': 991, 'woolworths': 992, 'shopping': 993, 'elderly': 994, 'disabled': 995, 'sfr': 996, 'tp': 997, 'hoarding': 998, 'invite': 999, 'regain': 1000, 'surprised': 1001, 'learn': 1002, 'immunosuppressed': 1003, 'saw': 1004, 'presentation': 1005, 'jarvits': 1006, 'centre': 1007, 'superb': 1008, 's': 1009, 'pieces': 1010, 'top': 1011, 'email': 1012, 'supposedly': 1013, 'advantage': 1014, 'technological': 1015, 'advances': 1016, 'mostly': 1017, 'states': 1018, 'definition': 1019, 'vocation': 1020, 'mutating': 1021, 'precipitation': 1022, 'busting': 1023, 'balls': 1024, 'store': 1025, 'employee': 1026, 'respectfully': 1027, 'request': 1028, 'truck': 1029, 'drivers': 1030, 'managers': 1031, 'stores': 1032, 'asap': 1033, 'continuation': 1034, 'guaranteed': 1035, 'viruses': 1036, 'building': 1037, 'trial': 1038, 'extending': 1039, 'effort': 1040, 'status': 1041, 'held': 1042, 'warehouses': 1043, 'conflicting': 1044, 'desperately': 1045, 'sign': 1046, 'petition': 1047, 'demanding': 1048, 'reasearch': 1049, 'condition': 1050, 'cheap': 1051, 'oclock': 1052, 'seriously': 1053, 'agency': 1054, 'greater': 1055, 'vary': 1056, 'pperson': 1057, 'hence': 1058, 'neutrality': 1059, 'altruism': 1060, 'imposed': 1061, 'fundamental': 1062, 'successfully': 1063, 'within': 1064, 'programm': 1065, 'amazing': 1066, 'feels': 1067, 'needle': 1068, 'inserted': 1069, 'massive': 1070, 'novel': 1071, 'minister': 1072, 'excellent': 1073, 'increase': 1074, 'restrictions': 1075, 'decrease': 1076, 'israel': 1077, 'conscious': 1078, 'proper': 1079, 'bra': 1080, 'supporter': 1081, 'mine': 1082, 'uae': 1083, 'timely': 1084, 'consider': 1085, 'age': 1086, 'limits': 1087, 'quebec': 1088, 'maimonides': 1089, 'among': 1090, 'seniors': 1091, 'aspire': 1092, 'wary': 1093, 'proposing': 1094, 'headlines': 1095, 'reassure': 1096, 'harmlessness': 1097, 'hard': 1098, 'current': 1099, 'attacks': 1100, 'rush': 1101, 'alternatives': 1102, 'grandmas': 1103, 'secrets': 1104, 'insisting': 1105, 'efficacy': 1106, 'wors': 1107, 'merkel': 1108, 'watching': 1109, 'smooth': 1110, 'operating': 1111, 'machine': 1112, 'prisoner': 1113, 'faster': 1114, 'spy': 1115, 'officials': 1116, 'medicare': 1117, 'claims': 1118, 'identity': 1119, 'theft': 1120, 'schemes': 1121, 'packages': 1122, 'ap': 1123, 'constraints': 1124, 'union': 1125, 'regulator': 1126, 'selection': 1127, 'starting': 1128, 'distanced': 1129, 'patiently': 1130, 'brought': 1131, 'perfection': 1132, 'toronto': 1133, 'ontarios': 1134, 'looks': 1135, 'lasts': 1136, 'tears': 1137, 'gave': 1138, 'joy': 1139, 'icu': 1140, 'sandra': 1141, 'lindsay': 1142, 'deal': 1143, 'chemo': 1144, 'alzheimers': 1145, 'parkinsons': 1146, 'aids': 1147, 'miracle': 1148, 'hurraah': 1149, 'dead': 1150, 'paranoid': 1151, 'litteraly': 1152, 'causes': 1153, 'shortage': 1154, 'hole': 1155, 'decates': 1156, 'deseases': 1157, 'heist': 1158, 'looting': 1159, 'half': 1160, 'africas': 1161, 'resources': 1162, 'drop': 1163, 'allergies': 1164, 'tolerating': 1165, 'oripire': 1166, 'record': 1167, 'intriguing': 1168, 'outcome': 1169, 'heh': 1170, 'purely': 1171, 'write': 1172, 'pays': 1173, 'armed': 1174, 'guidance': 1175, 'whilst': 1176, 'breastfeeding': 1177, 'opted': 1178, 'grey': 1179, 'area': 1180, 'cat': 1181, 'mouse': 1182, 'game': 1183, 'obviously': 1184, 'dosis': 1185, 'memorial': 1186, 'mir': 1187, 'gild': 1188, 'monthly': 1189, 'higher': 1190, 'appears': 1191, 'positioned': 1192, 'immigrant': 1193, 'muslim': 1194, 'couple': 1195, 'honored': 1196, 'gettin': 1197, 'besides': 1198, 'expectedcovid': 1199, 'superior': 1200, 'confirmed': 1201, 'past': 1202, 'above': 1203, 'design': 1204, 'incentives': 1205, 'ventilators': 1206, 'economists': 1207, 'navigate': 1208, 'york': 1209, 'city': 1210, 'reports': 1211, 'skeptics': 1212, 'becerra': 1213, 'medicine': 1214, 'cdc': 1215, 'motivated': 1216, 'prediction': 1217, 'overuse': 1218, 'antibacterial': 1219, 'lead': 1220, 'mutations': 1221, 'bacteria': 1222, 'astrazaneca': 1223, 'moreover': 1224, 'alarmed': 1225, 'mainly': 1226, 'massively': 1227, 'pessimistic': 1228, 'shipments': 1229, 'initial': 1230, 'selected': 1231, 'ports': 1232, 'entry': 1233, 'relevant': 1234, 'giving': 1235, 'clinical': 1236, 'humans': 1237, 'interact': 1238, 'ligma': 1239, 'catching': 1240, 'folks': 1241, 'eff': 1242, 'ruining': 1243, 'prospect': 1244, 'anesthesia': 1245, 'surgeries': 1246, 'apart': 1247, 'introduced': 1248, 'b': 1249, 'preferenceany': 1250, 'messing': 1251, 'heads': 1252, 'uphow': 1253, 'ride': 1254, 'pfeizer': 1255, 'whitout': 1256, 'accept': 1257, 'researchers': 1258, 'suppository': 1259, 'kids': 1260, 'towards': 1261, 'chloroquine': 1262, 'eyes': 1263, 'officially': 1264, 'nor': 1265, 'humanitarian': 1266, 'began': 1267, 'jabs': 1268, 'dunno': 1269, 'earth': 1270, 'guys': 1271, 'eliminate': 1272, 'helped': 1273, 'sydney': 1274, 'wave': 1275, 'jab': 1276, 'enrouged': 1277, 'slaves': 1278, 'article': 1279, 'explaining': 1280, 'linked': 1281, 'professor': 1282, 'eyeing': 1283, 'urges': 1284, 'canadians': 1285, 'tonight': 1286, 'flexing': 1287, 'takes': 1288, 'recherches': 1289, 'highly': 1290, 'risked': 1291, 'job': 1292, 'firefighters': 1293, 'revisit': 1294, 'museums': 1295, 'freshly': 1296, 'flu': 1297, 'phew': 1298, 'congratulate': 1299, 'vloggers': 1300, 'promotion': 1301, 'promote': 1302, 'complications': 1303, 'o': 1304, 'further': 1305, 'incentive': 1306, 'single': 1307, 'harmless': 1308, 'comorbidity': 1309, 'aged': 1310, 'pre': 1311, 'existing': 1312, 'include': 1313, 'hypertension': 1314, 'diabetes': 1315, 'asthma': 1316, 'respiratory': 1317, 'liver': 1318, 'kidney': 1319, 'stabilised': 1320, 'chronic': 1321, 'properly': 1322, 'washed': 1323, 'mouth': 1324, 'nose': 1325, 'hate': 1326, 'adults': 1327, 'failed': 1328, 'deliver': 1329, 'promises': 1330, 'numbers': 1331, 'serving': 1332, 'cobaille': 1333, 'arose': 1334, 'having': 1335, 'optimistic': 1336, 'september': 1337, 'sorry': 1338, 'lethal': 1339, 'lung': 1340, 'guilty': 1341, 'mama': 1342, 'michel': 1343, 'don': 1344, 'council': 1345, 'communicate': 1346, 'warn': 1347, 'society': 1348, 'licensed': 1349, 'pregnant': 1350, 'democrats': 1351, 'nation': 1352, 'senate': 1353, 'republicans': 1354, 'investors': 1355, 'starts': 1356, 'hopes': 1357, 'launch': 1358, 'watchdog': 1359, 'rospotrebnadzor': 1360, 'vacation': 1361, 'traumatize': 1362, 'refusing': 1363, 'collective': 1364, 'suicide': 1365, 'achieve': 1366, 'commodity': 1367, 'primarily': 1368, 'baby': 1369, 'annihilate': 1370, 'imminent': 1371, 'paranormal': 1372, 'girl': 1373, 'disparity': 1374, 'politicized': 1375, 'matters': 1376, 'play': 1377, 'anyhow': 1378, 'authorization': 1379, 'developer': 1380, 'sometimes': 1381, 'kinda': 1382, 'arabian': 1383, 'peninsula': 1384, 'expenditure': 1385, 'purposes': 1386, 'iran': 1387, 'helpfully': 1388, 'receives': 1389, 'recently': 1390, 'scenario': 1391, 'partnership': 1392, 'basis': 1393, 'hijacked': 1394, 'once': 1395, 'bothering': 1396, 'insist': 1397, 'corporations': 1398, 'fund': 1399, 'hurt': 1400, 'rusty': 1401, 'piece': 1402, 'iron': 1403, 'financial': 1404, 'scandal': 1405, 'organization': 1406, 'intend': 1407, 'import': 1408, 'capacity': 1409, 'resist': 1410, 'unbearable': 1411, 'ego': 1412, 'roof': 1413, 'liable': 1414, 'nura': 1415, 'emir': 1416, 'festi': 1417, 'brave': 1418, 'fighter': 1419, 'planes': 1420, 'missiles': 1421, 'neonuclear': 1422, 'weapons': 1423, 'protocol': 1424, 'funerals': 1425, 'traumatic': 1426, 'chinese': 1427, 'meanwhile': 1428, 'significant': 1429, 'total': 1430, 'friend': 1431, 'unless': 1432, 'eat': 1433, 'composition': 1434, 'inconvenients': 1435, 'mild': 1436, 'moderate': 1437, 'privileged': 1438, 'itll': 1439, 'singapore': 1440, 'throwing': 1441, 'thag': 1442, 'statistics': 1443, 'percentage': 1444, 'effect': 1445, 'whatever': 1446, 'immunizes': 1447, 'collect': 1448, 'teach': 1449, 'cells': 1450, 'trigger': 1451, 'vi': 1452, 'fought': 1453, 'property': 1454, 'object': 1455, 'denial': 1456, 'preventive': 1457, 'curative': 1458, 'infancy': 1459, 'evidence': 1460, 'particularly': 1461, 'helpful': 1462, 'primary': 1463, 'stabilitechs': 1464, 'intended': 1465, 'delivered': 1466, 'disruptive': 1467, 'capsule': 1468, 'efficacious': 1469, 'capsules': 1470, 'inexpensive': 1471, 'posted': 1472, 'rd': 1473, 'th': 1474, 'induce': 1475, 'carried': 1476, 'berlin': 1477, 'altruists': 1478, '21': 1479, 'sanitary': 1480, 'leaders': 1481, 'vacations': 1482, 'dit': 1483, 'horrible': 1484, 'marketing': 1485, 'misleading': 1486, 'produces': 1487, 'claim': 1488, 'built': 1489, 'mot': 1490, 'als': 1491, 'kuwait': 1492, 'consideration': 1493, 'friday': 1494, 'taxes': 1495, 'pisses': 1496, 'becomes': 1497, 'astraastrazeneka': 1498, 'somewhere': 1499, 'close': 1500, 'priority': 1501, 'queue': 1502, 'names': 1503, 'gloves': 1504, 'volatility': 1505, 'levels': 1506, 'become': 1507, 'growing': 1508, 'tan': 1509, 'concentrate': 1510, 'beneficial': 1511, 'small': 1512, 'summer': 1513, 'experiencing': 1514, 'potentially': 1515, 'saving': 1516, 'thousands': 1517, 'fourth': 1518, 'fifth': 1519, 'sixth': 1520, 'seventh': 1521, 'loop': 1522, 'ends': 1523, 'compares': 1524, 'plans': 1525, 'inoculation': 1526, 'wednesday': 1527, 'eventually': 1528, 'incredible': 1529, 'count': 1530, 'experiment': 1531, 'prepping': 1532, 'shipment': 1533, 'sites': 1534, 'conceived': 1535, 'haste': 1536, 'aim': 1537, 'day3': 1538, 'risking': 1539, 'value': 1540, 'convince': 1541, 'george': 1542, 'soros': 1543, 'four': 1544, 'dread': 1545, 'race': 1546, 'wife': 1547, 'win': 1548, 'provide': 1549, 'outdated': 1550, 'magnitude': 1551, 'action': 1552, 'brake': 1553, 'poisons': 1554, 'left': 1555, 'flocking': 1556, 'tragedy': 1557, 'corporate': 1558, 'greed': 1559, 'transparent': 1560, 'came': 1561, 'decisions': 1562, 'sides': 1563, 'tolerated': 1564, 'sickness': 1565, 'itself': 1566, 'patented': 1567, 're': 1568, 'several': 1569, 'tinkered': 1570, 'marketed': 1571, 'urgent': 1572, 'warnings': 1573, 'chaos': 1574, 'hunt': 1575, 'usedas': 1576, 'influence': 1577, 'worries': 1578, 'barely': 1579, 'text': 1580, 'pandemie': 1581, 'forgot': 1582, 'clue': 1583, 'heath': 1584, 'comparison': 1585, 'distant': 1586, 'versus': 1587, 'workso': 1588, 'types': 1589, 'theyd': 1590, 'buy': 1591, 'extrapolated': 1592, 'cartels': 1593, 'payback': 1594, 'difficulty': 1595, 'picking': 1596, 'solved': 1597, 'operator': 1598, 'surrounding': 1599, 'aka': 1600, 'practically': 1601, 'disappeared': 1602, 'require': 1603, 'specific': 1604, 'operation': 1605, 'huge': 1606, 'ensuring': 1607, 'suppose': 1608, 'documents': 1609, 'id': 1610, 'w': 1611, 'excuse': 1612, 'contain': 1613, 'credibility': 1614, 'tiniest': 1615, 'bit': 1616, 'soreness': 1617, 'automatically': 1618, 'enters': 1619, 'bloodstream': 1620, 'challenge': 1621, 'accessible': 1622, 'affordable': 1623, 'mortality': 1624, 'contract': 1625, 'transmit': 1626, 'arms': 1627, 'meeting': 1628, 'review': 1629, 'possibly': 1630, 'approving': 1631, 'bumped': 1632, 'december': 1633, 'list': 1634, 'technique': 1635, 'capable': 1636, 'decimating': 1637, 'act': 1638, 'warm': 1639, 'spreading': 1640, 'relieved': 1641, 'fo': 1642, 'trustworthy': 1643, 'academic': 1644, 'critical': 1645, 'easing': 1646, 'concerns': 1647, 'dromois': 1648, 'teenagers': 1649, 'keeping': 1650, 'reserves': 1651, 'mid': 1652, 'july': 1653, 'complete': 1654, '4': 1655, 'desease': 1656, 'oregon': 1657, 'wanted': 1658, 'amazed': 1659, 'turnaround': 1660, 'healthy': 1661, 'became': 1662, 'owe': 1663, 'debt': 1664, 'gratitude': 1665, 'bravery': 1666, 'neither': 1667, 'produced': 1668, 'notice': 1669, 'nhs': 1670, 'picture': 1671, 'video': 1672, 'actual': 1673, 'poisson': 1674, 'departure': 1675, 'impressive': 1676, 'cameroon': 1677, 'containment': 1678, 'suspicion': 1679, 'mistrust': 1680, 'scale': 1681, 'holding': 1682, 'deliveries': 1683, 'major': 1684, 'banning': 1685, 'exports': 1686, 'stole': 1687, 'orcas': 1688, 'rice': 1689, 'senators': 1690, 'insider': 1691, 'trading': 1692, 'doubles': 1693, 'capitol': 1694, 'hill': 1695, 'debate': 1696, 'folk': 1697, 'additional': 1698, 'under': 1699, 'anyones': 1700, 'california': 1701, 'nightgov': 1702, 'gav': 1703, 'paid': 1704, 'level': 1705, 'youre': 1706, 'tick': 1707, 'remembers': 1708, 'childhood': 1709, 'messenger': 1710, 'advanced': 1711, 'raised': 1712, 'responsibility': 1713, 'iv': 1714, 'm': 1715, 'house': 1716, 'often': 1717, 'regularly': 1718, 'office': 1719, 'prioritized': 1720, 'constantly': 1721, 'football': 1722, 'stadium': 1723, 'arrives': 1724, 'oman': 1725, 'forcing': 1726, 'emirati': 1727, 'observe': 1728, 'rotten': 1729, 'bribing': 1730, 'shame': 1731, 'pressuring': 1732, 'license': 1733, 'organisation': 1734, 'agns': 1735, 'buzyn': 1736, 'laugh': 1737, 'loud': 1738, 'enjoy': 1739, 'supervising': 1740, 'torn': 1741, 'firstish': 1742, 'founder': 1743, 'biotechnology': 1744, 'hat': 1745, 'attention': 1746, 'british': 1747, 'airways': 1748, 'suspend': 1749, 'wanting': 1750, 'encouraging': 1751, 'bosnia': 1752, 'sinovac': 1753, 'confused': 1754, 'contradictory': 1755, 'circulating': 1756, 'hurry': 1757, 'announce': 1758, 'animals': 1759, 'experiments': 1760, 'africans': 1761, 'views': 1762, 'complaining': 1763, 'wearing': 1764, 'piss': 1765, 'privilege': 1766, 'oms': 1767, 'fail': 1768, 'proliferate': 1769, 'watch': 1770, 'victim': 1771, 'donation': 1772, 'mule': 1773, 'recruitment': 1774, 'tactics': 1775, 'vogue': 1776, 'coronavirusdo': 1777, 'fooled': 1778, 'capitalists': 1779, 'charade': 1780, 'limited': 1781, 'certain': 1782, 'areas': 1783, 'imagined': 1784, 'cured': 1785, 'medication': 1786, 'uncertain': 1787, 'grandchildren': 1788, 'becoming': 1789, 'destined': 1790, 'rome': 1791, 'initiative': 1792, 'intrigued': 1793, 'speaking': 1794, 'department': 1795, 'justice': 1796, 'shut': 1797, 'website': 1798, 'warns': 1799, 'join': 1800, 'ranks': 1801, 'scared': 1802, 'vijay': 1803, 'reddy': 1804, 'forget': 1805, 'tragic': 1806, 'episode': 1807, 'century': 1808, 'recover': 1809, 'atshmatic': 1810, 'mucus': 1811, 'suffer': 1812, 'underestimate': 1813, 'wonders': 1814, 'certificate': 1815, 'fly': 1816, 'cruise': 1817, 'subway': 1818, 'concert': 1819, 'noir': 1820, 'thomasall': 1821, 'boom': 1822, 'delt': 1823, 'extreme': 1824, 'confident': 1825, 'played': 1826, 'role': 1827, 'hey': 1828, 'terfs': 1829, 'heard': 1830, 'trans': 1831, 'vax': 1832, 'remember': 1833, 'lick': 1834, 'counters': 1835, 'transit': 1836, 'seats': 1837, 'boose': 1838, 'tough': 1839, 'myth': 1840, 'terf': 1841, 'meet': 1842, 'corp': 1843, 'rising': 1844, 'pharmaceuticals': 1845, 'doubled': 1846, 'safeguards': 1847, 'jacking': 1848, 'guide': 1849, 'notgiven': 1850, 'gift': 1851, 'grandmothers': 1852, 'retirement': 1853, 'starvation': 1854, 'malnutrition': 1855, 'invention': 1856, 'labs': 1857, 'commission': 1858, 'eu': 1859, 'conscience': 1860, 'warp': 1861, 'speedplease': 1862, 'issued': 1863, 'advising': 1864, 'rapidly': 1865, 'facilitate': 1866, 'dog': 1867, 'chickens': 1868, 'mutant': 1869, 'unbelievable': 1870, 'ha': 1871, 'formally': 1872, 'casts': 1873, 'votes': 1874, 'courage': 1875, 'ability': 1876, 'defend': 1877, 'sat': 1878, 'cup': 1879, 'coffee': 1880, 'witness': 1881, 'impact': 1882, 'menstruation': 1883, 'expire': 1884, 'march': 1885, 'writing': 1886, 'book': 1887, 'exposed': 1888, 'cimas': 1889, 'recommends': 1890, 'pleased': 1891, 'possi': 1892, 'heroes': 1893, 'todayimpressive': 1894, 'resource': 1895, 'mobilization': 1896, 'oh': 1897, 'freer': 1898, 'completely': 1899, 'noway': 1900, 'chipped': 1901, 'reassured': 1902, 'lack': 1903, 'hindsight': 1904, 'annoyed': 1905, 'proportion': 1906, 'disorders': 1907, 'caused': 1908, 'whereas': 1909, 'hardly': 1910, 'stick': 1911, 'shitty': 1912, 'okay': 1913, 'sceptical': 1914, 'c': 1915, 'toxic': 1916, 'smells': 1917, 'war': 1918, 'concretely': 1919, 'motivates': 1920, 'inventors': 1921, 'sterile': 1922, 'importance': 1923, 'ceased': 1924, 'passed': 1925, 'military': 1926, 'industrialists': 1927, 'main': 1928, 'objects': 1929, 'infection': 1930, 'victims': 1931, 'compensated': 1932, 'concerning': 1933, 'encouraged': 1934, 'taxpayer': 1935, 'reached': 1936, 'federal': 1937, 'artemesia': 1938, 'officialized': 1939, 'organizations': 1940, 'neglected': 1941, 'ill': 1942, 'benefit': 1943, 'deadly': 1944, 'savinghuman': 1945, 'hold': 1946, 'accountable': 1947, 'brothers': 1948, 'fill': 1949, 'coffers': 1950, 'everywhere': 1951, 'results': 1952, 'entire': 1953, 'delaware': 1954, 'reasons': 1955, 'stella': 1956, 'maris': 1957, 'citizens': 1958, 'families': 1959, 'showed': 1960, 'fair': 1961, 'equitable': 1962, 'recalls': 1963, 'supposed': 1964, 'autumn': 1965, 'else': 1966, 'undergo': 1967, 'surprising': 1968, 'acceptable': 1969, 'jam': 1970, 'neutral': 1971, 'modernas': 1972, 'joins': 1973, 'battle': 1974, 'canton': 1975, 'due': 1976, 'jan': 1977, 'alive': 1978, 'worked': 1979, 'pig': 1980, 'ehpad': 1981, 'testify': 1982, 'liveplease': 1983, 'trusts': 1984, 'republic': 1985, 'poorly': 1986, 'researched': 1987, 'realise': 1988, 'unvaccinated': 1989, 'againts': 1990, 'virusbecause': 1991, 'vacination': 1992, 'advance': 1993, 'persones': 1994, 'drasticaly': 1995, 'reduced': 1996, 'pressure': 1997, 'poooor': 1998, 'worlds': 1999, 'pension': 2000, 'remedy': 2001, 'accepted': 2002, 'auditioned': 2003, 'product': 2004, 'visible': 2005, 'sheet': 2006, 'providers': 2007, 'limit': 2008, 'liquidate': 2009, 'ideal': 2010, 'targets': 2011, 'biya': 2012, 'previous': 2013, 'historical': 2014, 'daughter': 2015, 'polishes': 2016, 'decades': 2017, 'smallpox': 2018, 'adjusted': 2019, 'dominant': 2020, 'learned': 2021, 'frontline': 2022, 'childrens': 2023, 'though': 2024, 'posing': 2025, 'vulnerable': 2026, 'late': 2027, 'j': 2028, 'crap': 2029, 'approv': 2030, 'prejorative': 2031, 'surreal': 2032, 'dropping': 2033, 'deplore': 2034, 'bion': 2035, 'bogus': 2036, 'kit': 2037, 'minimal': 2038, 'immense': 2039, 'miss': 2040, 'prowess': 2041, 'chance': 2042, 'armor': 2043, 'professionals': 2044, 'nurses': 2045, 'caregivers': 2046, 'kissed': 2047, 'goodbye': 2048, 'distance': 2049, 'uses': 2050, 'receivers': 2051, 'momentous': 2052, 'particular': 2053, 'fewer': 2054, 'naysayers': 2055, 'graveling': 2056, 'feet': 2057, 'killed': 2058, 'k': 2059, 'appreciate': 2060, 'waking': 2061, 'efforts': 2062, 'kingdom': 2063, 'scotland': 2064, 'place': 2065, 'purpose': 2066, 'doesnt': 2067, 'approval': 2068, 'thr': 2069, 'compagnie': 2070, 'emmanuel': 2071, 'macron': 2072, 'himself': 2073, 'images': 2074, 'broadcast': 2075, 'television': 2076, 'bringing': 2077, 'air': 2078, 'unexpected': 2079, 'name': 2080, 'suggests': 2081, 'predict': 2082, 'clinic': 2083, 'lots': 2084, 'releases': 2085, 'astra': 2086, 'astrazeneka': 2087, 'controversy': 2088, 'tv': 2089, 'saying': 2090, 'expensive': 2091, 'soared': 2092, 'lying': 2093, 'winning': 2094, 'joke': 2095, 'chose': 2096, 'yours': 2097, 'hcw': 2098, 'assuage': 2099, 'anxiety': 2100, 'liberty': 2101, 'cold': 2102, 'across': 2103, 'county': 2104, 'dictatorship': 2105, 'spoke': 2106, 'dull': 2107, 'achey': 2108, 'sore': 2109, 'deltoid': 2110, 'advantages': 2111, 'outweigh': 2112, 'high': 2113, 'patents': 2114, 'arses': 2115, 'arriving': 2116, 'complicated': 2117, 'inform': 2118, 'project': 2119, 'report': 2120, 'percent': 2121, 'saudis': 2122, 'expats': 2123, 'daft': 2124, 'hurts': 2125, 'ears': 2126, 'faint': 2127, 'recommended': 2128, 'quarterly': 2129, 'deprogramming': 2130, 'catastrophic': 2131, 'eligible': 2132, 'amid': 2133, 'tiktok': 2134, 'losing': 2135, 'minds': 2136, 'reputation': 2137, 'premature': 2138, 'member': 2139, 'concussion': 2140, 'occurred': 2141, 'tuesday': 2142, 'impression': 2143, 'maximum': 2144, 'costs': 2145, 'leads': 2146, 'investigating': 2147, 'rare': 2148, 'extent': 2149, 'figures': 2150, 'booked': 2151, 'laughing': 2152, 'thought': 2153, 'schools': 2154, 'closed': 2155, 'carriers': 2156, 'volunteer': 2157, 'nights': 2158, 'shift': 2159, 'viable': 2160, 'pessimist': 2161, 'existence': 2162, 'anymore': 2163, 'treats': 2164, 'leaving': 2165, 'peaceful': 2166, 'pain': 2167, 'shoulder': 2168, 'sister': 2169, 'law': 2170, 'sim': 2171, 'trouble': 2172, 'passing': 2173, 'f': 2174, 'rages': 2175, 'kill': 2176, 'retrovirus': 2177, 'sinopharm': 2178, 'behaviour': 2179, 'contains': 2180, 'pristine': 2181, 'painless': 2182, 'creation': 2183, 'atrocities': 2184, 'notbeen': 2185, 'phase': 2186, 'dec': 2187, 'tendency': 2188, 'europeans': 2189, 'propagation': 2190, 'sad': 2191, 'listed': 2192, 'various': 2193, 'markets': 2194, 'pushing': 2195, 'finding': 2196, 'cures': 2197, 'push': 2198, 'identified': 2199, 'undoubtably': 2200, 'regulators': 2201, 'street': 2202, 'regret': 2203, 'crowded': 2204, 'rots': 2205, 'return': 2206, 'opt': 2207, 'employer': 2208, 'polished': 2209, 'theories': 2210, 'calls': 2211, 'emails': 2212, 'visitors': 2213, 'asking': 2214, 'usernames': 2215, 'pasords': 2216, 'strange': 2217, 'links': 2218, 'regions': 2219}\n"
     ]
    }
   ],
   "source": [
    "# visualization of the result obtained after tokenization.\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print(f\"{Fore.GREEN}------------------- visualization of the result obtained after tokenization. ------------------- \")\n",
    "print(f\"{Fore.BLACK}\",word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    " Let's apply the tokenisation operation to each expression in column x. \n",
    "This will allow us to observe that each expression is identifiable by a group of numbers.\n",
    "\"\"\"\n",
    "\n",
    "train_sequences = tokenizer.texts_to_sequences(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we need to be vaccinated to protect all person around us\n",
      "\u001b[34m first sentence. ===>  we need to be vaccinated to protect all person around us\n",
      "\u001b[34m first sentence. ===>  [48, 963, 3, 25, 13, 1, 4]\n",
      "\u001b[32m second sentence.  ===> it is a pleasure to see how the govement are working for our help i thing the vaccination is good for all of us\n",
      "\u001b[34m second sentence. ===>  [19, 5, 964, 617, 618, 33, 6, 2, 965, 230, 356, 231]\n",
      "\u001b[35m third sentence.  ===>  negative\n",
      "\u001b[34m third sentence. ===>  [357, 2, 39, 168, 66, 27, 103, 9, 4]\n"
     ]
    }
   ],
   "source": [
    "# Let's see what the first three expressions of the document look like after the tokenisation operation.\n",
    "print(data.clean[0])\n",
    "print(f\"{Fore.BLUE} first sentence. ===> \",data.clean[0])\n",
    "print(f\"{Fore.BLUE} first sentence. ===> \",train_sequences[0])\n",
    "\n",
    "print(f\"{Fore.GREEN} second sentence.  ===>\",data.clean[1])\n",
    "print(f\"{Fore.BLUE} second sentence. ===> \",train_sequences[1])\n",
    "\n",
    "print(f\"{Fore.MAGENTA} third sentence.  ===> \",data.clean[2])\n",
    "print(f\"{Fore.BLUE} third sentence. ===> \",train_sequences[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We will try to transform each expression in the tokenizer to the length format defined above.\n",
    "This allows us to have expressions of the same length.\n",
    "\"\"\"\n",
    "\n",
    "train_padded = pad_sequences(train_sequences, maxlen=max_length, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m first sentence. ===>  [ 48 963   3  25  13   1   4   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0]\n",
      "\u001b[32m second sentence.  ===> [ 19   5 964 617 618  33   6   2 965 230 356 231   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0]\n",
      "\u001b[35m third sentence.  ===>  [357   2  39 168  66  27 103   9   4   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "# Let's see what the first three expressions of the document look like after the operation.\n",
    "\n",
    "print(f\"{Fore.BLUE} first sentence. ===> \",train_padded[0])\n",
    "print(f\"{Fore.GREEN} second sentence.  ===>\",train_padded[1])\n",
    "print(f\"{Fore.MAGENTA} third sentence.  ===> \",train_padded[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we repeat the same operations on the test sentences\n",
    "\n",
    "\"\"\"\n",
    "We will try to transform each expression in the tokenizer to the length format defined above.\n",
    "This allows us to have expressions of the same length.\n",
    "\"\"\"\n",
    "\n",
    "test_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "test_padded = pad_sequences(test_sequences, maxlen=max_length, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m Shape of train. ===>  {(818, 42)}\n",
      "\u001b[34m Shape of train. ===>  {(205, 42)}\n",
      "\u001b[32m This means that 80% of the training data corresponds to 817 sentences of 42 words each. \n"
     ]
    }
   ],
   "source": [
    "# how our training data is dimensioned.\n",
    "print(f\"{Fore.BLUE} Shape of train. ===> \",{train_padded.shape})\n",
    "print(f\"{Fore.BLUE} Shape of train. ===> \",{test_padded.shape})\n",
    "print(f\"{Fore.GREEN} This means that 80% of the training data corresponds to 817 sentences of 42 words each. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 42, 100)           254000    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 42, 100)           0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 42, 64)            42240     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 32)                12416     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 308,755\n",
      "Trainable params: 308,755\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "We will now create a model that will be adapted to tertiary data. That is, with two labels, positive,neutral and negative\n",
    "\n",
    "positive ==> [0 0 1]\n",
    "Neutral  ==> [0 1 0]\n",
    "Negative ==> [1 0 0]\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# define model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(num_words, 100, input_length=max_length))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.1))\n",
    "model.add(LSTM(32, dropout=0.2, recurrent_dropout=0.1))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "optimizer = Adam()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "52/52 - 48s - loss: 1.0201 - accuracy: 0.4804\n",
      "Epoch 2/10\n",
      "52/52 - 6s - loss: 1.0080 - accuracy: 0.4756\n",
      "Epoch 3/10\n",
      "52/52 - 4s - loss: 1.0007 - accuracy: 0.4939\n",
      "Epoch 4/10\n",
      "52/52 - 5s - loss: 0.9373 - accuracy: 0.5636\n",
      "Epoch 5/10\n",
      "52/52 - 4s - loss: 0.6973 - accuracy: 0.7213\n",
      "Epoch 6/10\n",
      "52/52 - 5s - loss: 0.5570 - accuracy: 0.7836\n",
      "Epoch 7/10\n",
      "52/52 - 5s - loss: 0.4426 - accuracy: 0.8191\n",
      "Epoch 8/10\n",
      "52/52 - 5s - loss: 0.4434 - accuracy: 0.8178\n",
      "Epoch 9/10\n",
      "52/52 - 4s - loss: 0.4071 - accuracy: 0.8289\n",
      "Epoch 10/10\n",
      "52/52 - 4s - loss: 0.4461 - accuracy: 0.8301\n",
      "\u001b[32m-------------------  The model was trained. ------------------- \n"
     ]
    }
   ],
   "source": [
    "# now we have to train the model \n",
    "model.fit(train_padded, y_train, epochs=10,batch_size=16,  verbose=2)\n",
    "print(f\"{Fore.GREEN}-------------------  The model was trained. ------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model :  61.95\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Now we test the model and we print the metrics data\n",
    "\"\"\"\n",
    "\n",
    "predictions = model.predict(test_padded)\n",
    "y_pred = (predictions > 0.5)\n",
    "print('Accuracy of the model : ', \"%.2f\" % (accuracy_score(y_pred, y_test)*100))\n",
    "# print(\"F1-score:  : \", \"%.2f\" %  (f1_score(y_pred, y_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m------------------- The simulation messages were successfully recorded.. ------------------- \n"
     ]
    }
   ],
   "source": [
    "#Simulate the model with unknow values\n",
    "\n",
    "\n",
    "# you cn write your own sentences on e and f nd check the result\n",
    "a = [\"a vaccine no i am not interested.\"]\n",
    "b = [\"There are times when I wonder why it is free. Anything that is free is dangerous. So i will never get it.\"]\n",
    "c = [\"I really don't know. I let time tell me.\"]\n",
    "d = [\" I don't think there's much difference with or without the vaccine, so I don't know what to do.\"]\n",
    "e = [\"I have my two doses and I am still alive. I am waiting for the others to find my freedom.\"]\n",
    "f = [\"Vaccination is very important. Also the vaccination against covid19.\"]\n",
    "\n",
    "print(f\"{Fore.GREEN}------------------- The simulation messages were successfully recorded.. ------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m------------------- The simulation messages cleaning operation is complete.. ------------------- \n"
     ]
    }
   ],
   "source": [
    "# clean the values\n",
    "clean_textA = clean_tweets(a)\n",
    "clean_textB = clean_tweets(b)\n",
    "clean_textC = clean_tweets(c)\n",
    "clean_textD = clean_tweets(d)\n",
    "clean_textE = clean_tweets(e)\n",
    "clean_textF = clean_tweets(f)\n",
    "\n",
    "print(f\"{Fore.GREEN}------------------- The simulation messages cleaning operation is complete.. ------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m 1.sentence. ===>  ['a vaccine no i am not interested.']\n",
      "\u001b[34m 1.sentence. ===>  [[  9   4  30   3  25   6 346   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0]]\n",
      "\u001b[32m 2.sentence. ===>  ['There are times when I wonder why it is free. Anything that is free is dangerous. So i will never get it.']\n",
      "\u001b[32m 2.sentence. ===>  [[ 59  15 911  75   3 343  66  10   5 100 858  18   5 100   5 786  26   3\n",
      "   21 105  20  10   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0]]\n",
      "\u001b[31m 3.sentence. ===>  [\"I really don't know. I let time tell me.\"]\n",
      "\u001b[31m 3.sentence. ===>  [[  3 130 811  99   3  94 117 380  39   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0]]\n",
      "\u001b[30m 4.sentence. ===>  [\" I don't think there's much difference with or without the vaccine, so I don't know what to do.\"]\n",
      "\u001b[30m 4.sentence. ===>  [[  3 811  53 640 134 552  29  43  96   1   4  26   3 811  99  86   2  22\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0]]\n",
      "\u001b[35m 5.sentence. ===>  ['I have my two doses and I am still alive. I am waiting for the others to find my freedom.']\n",
      "\u001b[35m 5.sentence. ===>  [[   3   24   23  106   72    7    3   25   91 1978    3   25  508   13\n",
      "     1  172    2  201   23  472    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0]]\n",
      "\u001b[34m 6.sentence. ===>  ['Vaccination is very important. Also the vaccination against covid19.']\n",
      "\u001b[34m 6.sentence. ===>  [[ 45   5  78 149 137   1  45  56 194   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "We will try to transform each expression in the tokenizer to the length format defined above.\n",
    "This allows us to have expressions of the same length.\n",
    "\"\"\"\n",
    "simulate_sentence_A = tokenizer.texts_to_sequences(clean_textA)\n",
    "simulate_sentence_B = tokenizer.texts_to_sequences(clean_textB)\n",
    "simulate_sentence_C = tokenizer.texts_to_sequences(clean_textC)\n",
    "simulate_sentence_D = tokenizer.texts_to_sequences(clean_textD)\n",
    "simulate_sentence_E = tokenizer.texts_to_sequences(clean_textE)\n",
    "simulate_sentence_F = tokenizer.texts_to_sequences(clean_textF)\n",
    "\n",
    "\n",
    "test_padded1 = pad_sequences(simulate_sentence_A, maxlen=max_length, padding='post', truncating='post')\n",
    "test_padded2 = pad_sequences(simulate_sentence_B, maxlen=max_length, padding='post', truncating='post')\n",
    "test_padded3 = pad_sequences(simulate_sentence_C, maxlen=max_length, padding='post', truncating='post')\n",
    "test_padded4 = pad_sequences(simulate_sentence_D, maxlen=max_length, padding='post', truncating='post')\n",
    "test_padded5 = pad_sequences(simulate_sentence_E, maxlen=max_length, padding='post', truncating='post')\n",
    "test_padded6 = pad_sequences(simulate_sentence_F, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "\n",
    "print(f\"{Fore.BLUE} 1.sentence. ===> \",a)\n",
    "print(f\"{Fore.BLUE} 1.sentence. ===> \",test_padded1)\n",
    "\n",
    "print(f\"{Fore.GREEN} 2.sentence. ===> \",b)\n",
    "print(f\"{Fore.GREEN} 2.sentence. ===> \",test_padded2)\n",
    "\n",
    "print(f\"{Fore.RED} 3.sentence. ===> \",c)\n",
    "print(f\"{Fore.RED} 3.sentence. ===> \",test_padded3)\n",
    "\n",
    "print(f\"{Fore.BLACK} 4.sentence. ===> \",d)\n",
    "print(f\"{Fore.BLACK} 4.sentence. ===> \",test_padded4)\n",
    "\n",
    "print(f\"{Fore.MAGENTA} 5.sentence. ===> \",e)\n",
    "print(f\"{Fore.MAGENTA} 5.sentence. ===> \",test_padded5)\n",
    "\n",
    "print(f\"{Fore.BLUE} 6.sentence. ===> \",f)\n",
    "print(f\"{Fore.BLUE} 6.sentence. ===> \",test_padded6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m------------------- Legend. ------------------- \n",
      "\u001b[31m negative ==> [1 0 0]\n",
      "\u001b[31m Neutral  ==> [0 1 0]\n",
      "\u001b[31m positive ==> [0 0 1]\n",
      "\u001b[32m#####################################################################################################\n",
      "\u001b[30m 1 --> display:  [[1. 0. 0.]]  instead of Negative [1 0 0]\n",
      "\u001b[30m 2 --> display:  [[1. 0. 0.]]  instead of Negative [1 0 0]\n",
      "\u001b[30m 3 --> display:  [[1. 0. 0.]]  instead of Neutral  [0 1 0]\n",
      "\u001b[30m 4 --> display:  [[1. 0. 0.]]  instead of Neutral  [0 1 0]\n",
      "\u001b[30m 5 --> display:  [[0. 0. 1.]]  instead of Positive [0 0 1]\n",
      "\u001b[30m 6 --> display:  [[0. 0. 1.]]  instead of Positive [0 0 1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pred1 = model.predict(test_padded1)\n",
    "pred2 = model.predict(test_padded2)\n",
    "pred3 = model.predict(test_padded3)\n",
    "pred4 = model.predict(test_padded4)\n",
    "pred5 = model.predict(test_padded5)\n",
    "pred6 = model.predict(test_padded6)\n",
    "\n",
    "print(f\"{Fore.BLUE}------------------- Legend. ------------------- \")\n",
    "print(f\"{Fore.RED} negative ==> [1 0 0]\")\n",
    "print(f\"{Fore.RED} Neutral  ==> [0 1 0]\")\n",
    "print(f\"{Fore.RED} positive ==> [0 0 1]\")\n",
    "\n",
    "print(f\"{Fore.GREEN}#####################################################################################################\")\n",
    "\n",
    "print(f\"{Fore.BLACK} 1 --> display: \", np.around(pred1, decimals=0),\" instead of Negative [1 0 0]\")\n",
    "print(f\"{Fore.BLACK} 2 --> display: \", np.around(pred2, decimals=0),\" instead of Negative [1 0 0]\")\n",
    "print(f\"{Fore.BLACK} 3 --> display: \", np.around(pred3, decimals=0),\" instead of Neutral  [0 1 0]\")\n",
    "print(f\"{Fore.BLACK} 4 --> display: \", np.around(pred4, decimals=0),\" instead of Neutral  [0 1 0]\")\n",
    "print(f\"{Fore.BLACK} 5 --> display: \", np.around(pred5, decimals=0),\" instead of Positive [0 0 1]\")\n",
    "print(f\"{Fore.BLACK} 6 --> display: \", np.around(pred6, decimals=0),\" instead of Positive [0 0 1]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m------------------- The firsst NN prototype is completed. ------------------- \n"
     ]
    }
   ],
   "source": [
    "print(f\"{Fore.GREEN}------------------- The firsst NN prototype is completed. ------------------- \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
