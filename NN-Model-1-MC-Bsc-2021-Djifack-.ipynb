{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bachelorarbait-2021\n",
    "# Author: Michel Bosris Djifack\n",
    "# Matrikelnummer:7103963"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A sentiment analysis program will be designed to make predictions about the english written expressions to rank them and \n",
    "# determine which ones are in favor of the coronavirus vaccine and which are against.\n",
    "# Method: NN (Neural Network)\n",
    "\n",
    "# ===> three classes (Multiclass) with NN\n",
    "\n",
    "\n",
    "# NN-Prototype-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m------------------- All libraries have been successfully imported.------------------- \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "import all libraries (Math-function, diagram-visualisation, regex, document and NLP functions)\n",
    "\n",
    "\"\"\"\n",
    "# NLP Libraries\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, LSTM, Embedding, Dropout, Activation, BatchNormalization,Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "\n",
    "# Math, documents and visualisation Libraries\n",
    "import numpy as np\n",
    "import preprocessor as p\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import colorama\n",
    "from colorama import Fore\n",
    "\n",
    "print(f\"{Fore.MAGENTA}------------------- All libraries have been successfully imported.------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m------------------- The document has been successfully uploaded. ------------------- \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "upload The dataset, open it and check it.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# upload the DataSet\n",
    "file = open('covidVaccineAdvice_mldata_d1.csv',encoding=\"utf-8\")\n",
    "data = pd.read_csv(file,delimiter=\";\")\n",
    "print(f\"{Fore.MAGENTA}------------------- The document has been successfully uploaded. ------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m -------------------  overview of the dataset ------------------- \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>We need to be vaccinated to protect all person...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>it is a pleasure to see how the govement are w...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>The most popular vaccine that i know is Modern...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Of course we need to be vaccinated if we want ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            message sentiment\n",
       "0   1  We need to be vaccinated to protect all person...  Positive\n",
       "1   2  it is a pleasure to see how the govement are w...  Positive\n",
       "2   3                                          Negative   Negative\n",
       "3   4  The most popular vaccine that i know is Modern...  Positive\n",
       "4   5  Of course we need to be vaccinated if we want ...  Positive"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the document header.\n",
    "print(f\"{Fore.MAGENTA} -------------------  overview of the dataset ------------------- \")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m -------------------  The document has 1023 rows and 3 columns ------------------- \n"
     ]
    }
   ],
   "source": [
    "#count the data set\n",
    "print(f\"{Fore.MAGENTA} -------------------  The document has\", data.shape[0], \"rows and\", data.shape[1],\"columns ------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m------------------- the number and percentage of missing values in the data set. ------------------- \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>message</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count  Percentage\n",
       "id             0         0.0\n",
       "message        0         0.0\n",
       "sentiment      0         0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check missing values\n",
    "count =data.isnull().sum().sort_values(ascending=False)\n",
    "percentage =((data.isnull().sum()/len(data)*100)).sort_values(ascending=False)\n",
    "missing_data =pd.concat([count,percentage],axis=1,keys=['count','Percentage'])\n",
    "\n",
    "print(f\"{Fore.MAGENTA}------------------- the number and percentage of missing values in the data set. ------------------- \")\n",
    "missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#check the Distributin of Sentiments\n",
    "category = ['Negative','Neutral','Positive']\n",
    "values = [data.sentiment.str.count(\"Negative\").sum(),data.sentiment.str.count(\"Neutral\").sum(),data.sentiment.str.count(\"Positive\").sum()]\n",
    "plt.pie(values, labels= category,autopct ='%0.2f%%')\n",
    "plt.title('------------------- percentage Distribution by Sentiment Category -------------------',fontsize=20,color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m------------------- Special characters and punctuation cleaning operations completed. ------------------- \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "We will now clean the data by removing the special characters.\n",
    "\n",
    "\"\"\"\n",
    "#set up punctuations we want to be replaced\n",
    "REPLACE_NO_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\')|(\\?)|(\\,)|(\\\")|(\\|)|(\\()|(\\))|(\\[)|(\\])|(\\%)|(\\$)|(\\>)|(\\<)|(\\{)|(\\})|(\\=)|(\\#)|(\\§)\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s/><br\\s/?)|(-)|(/)|(:).\")\n",
    "print(f\"{Fore.BLUE}------------------- Special characters and punctuation cleaning operations completed. ------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m------------------- preparation of the cleaning functions completed. ------------------- \n"
     ]
    }
   ],
   "source": [
    "# custum function to clean the dataset (combining tweet_preprocessor and reguar expression)\n",
    "def clean_tweets(df):\n",
    "  tempArr = []\n",
    "  for line in df:\n",
    "    # send to tweet_processor\n",
    "    tmpL = p.clean(line)\n",
    "    # remove puctuation\n",
    "    tmpL = REPLACE_NO_SPACE.sub(\"\", tmpL.lower()) # convert all tweets to lower cases\n",
    "    tmpL = REPLACE_WITH_SPACE.sub(\" \", tmpL)\n",
    "    tempArr.append(tmpL)\n",
    "  return tempArr\n",
    "\n",
    "print(f\"{Fore.BLUE}------------------- preparation of the cleaning functions completed. ------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m------------------- The message cleaning operation is complete. ------------------- \n"
     ]
    }
   ],
   "source": [
    "# Cleaning up tweets\n",
    "clean_tweet = clean_tweets(data[\"message\"])\n",
    "print(f\"{Fore.BLUE}------------------- The message cleaning operation is complete. ------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m------------------- The clean data column has been successfully added to the dataset. ------------------- \n"
     ]
    }
   ],
   "source": [
    "# append cleaned tweets to the training data\n",
    "clean_tweet = pd.DataFrame(clean_tweet)\n",
    "data[\"clean\"] = clean_tweet\n",
    "print(f\"{Fore.BLUE}------------------- The clean data column has been successfully added to the dataset. ------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m------------------- overview of the dataset with the clean_data column. ------------------- \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>We need to be vaccinated to protect all person...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>we need to be vaccinated to protect all person...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>it is a pleasure to see how the govement are w...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>it is a pleasure to see how the govement are w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>The most popular vaccine that i know is Modern...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>the most popular vaccine that i know is modern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Of course we need to be vaccinated if we want ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>of course we need to be vaccinated if we want ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            message sentiment  \\\n",
       "0   1  We need to be vaccinated to protect all person...  Positive   \n",
       "1   2  it is a pleasure to see how the govement are w...  Positive   \n",
       "2   3                                          Negative   Negative   \n",
       "3   4  The most popular vaccine that i know is Modern...  Positive   \n",
       "4   5  Of course we need to be vaccinated if we want ...  Positive   \n",
       "\n",
       "                                               clean  \n",
       "0  we need to be vaccinated to protect all person...  \n",
       "1  it is a pleasure to see how the govement are w...  \n",
       "2                                           negative  \n",
       "3  the most popular vaccine that i know is modern...  \n",
       "4  of course we need to be vaccinated if we want ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare the cleaned and uncleaned tweets\n",
    "print(f\"{Fore.BLUE}------------------- overview of the dataset with the clean_data column. ------------------- \")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function who help to count unique words\n",
    "\n",
    "def wordCount(text):\n",
    "    count = Counter()\n",
    "    for i in text.values:\n",
    "        for word in i.split():\n",
    "            count[word]+=1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m------------------- The column 'clean' contains:  2540  unique words ------------------- \n"
     ]
    }
   ],
   "source": [
    "# count the number of unique words contained in the set of cleaned expressions. \n",
    "text= data.clean\n",
    "counter = wordCount(text)\n",
    "print(f\"{Fore.BLUE}------------------- The column 'clean' contains: \",len(counter),\" unique words ------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive [0 0 1]\n",
      "Positive [0 0 1]\n",
      "Negative [1 0 0]\n",
      "Positive [0 0 1]\n",
      "Positive [0 0 1]\n",
      "Neutral [0 1 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert sentiment into numeric value\n",
    "y = pd.get_dummies(data['sentiment']).values\n",
    "[print(data['sentiment'][i], y[i]) for i in range(0,6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m------------------- The data was successfully split. ------------------- \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "In this section, we will divide the file (the 'clean' column) \n",
    "into two parts: one part for training and one part for testing.\n",
    "\n",
    "X_train ==> train_sentences\n",
    "X_test ==> test_sentences\n",
    "y_train ==> train_labels\n",
    "y_test ==> test_labels\n",
    "\n",
    "\"\"\"\n",
    "X = data['clean']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "print(f\"{Fore.GREEN}------------------- The data was successfully split. ------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m------------------- Operations completed. ------------------- \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "We will now define the maximum length of a sentence in terms of the number of words it can contain.\n",
    "But first, we define the word count as the number of unique words.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# define the number of words.\n",
    "num_words = len(counter)\n",
    "# maximum number of words in a sentence.\n",
    "max_length = 42\n",
    "print(f\"{Fore.GREEN}------------------- Operations completed. ------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m------------------- tokenization process complete. ------------------- \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "We will now tokenize the text ('clean' column):\n",
    "This means that a unique number is associated with each unique word in the text.\n",
    "\"\"\"\n",
    "\n",
    "tokenizer = Tokenizer(num_words=num_words, split=\" \")\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "print(f\"{Fore.GREEN}------------------- tokenization process complete. ------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m------------------- visualization of the result obtained after tokenization. ------------------- \n",
      "\u001b[30m {'the': 1, 'to': 2, 'i': 3, 'vaccine': 4, 'is': 5, 'not': 6, 'of': 7, 'and': 8, 'a': 9, 'it': 10, 'vaccinated': 11, 'in': 12, 'for': 13, 'vaccines': 14, 'covid': 15, 'be': 16, 'are': 17, 'that': 18, 'this': 19, 'will': 20, 'get': 21, 'my': 22, 'have': 23, 'do': 24, 'am': 25, 'so': 26, 'we': 27, 'you': 28, 'as': 29, 'no': 30, 'all': 31, 'with': 32, 'but': 33, 'people': 34, '19': 35, 'us': 36, 'they': 37, 'or': 38, 'on': 39, 'at': 40, 'first': 41, 'if': 42, 'me': 43, 'vaccination': 44, 'side': 45, 'take': 46, 'there': 47, 'effects': 48, 'who': 49, 'want': 50, 'pfizer': 51, 'think': 52, 'more': 53, 'was': 54, 'good': 55, 'about': 56, 'can': 57, 'because': 58, 'has': 59, 'should': 60, 'been': 61, 'these': 62, 'just': 63, 'against': 64, 'our': 65, 'virus': 66, 'one': 67, 'like': 68, 'what': 69, 'by': 70, 'dose': 71, 'everyone': 72, 'does': 73, 'any': 74, 'today': 75, 'getting': 76, 'after': 77, 'doses': 78, 'their': 79, 'when': 80, 'your': 81, 'from': 82, 'very': 83, 'would': 84, 'go': 85, 'know': 86, 'why': 87, 'an': 88, 'time': 89, 'only': 90, 'now': 91, 'make': 92, 'than': 93, 'many': 94, 'still': 95, 'need': 96, 'them': 97, 'those': 98, 'got': 99, 'lives': 100, 'going': 101, 'without': 102, 'did': 103, 'being': 104, 'had': 105, 'let': 106, 'received': 107, 'world': 108, 'well': 109, 'never': 110, 'other': 111, 'stop': 112, 'health': 113, 'how': 114, 'much': 115, 'out': 116, 'up': 117, 'free': 118, 'disease': 119, 'two': 120, 'vaccinate': 121, 'enough': 122, 'even': 123, 'trust': 124, 'thing': 125, 'really': 126, 'were': 127, 'life': 128, 'thank': 129, 'which': 130, 'risk': 131, 'coronavirus': 132, 'years': 133, 'some': 134, 'money': 135, 'pandemic': 136, 'live': 137, 'companies': 138, 'children': 139, 'also': 140, 'most': 141, 'case': 142, 'new': 143, 'way': 144, 'believe': 145, 'injection': 146, 'say': 147, 'prices': 148, 'save': 149, 'important': 150, 'day': 151, 'effective': 152, 'see': 153, 'safe': 154, 'nothing': 155, 'possible': 156, 'better': 157, 'biontech': 158, 'thanks': 159, 'before': 160, 'bad': 161, 'cannot': 162, 'protect': 163, 'moderna': 164, 'long': 165, 'wait': 166, 'soon': 167, 'yes': 168, 'end': 169, 'sure': 170, 'happy': 171, 'choice': 172, 'done': 173, 'family': 174, 'too': 175, 'corona': 176, 'yet': 177, 'great': 178, 'use': 179, 'its': 180, 'please': 181, 'finally': 182, 'able': 183, 'must': 184, 'afraid': 185, 'again': 186, 'caign': 187, 'anyone': 188, 'receive': 189, 'prevent': 190, 'allergic': 191, 'normal': 192, 'year': 193, 'second': 194, 'vaccinations': 195, 'news': 196, 'feeling': 197, 'consequences': 198, 'since': 199, 'order': 200, 'propaganda': 201, 'whether': 202, 'maybe': 203, 'less': 204, 'real': 205, 'ones': 206, 'problem': 207, 'made': 208, 'safety': 209, 'population': 210, 'work': 211, 'astrazeneca': 212, 'pharmaceutical': 213, 'useful': 214, 'given': 215, 'find': 216, 'then': 217, 'same': 218, 'country': 219, 'covid19': 220, 'days': 221, 'big': 222, 'could': 223, 'myself': 224, 'here': 225, 'laboratories': 226, 'far': 227, 'mrna': 228, 'cure': 229, 'die': 230, 'person': 231, 'public': 232, 'quickly': 233, 'point': 234, 'might': 235, 'severe': 236, 'others': 237, 'makes': 238, 'million': 239, 'hope': 240, 'patients': 241, 'future': 242, 'shot': 243, 'reactions': 244, 'g': 245, 'around': 246, 'taken': 247, 'tests': 248, 'immunity': 249, 'anti': 250, 'into': 251, 'said': 252, 'care': 253, 'developed': 254, 'turn': 255, 'encourage': 256, 'give': 257, 'serious': 258, 'emergency': 259, 'drug': 260, 'immune': 261, 'mind': 262, 'fine': 263, 'hours': 264, 'best': 265, 'both': 266, 'fear': 267, 'decision': 268, 'come': 269, 'every': 270, 'last': 271, 'rather': 272, 'fed': 273, 'effect': 274, 'decide': 275, 'excited': 276, 'ready': 277, 'science': 278, 'deaths': 279, 'always': 280, 'next': 281, 'own': 282, 'government': 283, 'media': 284, 'testing': 285, 'friends': 286, 'help': 287, 'taking': 288, 'yourself': 289, 'information': 290, 'vaccin': 291, 'course': 292, 'term': 293, 'young': 294, 'ive': 295, 'over': 296, 'five': 297, 'danger': 298, 'scientists': 299, 'lot': 300, 'reaction': 301, 'back': 302, 'through': 303, 'human': 304, 'rid': 305, 'question': 306, 'food': 307, 'stock': 308, 'protein': 309, 'using': 310, 'interested': 311, 'negative': 312, 'while': 313, 'available': 314, 'variants': 315, 'remain': 316, 'injected': 317, 'respect': 318, 'barrier': 319, 'personally': 320, 'almost': 321, 'frankly': 322, 'shows': 323, 'kind': 324, 'solution': 325, 'countries': 326, 'few': 327, 'found': 328, 'im': 329, 'business': 330, 'necessary': 331, 'his': 332, 'week': 333, 'put': 334, 'fact': 335, 'old': 336, 'test': 337, 'reduce': 338, 'matter': 339, 'stay': 340, 'arrived': 341, 'hospital': 342, 'millions': 343, 'keep': 344, 'employees': 345, 'effectiveness': 346, 'right': 347, 'nice': 348, 'fda': 349, 'approved': 350, 'continue': 351, 'variant': 352, 'research': 353, 'anything': 354, 'grateful': 355, 'natural': 356, 'ourselves': 357, 'down': 358, 'politicians': 359, 'shame': 360, 'such': 361, 'works': 362, 'reason': 363, 'st': 364, 'later': 365, 'administration': 366, 'waiting': 367, 'wonder': 368, 'rollout': 369, 'update': 370, 'where': 371, 'spread': 372, 'fake': 373, 'according': 374, 'gestures': 375, 'least': 376, 'until': 377, 'months': 378, 'ago': 379, 'refuse': 380, 'guinea': 381, 'avoid': 382, 'remember': 383, 'supermarket': 384, 'system': 385, 'social': 386, 'kiss': 387, 'therefore': 388, 'africa': 389, 'ingredients': 390, 'leave': 391, 'certainly': 392, 'data': 393, 'something': 394, 'part': 395, 'choose': 396, 'developing': 397, 'form': 398, 'afterwards': 399, 'comes': 400, 'night': 401, 'moment': 402, 'approve': 403, 'produce': 404, 'light': 405, 'wear': 406, 'set': 407, 'follow': 408, 'panic': 409, 'authorities': 410, 'prefer': 411, 'present': 412, 'working': 413, 'except': 414, 'feel': 415, 'gives': 416, 'nurse': 417, 'seen': 418, 'administering': 419, 'tell': 420, 'coming': 421, 'doctors': 422, 'between': 423, 'idea': 424, 'explain': 425, 'clear': 426, 'alone': 427, 'together': 428, 'gets': 429, 'global': 430, 'share': 431, 'situation': 432, 'allow': 433, 'administered': 434, 't': 435, 'opportunity': 436, 'adverse': 437, 'happens': 438, 'difficult': 439, 'hesitate': 440, 'thats': 441, 'contagious': 442, 'reliable': 443, 'drugs': 444, 'rate': 445, 'americans': 446, 'morning': 447, 'treatment': 448, 'imagine': 449, 'humanity': 450, 'freedom': 451, 'crisis': 452, 'johnson': 453, 'consumer': 454, 'company': 455, 'ahead': 456, 'says': 457, 'tested': 458, 'healthcare': 459, 'lie': 460, 'making': 461, 'quite': 462, 'diseases': 463, 'story': 464, 'pharmacists': 465, 'essential': 466, 'true': 467, 'saved': 468, 'harmful': 469, 'shown': 470, 'unexpected': 471, 'impossible': 472, 'tired': 473, 'approves': 474, 'response': 475, 'positive': 476, 'body': 477, 'mother': 478, 'dont': 479, 'cases': 480, 'another': 481, 'called': 482, 'charge': 483, 'easier': 484, 'based': 485, 'spike': 486, 'experimental': 487, 'post': 488, 'view': 489, 'three': 490, 'return': 491, 'bosses': 492, 'favour': 493, 'parents': 494, 'times': 495, 'ever': 496, 'option': 497, 'race': 498, 'create': 499, 'stand': 500, 'usa': 501, 'word': 502, 'realy': 503, 'pharma': 504, 'experts': 505, 'show': 506, 'simply': 507, 'means': 508, 'force': 509, 'travel': 510, 'longer': 511, 'thinking': 512, 'honest': 513, 'opinion': 514, 'bullshit': 515, 'trump': 516, 'suffer': 517, 'difference': 518, 'develop': 519, 'mean': 520, 'past': 521, 'death': 522, 'receiving': 523, 'technology': 524, 'talking': 525, 'false': 526, 'him': 527, 'exle': 528, 'hear': 529, 'cancer': 530, 'otherwise': 531, 'infected': 532, 'known': 533, 'contamination': 534, 'participate': 535, 'affraid': 536, 'seems': 537, 'scammers': 538, 'changed': 539, 'yesterday': 540, 'wary': 541, 'offering': 542, 'kits': 543, 'etc': 544, 'raise': 545, 'private': 546, 'naturally': 547, 'allowed': 548, 'took': 549, 'rna': 550, 'change': 551, 'zero': 552, 'governments': 553, 'bit': 554, 'historic': 555, 'pfizers': 556, 'saves': 557, 'supply': 558, 'hospitals': 559, 'room': 560, 'access': 561, 'price': 562, 'citizen': 563, 'happened': 564, 'scary': 565, 'type': 566, 'large': 567, 'loved': 568, 'grocery': 569, 'talk': 570, 'third': 571, 'trials': 572, 'bill': 573, 'gates': 574, 'wants': 575, 'quality': 576, 'affected': 577, 'problems': 578, 'little': 579, 'mass': 580, 'told': 581, 'cause': 582, 'delta': 583, 'doubt': 584, 'products': 585, 'affect': 586, 'fast': 587, 'fully': 588, 'support': 589, 'strong': 590, 'off': 591, 'pseudo': 592, 'during': 593, 'sheep': 594, 'sick': 595, 'cost': 596, 'control': 597, 'via': 598, 'already': 599, 'ridiculous': 600, 'medical': 601, 'likely': 602, 'each': 603, 'dying': 604, 'six': 605, 'he': 606, 'industry': 607, 'month': 608, 'state': 609, 'possibility': 610, 'stable': 611, 'dr': 612, 'scams': 613, 'home': 614, 'arrive': 615, 'measures': 616, 'press': 617, 'rich': 618, 'beginning': 619, 'themselves': 620, 'risks': 621, 'democrats': 622, 'affordable': 623, 'weeks': 624, 'including': 625, 'away': 626, 'call': 627, 'used': 628, 'doing': 629, 'easing': 630, 'concerns': 631, 'whole': 632, 'hell': 633, 'damn': 634, 'whats': 635, 'poisson': 636, 'success': 637, 'local': 638, 'site': 639, 'wouldnt': 640, 'currently': 641, 'name': 642, 'suggests': 643, 'predict': 644, 'house': 645, 'proud': 646, 'teach': 647, 'cells': 648, 'trigger': 649, 'contribute': 650, 'thankful': 651, 'prevention': 652, 'asked': 653, 'experience': 654, 'january': 655, 'june': 656, 'residents': 657, 'created': 658, 'evidence': 659, 'linked': 660, 'lockdown': 661, 'ways': 662, 'suffering': 663, 'she': 664, 'assume': 665, 'calling': 666, 'certainty': 667, 'protects': 668, 'fighter': 669, 'planes': 670, 'missiles': 671, 'weapons': 672, 'none': 673, 'pure': 674, 'labs': 675, 'hopefully': 676, 'regarding': 677, 'pigs': 678, 'distancing': 679, 'grandmother': 680, 'beat': 681, 'pleased': 682, 'pretty': 683, 'wish': 684, 'inflated': 685, 'article': 686, 'low': 687, 'aware': 688, 'god': 689, 're': 690, 'controlled': 691, 'appointment': 692, 'researchers': 693, 'ok': 694, 'theres': 695, 'unnecessary': 696, 'purposes': 697, 'responsible': 698, 'deplore': 699, 'animals': 700, 'prevents': 701, 'hospitalized': 702, 'worse': 703, 'lets': 704, 'daughter': 705, 'giving': 706, 'woman': 707, 'uk': 708, 'excellent': 709, 'understand': 710, 'hiv': 711, 'adapt': 712, 'tunnel': 713, 'agree': 714, 'toll': 715, 'stopped': 716, 'respecting': 717, 'empty': 718, 'green': 719, 'caused': 720, 'things': 721, 'nobody': 722, 'object': 723, 'disadvantages': 724, 'hands': 725, 'mouth': 726, 'efficacy': 727, 'convinced': 728, 'beautiful': 729, 'lucky': 730, 'yay': 731, 'protection': 732, 'advance': 733, 'per': 734, 'nonsense': 735, 'leading': 736, 'resuscitation': 737, 'ppe': 738, 'socially': 739, 'deadly': 740, 'toxic': 741, 'super': 742, 'profit': 743, 'stories': 744, 'rush': 745, 'matters': 746, 'chinese': 747, 'billions': 748, 'actually': 749, 'causing': 750, 'allergy': 751, 'hard': 752, 'pig': 753, 'announced': 754, 'may': 755, 'ensure': 756, 'heres': 757, 'looking': 758, 'suspicious': 759, 'personal': 760, 'strange': 761, 'goes': 762, 'poison': 763, 'moderne': 764, 'older': 765, 'rights': 766, 'authorizes': 767, 'injections': 768, 'importance': 769, 'honestly': 770, 'european': 771, 'regulator': 772, 'adolescents': 773, 'interesting': 774, 'speed': 775, 'feels': 776, 'obligation': 777, 'cobbled': 778, 'joe': 779, 'biden': 780, 'her': 781, 'scale': 782, 'china': 783, 'west': 784, 'chain': 785, 'putting': 786, 'wife': 787, 'economy': 788, 'worst': 789, 'confinement': 790, 'high': 791, 'vulnerable': 792, 'commercial': 793, 'spirit': 794, 'biontechs': 795, 'investigating': 796, 'don': 797, 'neutral': 798, 'knows': 799, 'try': 800, 'touch': 801, 'gene': 802, 'therapy': 803, 'chip': 804, 'prowess': 805, 'self': 806, 'stores': 807, 'top': 808, 'patents': 809, 'pleasure': 810, 'consent': 811, 'canada': 812, 'decided': 813, 'peace': 814, 'face': 815, 'mask': 816, 's': 817, 'sent': 818, 'experiencing': 819, 'start': 820, 'common': 821, 'frightening': 822, 'man': 823, 'gonna': 824, 'holiday': 825, 'cant': 826, 'herd': 827, 'containment': 828, 'conspiracy': 829, 'destroy': 830, 'lose': 831, 'unsafe': 832, 'hesitation': 833, 'questions': 834, 'acquired': 835, 'inject': 836, 'publicity': 837, 'warned': 838, 'summary': 839, 'resistant': 840, 'sufficiently': 841, 'vaxxers': 842, 'school': 843, 'achieve': 844, 'though': 845, 'taxpayers': 846, 'staff': 847, 'fresh': 848, 'usually': 849, 'started': 850, 'russian': 851, 'tomorrow': 852, 'vaccinating': 853, 'worried': 854, 'mutation': 855, 'production': 856, 'angry': 857, 'involved': 858, 'programme': 859, 'masks': 860, 'distributed': 861, 'across': 862, 'gov': 863, 'majority': 864, 'fighting': 865, 'ass': 866, 'scientific': 867, 'potential': 868, 'needs': 869, 'wont': 870, 'community': 871, 'nhs': 872, 'lost': 873, 'member': 874, 'interest': 875, 'listening': 876, 'christmas': 877, 'debate': 878, 'pity': 879, 'invented': 880, 'advice': 881, 'neighbours': 882, 'rest': 883, 'latest': 884, 'mine': 885, 'peoples': 886, 'everybody': 887, 'greatest': 888, 'technological': 889, 'begins': 890, 'fought': 891, 'eat': 892, 'offer': 893, 'treatments': 894, 'program': 895, 'arm': 896, 'friday': 897, 'careful': 898, 'confident': 899, 'everything': 900, 'capitalism': 901, 'plants': 902, 'confidence': 903, 'advise': 904, 'wiser': 905, 'apparently': 906, 'amazing': 907, 'employer': 908, 'listen': 909, 'united': 910, 'hot': 911, 'power': 912, 'door': 913, 'history': 914, 'shape': 915, 'step': 916, 'fight': 917, 'hand': 918, 'sanitizer': 919, 'anyway': 920, 'probably': 921, 'flexible': 922, 'broken': 923, 'passport': 924, 'seem': 925, 'receives': 926, 'anyways': 927, 'tetanus': 928, 'once': 929, 'read': 930, 'definitely': 931, 'evil': 932, 'development': 933, 'approval': 934, 'epidemic': 935, 'specialy': 936, 'imperative': 937, 'london': 938, 'suffered': 939, 'scam': 940, 'hesitating': 941, 'law': 942, 'traumatic': 943, 'thermally': 944, 'direct': 945, 'impact': 946, 'workers': 947, 'leaky': 948, 'transmission': 949, 'shed': 950, 'harm': 951, 'report': 952, 'someone': 953, 'contact': 954, 'senior': 955, 'keeping': 956, 'favor': 957, 'shipments': 958, 'illness': 959, 'sunday': 960, 'warning': 961, 'conditions': 962, 'rodents': 963, 'legacy': 964, 'registered': 965, 'recommended': 966, 'treated': 967, 'starting': 968, 'sudden': 969, 'inspire': 970, 'bacterial': 971, 'damage': 972, 'sell': 973, 'pessimistic': 974, 'ability': 975, 'defend': 976, 'rotten': 977, 'bribing': 978, 'york': 979, 'city': 980, 'reports': 981, 'oripire': 982, 'record': 983, 'intriguing': 984, 'outcome': 985, 'patient': 986, 'bion': 987, 'men': 988, 'treats': 989, 'leaving': 990, 'mild': 991, 'moderate': 992, 'selection': 993, 'collect': 994, 'efficient': 995, 'optimistic': 996, 'ontarian': 997, 'minutes': 998, 'p': 999, 'authorization': 1000, 'developer': 1001, 'day3': 1002, 'region': 1003, 'foreseen': 1004, 'confined': 1005, 'stepping': 1006, 'team': 1007, 'approvals': 1008, 'expects': 1009, 'shots': 1010, 'december': 1011, 'risking': 1012, 'mankind': 1013, 'smallpox': 1014, 'wreaked': 1015, 'havoc': 1016, 'centuries': 1017, 'earth': 1018, 'chance': 1019, 'armor': 1020, 'nd': 1021, 'ehpad': 1022, 'testify': 1023, 'alive': 1024, 'dubai': 1025, 'creation': 1026, 'atrocities': 1027, 'adjusted': 1028, 'dominant': 1029, 'jennifer': 1030, 'haller': 1031, 'concentrate': 1032, 'gild': 1033, 'monthly': 1034, 'higher': 1035, 'appears': 1036, 'positioned': 1037, 'takes': 1038, 'reliability': 1039, 'necessity': 1040, 'marginal': 1041, 'nuclear': 1042, 'courage': 1043, 'totally': 1044, 'irresponsible': 1045, 'starvation': 1046, 'malnutrition': 1047, 'invention': 1048, 'minimal': 1049, 'immense': 1050, 'preferenceany': 1051, 'hcw': 1052, 'assuage': 1053, 'anxiety': 1054, 'liberty': 1055, 'hey': 1056, 'terfs': 1057, 'heard': 1058, 'trans': 1059, 'vax': 1060, 'lick': 1061, 'counters': 1062, 'transit': 1063, 'seats': 1064, 'boose': 1065, 'tough': 1066, 'myth': 1067, 'terf': 1068, 'meet': 1069, 'glad': 1070, 'medicin': 1071, 'accept': 1072, 'increase': 1073, 'restrictions': 1074, 'decrease': 1075, 'look': 1076, 'israel': 1077, 'conscious': 1078, 'level': 1079, 'eventually': 1080, 'm': 1081, 'several': 1082, 'tinkered': 1083, 'marketed': 1084, 'dead': 1085, 'proposals': 1086, 'syringes': 1087, 'clever': 1088, 'comparison': 1089, 'recherches': 1090, 'status': 1091, 'proven': 1092, 'increasing': 1093, 'expenditure': 1094, 'suppose': 1095, 'documents': 1096, 'id': 1097, 'neonuclear': 1098, 'desired': 1099, 'constraints': 1100, 'surreal': 1101, 'dropping': 1102, 'announce': 1103, 'experiments': 1104, 'join': 1105, 'ranks': 1106, 'skeptics': 1107, 'savinghuman': 1108, 'clue': 1109, 'relieved': 1110, 'fo': 1111, 'historical': 1112, 'unlike': 1113, 'pregnant': 1114, 'wonderful': 1115, 'speaking': 1116, 'president': 1117, 'pushed': 1118, 'everywhere': 1119, 'results': 1120, 'entire': 1121, 'atshmatic': 1122, 'mucus': 1123, 'versus': 1124, 'further': 1125, 'incentive': 1126, 'flu': 1127, 'proper': 1128, 'bra': 1129, 'confirmed': 1130, 'above': 1131, 'incredible': 1132, 'emmanuel': 1133, 'macron': 1134, 'himself': 1135, 'images': 1136, 'broadcast': 1137, 'television': 1138, 'paranoid': 1139, 'litteraly': 1140, 'causes': 1141, 'shortage': 1142, 'phew': 1143, 'slowness': 1144, 'caigns': 1145, 'brussels': 1146, 'bureaucracy': 1147, 'move': 1148, 'ceo': 1149, 'firsti': 1150, 'takeanother': 1151, 'advantages': 1152, 'outweigh': 1153, 'properly': 1154, 'washed': 1155, 'nose': 1156, 'hate': 1157, 'insisting': 1158, 'wors': 1159, 'baby': 1160, 'extent': 1161, 'figures': 1162, 'scare': 1163, 'coffin': 1164, 'harmless': 1165, 'comorbidity': 1166, 'seriously': 1167, 'deal': 1168, 'chemo': 1169, 'alzheimers': 1170, 'parkinsons': 1171, 'aids': 1172, 'miracle': 1173, 'kissed': 1174, 'goodbye': 1175, 'distance': 1176, 'wave': 1177, 'hostile': 1178, 'ummc': 1179, 'againts': 1180, 'virusbecause': 1181, 'vacination': 1182, 'number': 1183, 'persones': 1184, 'drasticaly': 1185, 'reduced': 1186, 'distant': 1187, 'manufacturers': 1188, 'dictatorship': 1189, 'sue': 1190, 'batch': 1191, 'congratulations': 1192, 'tourists': 1193, 'bring': 1194, 'usual': 1195, 'discussing': 1196, 'nor': 1197, 'limit': 1198, 'surrounding': 1199, 'aka': 1200, 'dizzy': 1201, 'faints': 1202, 'tennessee': 1203, 'hospita': 1204, 'polyethylene': 1205, 'glycol': 1206, 'african': 1207, 'tiktok': 1208, 'losing': 1209, 'minds': 1210, 'observe': 1211, 'died': 1212, 'manufactured': 1213, 'helped': 1214, 'sydney': 1215, 'watching': 1216, 'smooth': 1217, 'operating': 1218, 'machine': 1219, 'prisoner': 1220, 'eligible': 1221, 'calls': 1222, 'emails': 1223, 'visitors': 1224, 'asking': 1225, 'usernames': 1226, 'pasords': 1227, 'links': 1228, 'react': 1229, 'desperately': 1230, 'sign': 1231, 'petition': 1232, 'demanding': 1233, 'reasearch': 1234, 'condition': 1235, 'cheap': 1236, 'bothered': 1237, 'bosnia': 1238, 'sinovac': 1239, 'confused': 1240, 'contradictory': 1241, 'circulating': 1242, 'supporter': 1243, 'disparity': 1244, 'came': 1245, 'respected': 1246, 'decisions': 1247, 'difficulty': 1248, 'picking': 1249, 'solved': 1250, 'operator': 1251, 'indeed': 1252, 'retrovirus': 1253, 'sinopharm': 1254, 'shitty': 1255, 'pretend': 1256, 'enrouged': 1257, 'doctor': 1258, 'propagation': 1259, 'union': 1260, 'capacity': 1261, 'resist': 1262, 'forget': 1263, 'tragic': 1264, 'episode': 1265, 'century': 1266, 'recover': 1267, 'exciting': 1268, 'misinformation': 1269, 'believing': 1270, 'ruining': 1271, 'prospect': 1272, 'delaware': 1273, 'failed': 1274, 'deliver': 1275, 'promises': 1276, 'dit': 1277, 'safest': 1278, 'beneficial': 1279, 'early': 1280, 'suspicion': 1281, 'mistrust': 1282, 'holding': 1283, 'deliveries': 1284, 'major': 1285, 'producing': 1286, 'banning': 1287, 'exports': 1288, 'waking': 1289, 'pressure': 1290, 'commission': 1291, 'eu': 1292, 'happiest': 1293, 'texting': 1294, 'shes': 1295, 'yours': 1296, 'useless': 1297, 'crowded': 1298, 'rots': 1299, 'opt': 1300, 'monopolies': 1301, 'unaffordable': 1302, 'amoral': 1303, 'dangerously': 1304, 'stupid': 1305, 'bc': 1306, 'defeat': 1307, 'smells': 1308, 'war': 1309, 'concretely': 1310, 'gain': 1311, 'motivates': 1312, 'inventors': 1313, 'fall': 1314, 'flies': 1315, 'privileged': 1316, 'offered': 1317, 'itll': 1318, 'handled': 1319, 'modernas': 1320, 'joins': 1321, 'battle': 1322, 'single': 1323, 'arriving': 1324, 'departure': 1325, 'guaranteed': 1326, 'imagined': 1327, 'lack': 1328, 'hindsight': 1329, 'annoyed': 1330, 'proportion': 1331, 'disorders': 1332, 'whereas': 1333, 'hardly': 1334, 'honored': 1335, 'gettin': 1336, 'whitout': 1337, 'contains': 1338, 'pristine': 1339, 'miss': 1340, 'implore': 1341, 'trusts': 1342, 'republic': 1343, 'saturated': 1344, 'deprogramming': 1345, 'catastrophic': 1346, 'store': 1347, 'employee': 1348, 'respectfully': 1349, 'request': 1350, 'truck': 1351, 'drivers': 1352, 'managers': 1353, 'asap': 1354, 'continuation': 1355, 'desolation': 1356, 'bottom': 1357, 'billionaires': 1358, 'naivety': 1359, 'gone': 1360, 'deceived': 1361, 'sorry': 1362, 'volunteer': 1363, 'nights': 1364, 'shift': 1365, 'messing': 1366, 'heads': 1367, 'uphow': 1368, 'ride': 1369, 'pfeizer': 1370, 'slip': 1371, 'animal': 1372, 'warns': 1373, 'booked': 1374, 'explaining': 1375, 'mot': 1376, 'saw': 1377, 'presentation': 1378, 'jarvits': 1379, 'centre': 1380, 'superb': 1381, 'pieces': 1382, 'email': 1383, 'similar': 1384, 'besides': 1385, 'officially': 1386, 'helps': 1387, 'meanwhile': 1388, 'significant': 1389, 'releases': 1390, 'als': 1391, 'kids': 1392, 'towards': 1393, 'previous': 1394, 'advised': 1395, 'energy': 1396, 'shop': 1397, 'restaurant': 1398, 'cameroon': 1399, 'measure': 1400, 'barier': 1401, 'worlds': 1402, 'pension': 1403, 'rd': 1404, 'th': 1405, 'multinational': 1406, 'fuss': 1407, 'l': 1408, 'c': 1409, 'paul': 1410, 'arose': 1411, 'fauci': 1412, 'aner': 1413, 'childrens': 1414, 'defense': 1415, 'peaceful': 1416, 'playing': 1417, 'knew': 1418, 'infection': 1419, 'fail': 1420, 'quarterly': 1421, 'whatever': 1422, 'immunizes': 1423, 'hole': 1424, 'decates': 1425, 'deseases': 1426, 'messenger': 1427, 'advanced': 1428, 'eager': 1429, 'drama': 1430, 'wonders': 1431, 'certificate': 1432, 'fly': 1433, 'cruise': 1434, 'subway': 1435, 'concert': 1436, 'bar': 1437, 'expire': 1438, 'mockery': 1439, 'encouraged': 1440, 'procurement': 1441, 'pay': 1442, 'r': 1443, 'd': 1444, 'manufacturing': 1445, 'makers': 1446, 'british': 1447, 'airways': 1448, 'suspend': 1449, 'wanting': 1450, 'encouraging': 1451, 'bringing': 1452, 'air': 1453, 'played': 1454, 'role': 1455, 'women': 1456, 'technique': 1457, 'survival': 1458, 'costs': 1459, 'clearly': 1460, 'operation': 1461, 'molecules': 1462, 'treat': 1463, 'sham': 1464, '4': 1465, 'announces': 1466, 'reassure': 1467, 'harmlessness': 1468, 'expected': 1469, 'scared': 1470, 'europe': 1471, 'okay': 1472, 'sceptical': 1473, 'russia': 1474, 'detected': 1475, 'sfr': 1476, 'unfortunate': 1477, 'normally': 1478, 'study': 1479, 'spends': 1480, 'bothering': 1481, 'insist': 1482, 'vi': 1483, 'sterile': 1484, 'huge': 1485, 'ensuring': 1486, 'tiring': 1487, 'victimisation': 1488, 'secret': 1489, 'deceiving': 1490, 'innocent': 1491, 'choices': 1492, 'cold': 1493, 'county': 1494, 'investor': 1495, 'paywall': 1496, 'warp': 1497, 'speedplease': 1498, 'receivers': 1499, 'momentous': 1500, 'laughing': 1501, 'thought': 1502, 'mandatory': 1503, 'schools': 1504, 'closed': 1505, 'carriers': 1506, 'automatically': 1507, 'enters': 1508, 'bloodstream': 1509, 'happening': 1510, 'noir': 1511, 'thomasall': 1512, 'having': 1513, 'transmitting': 1514, 'credibility': 1515, 'showed': 1516, 'corp': 1517, 'rising': 1518, 'pharmaceuticals': 1519, 'doubled': 1520, 'safeguards': 1521, 'jacking': 1522, 'anesthesia': 1523, 'surgeries': 1524, 'apart': 1525, 'introduced': 1526, 'b': 1527, 'although': 1528, 'designed': 1529, 'threatened': 1530, 'notice': 1531, 'picture': 1532, 'video': 1533, 'actual': 1534, 'four': 1535, 'dread': 1536, 'concussion': 1537, 'percent': 1538, 'saudis': 1539, 'expats': 1540, 'daft': 1541, 'hurts': 1542, 'ears': 1543, 'biggest': 1544, 'nura': 1545, 'emir': 1546, 'festi': 1547, 'brave': 1548, 'competition': 1549, 'recipe': 1550, 'senators': 1551, 'insider': 1552, 'trading': 1553, 'doubles': 1554, 'capitol': 1555, 'hill': 1556, 'folk': 1557, 'council': 1558, 'communicate': 1559, 'warn': 1560, 'society': 1561, 'neither': 1562, 'produced': 1563, 'capitalists': 1564, 'charade': 1565, 'scenario': 1566, 'views': 1567, 'nursing': 1568, 'homes': 1569, 'pennsylvania': 1570, 'prepare': 1571, 'distribut': 1572, 'recalls': 1573, 'supposed': 1574, 'autumn': 1575, 'else': 1576, 'undergo': 1577, 'anymore': 1578, 'merkel': 1579, 'traumatize': 1580, 'refusing': 1581, 'collective': 1582, 'suicide': 1583, 'property': 1584, 'design': 1585, 'incentives': 1586, 'market': 1587, 'ventilators': 1588, 'economists': 1589, 'navigate': 1590, 'moreover': 1591, 'africans': 1592, 'faster': 1593, 'spy': 1594, 'full': 1595, 'list': 1596, 'total': 1597, 'friend': 1598, 'shut': 1599, 'certified': 1600, 'contrary': 1601, 'bravery': 1602, 'pendemia': 1603, 'vehemently': 1604, 'opposed': 1605, 'forms': 1606, 'partly': 1607, 'particularly': 1608, 'helpful': 1609, 'primary': 1610, 'quebec': 1611, 'maimonides': 1612, 'among': 1613, 'seniors': 1614, 'kuwait': 1615, 'patented': 1616, 'jab': 1617, 'beliefs': 1618, 'convictions': 1619, 'elsewhere': 1620, 'fragile': 1621, 'require': 1622, 'catching': 1623, 'humanitarian': 1624, 'freshly': 1625, 'issues': 1626, 'transporting': 1627, 'bogus': 1628, 'kit': 1629, 'assure': 1630, 'reuters': 1631, 'rare': 1632, 'sat': 1633, 'cup': 1634, 'coffee': 1635, 'witness': 1636, 'football': 1637, 'stadium': 1638, 'march': 1639, 'win': 1640, 'highly': 1641, 'risked': 1642, 'job': 1643, 'firefighters': 1644, 'unfortunately': 1645, 'logistics': 1646, 'equipment': 1647, 'needed': 1648, 'astraastrazeneka': 1649, 'w': 1650, 'needle': 1651, 'inserted': 1652, 'becomes': 1653, 'breaking': 1654, 'begin': 1655, 'september': 1656, 'repeat': 1657, 'mistake': 1658, 'jeopardized': 1659, 'consideration': 1660, 'suppository': 1661, 'quiet': 1662, 'arabian': 1663, 'peninsula': 1664, 'humans': 1665, 'funny': 1666, 'absolutely': 1667, 'sometimes': 1668, 'kinda': 1669, 'politicized': 1670, 'play': 1671, 'anyhow': 1672, 'prepping': 1673, 'shipment': 1674, 'sites': 1675, 'forgot': 1676, 'clinical': 1677, 'guide': 1678, 'notgiven': 1679, 'expectedcovid': 1680, 'superior': 1681, 'arms': 1682, 'complications': 1683, 'o': 1684, 'taxes': 1685, 'pisses': 1686, 'iv': 1687, 'usedas': 1688, 'influence': 1689, 'street': 1690, 'regret': 1691, 'requires': 1692, 'spending': 1693, 'afternoon': 1694, 'volunteering': 1695, 'prescribe': 1696, 'following': 1697, 'complicated': 1698, 'heavily': 1699, 'convicted': 1700, 'fraud': 1701, 'stake': 1702, 'become': 1703, 'amid': 1704, 'conscience': 1705, 'tells': 1706, 'compared': 1707, 'potentially': 1708, 'saving': 1709, 'thousands': 1710, 'iran': 1711, 'refused': 1712, 'helpfully': 1713, 'authorized': 1714, 'states': 1715, 'basis': 1716, 'painless': 1717, 'corporations': 1718, 'fund': 1719, 'invite': 1720, 'regain': 1721, 'canton': 1722, 'due': 1723, 'jan': 1724, 'opted': 1725, 'water': 1726, 'concern': 1727, 'magnitude': 1728, 'action': 1729, 'brake': 1730, 'begun': 1731, 'prototype': 1732, 'laboratory': 1733, 'siberia': 1734, 'russias': 1735, 'reasons': 1736, 'stella': 1737, 'maris': 1738, 'desease': 1739, 'kill': 1740, 'dunno': 1741, 'colleagues': 1742, 'reported': 1743, 'claiming': 1744, 'providing': 1745, 'rushed': 1746, 'economic': 1747, 'inconvenients': 1748, 'lung': 1749, 'guilty': 1750, 'vijay': 1751, 'reddy': 1752, 'curb': 1753, 'australia': 1754, 'outbreak': 1755, 'woolworths': 1756, 'special': 1757, 'shopping': 1758, 'elderly': 1759, 'disabled': 1760, 'rome': 1761, 'listed': 1762, 'various': 1763, 'markets': 1764, 'pushing': 1765, 'finding': 1766, 'cures': 1767, 'push': 1768, 'identified': 1769, 'undoubtably': 1770, 'regulators': 1771, 'pandemie': 1772, 'proliferate': 1773, 'watch': 1774, 'victim': 1775, 'donation': 1776, 'traditional': 1777, 'mule': 1778, 'recruitment': 1779, 'tactics': 1780, 'vogue': 1781, 'coronavirusdo': 1782, 'fooled': 1783, 'horrible': 1784, 'marketing': 1785, 'misleading': 1786, 'produces': 1787, 'claim': 1788, 'built': 1789, 'somewhere': 1790, 'close': 1791, 'priority': 1792, 'queue': 1793, 'youre': 1794, 'medicines': 1795, 'liable': 1796, 'beings': 1797, 'rushes': 1798, 'weekend': 1799, 'seeing': 1800, 'sanitary': 1801, 'leaders': 1802, 'vacations': 1803, 'privilege': 1804, 'oms': 1805, 'jam': 1806, 'hearing': 1807, 'anyones': 1808, 'doesnt': 1809, 'poooor': 1810, 'grandparents': 1811, 'responsibility': 1812, 'definition': 1813, 'vocation': 1814, 'mutating': 1815, 'hurt': 1816, 'rusty': 1817, 'piece': 1818, 'iron': 1819, 'financial': 1820, 'scandal': 1821, 'supervising': 1822, 'torn': 1823, 'firstish': 1824, 'thesis': 1825, 'convincing': 1826, 'multiple': 1827, 'contradictions': 1828, 'altruism': 1829, 'imposed': 1830, 'fundamental': 1831, 'liveplease': 1832, 'preserve': 1833, 'spoke': 1834, 'dull': 1835, 'achey': 1836, 'sore': 1837, 'deltoid': 1838, 'hurry': 1839, 'regions': 1840, 'conflicting': 1841, 'uae': 1842, 'timely': 1843, 'u': 1844, 'becoime': 1845, 'tend': 1846, 'ignoramuses': 1847, 'charlatans': 1848, 'theorists': 1849, 'concerned': 1850, 'check': 1851, 'recap': 1852, 'supposedly': 1853, 'advantage': 1854, 'advances': 1855, 'popular': 1856, 'sad': 1857, 'scarier': 1858, 'tp': 1859, 'hoarding': 1860, 'moments': 1861, 'sisters': 1862, 'mama': 1863, 'michel': 1864, 'issued': 1865, 'advising': 1866, 'beware': 1867, 'fraudulent': 1868, 'rapidly': 1869, 'facilitate': 1870, 'evening': 1871, 'wrap': 1872, 'process': 1873, 'behaviour': 1874, 'remains': 1875, 'caught': 1876, 'protected': 1877, 'heath': 1878, 'guarantee': 1879, 'non': 1880, 'ceased': 1881, 'credible': 1882, 'passed': 1883, 'military': 1884, 'industrialists': 1885, 'main': 1886, 'objects': 1887, 'melove': 1888, 'verb': 1889, 'allergies': 1890, 'tolerating': 1891, 'citizens': 1892, 'families': 1893, 'greater': 1894, 'vary': 1895, 'pperson': 1896, 'hence': 1897, 'neutrality': 1898, 'monthsall': 1899, 'professor': 1900, 'eyeing': 1901, 'urges': 1902, 'canadians': 1903, 'lethal': 1904, 'hurraah': 1905, 'adults': 1906, 'alaskan': 1907, 'worker': 1908, 'astra': 1909, 'astrazeneka': 1910, 'controversy': 1911, 'dog': 1912, 'chickens': 1913, 'approv': 1914, 'specialists': 1915, 'willget': 1916, 'becerra': 1917, 'medicine': 1918, 'cdc': 1919, 'count': 1920, 'experiment': 1921, 'george': 1922, 'soros': 1923, 'despite': 1924, 'cat': 1925, 'mouse': 1926, 'game': 1927, 'obviously': 1928, 'provide': 1929, 'outdated': 1930, 'tendency': 1931, 'europeans': 1932, 'impressive': 1933, 'purpose': 1934, 'theyd': 1935, 'buy': 1936, 'extrapolated': 1937, 'cartels': 1938, 'payback': 1939, 'wanted': 1940, 'amazed': 1941, 'turnaround': 1942, 'exists': 1943, 'positiv': 1944, 'catch': 1945, 'bug': 1946, 'coma': 1947, 'looked': 1948, 'nonprofits': 1949, 'medicaid': 1950, 'thankfully': 1951, 'wondering': 1952, 'altruists': 1953, '21': 1954, 'grey': 1955, 'area': 1956, 'pain': 1957, 'shoulder': 1958, 'sister': 1959, 'sim': 1960, 'trouble': 1961, 'passing': 1962, 'f': 1963, 'tiniest': 1964, 'soreness': 1965, 'stabilitechs': 1966, 'intended': 1967, 'delivered': 1968, 'disruptive': 1969, 'capsule': 1970, 'efficacious': 1971, 'capsules': 1972, 'inexpensive': 1973, 'posted': 1974, 'menstruation': 1975, 'proposing': 1976, 'headlines': 1977, 'directly': 1978, 'governors': 1979, 'mayors': 1980, 'shops': 1981, 'concessions': 1982, 'hardware': 1983, 'determining': 1984, 'busting': 1985, 'balls': 1986, 'founder': 1987, 'biotechnology': 1988, 'hat': 1989, 'attention': 1990, 'arses': 1991, 'tan': 1992, 'idiot': 1993, 'began': 1994, 'jabs': 1995, 'dosis': 1996, 'memorial': 1997, 'mir': 1998, 'learned': 1999, 'unknown': 2000, 'models': 2001, 'saying': 2002, 'california': 2003, 'nightgov': 2004, 'gav': 2005, 'interessed': 2006, 'thag': 2007, 'statistics': 2008, 'percentage': 2009, 'alongside': 2010, 'microchip': 2011, 'u2': 2012, 'album': 2013, 'often': 2014, 'regularly': 2015, 'office': 2016, 'prioritized': 2017, 'constantly': 2018, 'graveling': 2019, 'feet': 2020, 'killed': 2021, 'k': 2022, 'appreciate': 2023, 'calm': 2024, 'boom': 2025, 'delt': 2026, 'professionals': 2027, 'nurses': 2028, 'caregivers': 2029, 'reputation': 2030, 'premature': 2031, 'enjoy': 2032, 'hijacked': 2033, 'emirati': 2034, 'listened': 2035, 'gp': 2036, 'morons': 2037, 'artemesia': 2038, 'officialized': 2039, 'organizations': 2040, 'neglected': 2041, 'oclock': 2042, 'massive': 2043, 'novel': 2044, 'minister': 2045, 'revisit': 2046, 'museums': 2047, 'tears': 2048, 'gave': 2049, 'joy': 2050, 'destined': 2051, 'current': 2052, 'attacks': 2053, 'induce': 2054, 'carried': 2055, 'formally': 2056, 'casts': 2057, 'votes': 2058, 'alternatives': 2059, 'grandmas': 2060, 'secrets': 2061, 'plan': 2062, 'questionable': 2063, 'image': 2064, 'ship': 2065, 'missouris': 2066, 'wednesday': 2067, 'nation': 2068, 'senate': 2069, 'republicans': 2070, 'investors': 2071, 'possi': 2072, 'immigrant': 2073, 'muslim': 2074, 'couple': 2075, 'posing': 2076, 'late': 2077, 'j': 2078, 'ligma': 2079, 'taxpayer': 2080, 'stole': 2081, 'orcas': 2082, 'rice': 2083, 'viable': 2084, 'writing': 2085, 'book': 2086, 'hopeful': 2087, 'ill': 2088, 'benefit': 2089, 'inform': 2090, 'marc': 2091, 'siegel': 2092, 'nyu': 2093, 'langone': 2094, 'folks': 2095, 'eff': 2096, 'worked': 2097, 'adds': 2098, 'officials': 2099, 'especially': 2100, 'medicare': 2101, 'claims': 2102, 'identity': 2103, 'theft': 2104, 'schemes': 2105, 'packages': 2106, 'ap': 2107, 'aged': 2108, 'pre': 2109, 'existing': 2110, 'autoimmune': 2111, 'include': 2112, 'hypertension': 2113, 'diabetes': 2114, 'asthma': 2115, 'respiratory': 2116, 'liver': 2117, 'kidney': 2118, 'stabilised': 2119, 'chronic': 2120, 'road': 2121, 'capable': 2122, 'decimating': 2123, 'act': 2124, 'hide': 2125, 'dangerous': 2126, 'unless': 2127, 'aspire': 2128, 'protocol': 2129, 'funerals': 2130, 'key': 2131, 'commodity': 2132, 'primarily': 2133, 'dromois': 2134, 'teenagers': 2135, 'reserves': 2136, 'mid': 2137, 'july': 2138, 'complete': 2139, 'organisation': 2140, 'agns': 2141, 'buzyn': 2142, 'laugh': 2143, 'loud': 2144, 'stick': 2145, 'persons': 2146, 'age': 2147, 'under': 2148, 'maturity': 2149, 'prejorative': 2150, 'grandchildren': 2151, 'becoming': 2152, 'urge': 2153, 'however': 2154, 'willing': 2155, 'thr': 2156, 'compagnie': 2157, 'challenge': 2158, 'accessible': 2159, 'initial': 2160, 'selected': 2161, 'ports': 2162, 'entry': 2163, 'distanced': 2164, 'patiently': 2165, 'annihilate': 2166, 'imminent': 2167, 'paranormal': 2168, 'run': 2169, 'girl': 2170, 'victims': 2171, 'compensated': 2172, 'concerning': 2173, 'extreme': 2174, 'looks': 2175, 'guidance': 2176, 'whilst': 2177, 'breastfeeding': 2178, 'paid': 2179, 'relevant': 2180, 'corresponds': 2181, 'logistical': 2182, 'pharmacy': 2183, 'kept': 2184, 'specialized': 2185, 'awareness': 2186, 'madness': 2187, 'incite': 2188, 'product': 2189, 'clinic': 2190, 'lots': 2191, 'conceived': 2192, 'haste': 2193, 'aim': 2194, 'deeply': 2195, 'remind': 2196, 'congressman': 2197, 'voted': 2198, 'allowing': 2199, 'negotiate': 2200, 'lower': 2201, 'medication': 2202, 'pa': 2203, 'brought': 2204, 'perfection': 2205, 'prediction': 2206, 'overuse': 2207, 'antibacterial': 2208, 'lead': 2209, 'mutations': 2210, 'bacteria': 2211, 'toronto': 2212, 'ontarios': 2213, 'liquidate': 2214, 'stocks': 2215, 'ideal': 2216, 'targets': 2217, 'efforts': 2218, 'kingdom': 2219, 'roll': 2220, 'scotland': 2221, 'place': 2222, 'disappear': 2223, 'mutant': 2224, 'unbelievable': 2225, 'ha': 2226, 'cool': 2227, 'denial': 2228, 'preventive': 2229, 'curative': 2230, 'infancy': 2231, 'mostly': 2232, 'drop': 2233, 'pants': 2234, 'vacated': 2235, 'thead': 2236, 'epidemiologist': 2237, 'faint': 2238, 'rolling': 2239, 'surprising': 2240, 'appearance': 2241, 'management': 2242, 'reinforced': 2243, 'pessimism': 2244, 'armed': 2245, 'antibodies': 2246, 'exposed': 2247, 'cimas': 2248, 'recommends': 2249, 'pressuring': 2250, 'license': 2251, 'occurred': 2252, 'tuesday': 2253, 'uses': 2254, 'mortality': 2255, 'contract': 2256, 'transmit': 2257, 'sheet': 2258, 'providers': 2259, 'academic': 2260, 'critical': 2261, 'particular': 2262, 'worries': 2263, 'lasts': 2264, 'forever': 2265, 'pucking': 2266, 'intend': 2267, 'wht': 2268, 'wrong': 2269, 'astrazaneca': 2270, 'emotional': 2271}\n"
     ]
    }
   ],
   "source": [
    "# visualization of the result obtained after tokenization.\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print(f\"{Fore.GREEN}------------------- visualization of the result obtained after tokenization. ------------------- \")\n",
    "print(f\"{Fore.BLACK}\",word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    " Let's apply the tokenisation operation to each expression in column x. \n",
    "This will allow us to observe that each expression is identifiable by a group of numbers.\n",
    "\"\"\"\n",
    "\n",
    "train_sequences = tokenizer.texts_to_sequences(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we need to be vaccinated to protect all person around us\n",
      "\u001b[34m first sentence. ===>  we need to be vaccinated to protect all person around us\n",
      "\u001b[34m first sentence. ===>  [3, 24, 6, 124, 14, 58, 3, 52, 37, 46, 626, 65, 356, 975, 2, 976, 357]\n",
      "\u001b[32m second sentence.  ===> it is a pleasure to see how the govement are working for our help i thing the vaccination is good for all of us\n",
      "\u001b[34m second sentence. ===>  [3, 107, 9, 627, 13, 22, 4, 33, 3, 52, 3, 25, 101, 2, 255, 10, 358, 13, 43, 37, 17, 6, 462, 47, 177]\n",
      "\u001b[35m third sentence.  ===>  negative\n",
      "\u001b[34m third sentence. ===>  [37, 17, 31, 977, 359, 26, 628, 2, 978, 37, 23, 30, 360, 12, 629, 26, 2, 256, 34, 2, 21, 11]\n"
     ]
    }
   ],
   "source": [
    "# Let's see what the first three expressions of the document look like after the tokenisation operation.\n",
    "print(data.clean[0])\n",
    "print(f\"{Fore.BLUE} first sentence. ===> \",data.clean[0])\n",
    "print(f\"{Fore.BLUE} first sentence. ===> \",train_sequences[0])\n",
    "\n",
    "print(f\"{Fore.GREEN} second sentence.  ===>\",data.clean[1])\n",
    "print(f\"{Fore.BLUE} second sentence. ===> \",train_sequences[1])\n",
    "\n",
    "print(f\"{Fore.MAGENTA} third sentence.  ===> \",data.clean[2])\n",
    "print(f\"{Fore.BLUE} third sentence. ===> \",train_sequences[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We will try to transform each expression in the tokenizer to the length format defined above.\n",
    "This allows us to have expressions of the same length.\n",
    "\"\"\"\n",
    "\n",
    "train_padded = pad_sequences(train_sequences, maxlen=max_length, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m first sentence. ===>  [  3  24   6 124  14  58   3  52  37  46 626  65 356 975   2 976 357   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0]\n",
      "\u001b[32m second sentence.  ===> [  3 107   9 627  13  22   4  33   3  52   3  25 101   2 255  10 358  13\n",
      "  43  37  17   6 462  47 177   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0]\n",
      "\u001b[35m third sentence.  ===>  [ 37  17  31 977 359  26 628   2 978  37  23  30 360  12 629  26   2 256\n",
      "  34   2  21  11   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "# Let's see what the first three expressions of the document look like after the operation.\n",
    "\n",
    "print(f\"{Fore.BLUE} first sentence. ===> \",train_padded[0])\n",
    "print(f\"{Fore.GREEN} second sentence.  ===>\",train_padded[1])\n",
    "print(f\"{Fore.MAGENTA} third sentence.  ===> \",train_padded[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we repeat the same operations on the test sentences\n",
    "\n",
    "\"\"\"\n",
    "We will try to transform each expression in the tokenizer to the length format defined above.\n",
    "This allows us to have expressions of the same length.\n",
    "\"\"\"\n",
    "\n",
    "test_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "test_padded = pad_sequences(test_sequences, maxlen=max_length, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m Shape of train. ===>  {(818, 42)}\n",
      "\u001b[34m Shape of train. ===>  {(205, 42)}\n",
      "\u001b[32m This means that 80% of the training data corresponds to 817 sentences of 42 words each. \n"
     ]
    }
   ],
   "source": [
    "# how our training data is dimensioned.\n",
    "print(f\"{Fore.BLUE} Shape of train. ===> \",{train_padded.shape})\n",
    "print(f\"{Fore.BLUE} Shape of train. ===> \",{test_padded.shape})\n",
    "print(f\"{Fore.GREEN} This means that 80% of the training data corresponds to 817 sentences of 42 words each. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 42, 100)           254000    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 42, 100)           0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 42, 64)            42240     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 32)                12416     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 308,755\n",
      "Trainable params: 308,755\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "We will now create a model that will be adapted to binary data. That is, with two labels, positive and negative\n",
    "\n",
    "positive ==> [0 0 1]\n",
    "Neutral  ==> [1 0 0]\n",
    "Negative ==> [0 1 0]\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# define model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(num_words, 100, input_length=max_length))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.1))\n",
    "model.add(LSTM(32, dropout=0.2, recurrent_dropout=0.1))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "optimizer = Adam()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "52/52 - 37s - loss: 1.0162 - accuracy: 0.4707\n",
      "Epoch 2/10\n",
      "52/52 - 4s - loss: 1.0019 - accuracy: 0.4743\n",
      "Epoch 3/10\n",
      "52/52 - 3s - loss: 0.9969 - accuracy: 0.4707\n",
      "Epoch 4/10\n",
      "52/52 - 4s - loss: 0.8965 - accuracy: 0.5844\n",
      "Epoch 5/10\n",
      "52/52 - 4s - loss: 0.7416 - accuracy: 0.7152\n",
      "Epoch 6/10\n",
      "52/52 - 4s - loss: 0.7431 - accuracy: 0.7200\n",
      "Epoch 7/10\n",
      "52/52 - 3s - loss: 0.7250 - accuracy: 0.7286\n",
      "Epoch 8/10\n",
      "52/52 - 4s - loss: 0.6307 - accuracy: 0.7775\n",
      "Epoch 9/10\n",
      "52/52 - 3s - loss: 0.5361 - accuracy: 0.8178\n",
      "Epoch 10/10\n",
      "52/52 - 4s - loss: 0.5013 - accuracy: 0.8252\n",
      "\u001b[32m-------------------  The model was trained. ------------------- \n"
     ]
    }
   ],
   "source": [
    "# now we have to train the model \n",
    "model.fit(train_padded, y_train, epochs=10,batch_size=16,  verbose=2)\n",
    "print(f\"{Fore.GREEN}-------------------  The model was trained. ------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model :  56.59\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Now we test the model and we print the metrics data\n",
    "\"\"\"\n",
    "\n",
    "predictions = model.predict(test_padded)\n",
    "y_pred = (predictions > 0.5)\n",
    "print('Accuracy of the model : ', \"%.2f\" % (accuracy_score(y_pred, y_test)*100))\n",
    "# print(\"F1-score:  : \", \"%.2f\" %  (f1_score(y_pred, y_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m------------------- The simulation messages were successfully recorded.. ------------------- \n"
     ]
    }
   ],
   "source": [
    "#Simulate the model with unknow values\n",
    "\n",
    "\n",
    "# you cn write your own sentences on e and f nd check the result\n",
    "a = [\"a vaccine no i am not interested.\"]\n",
    "b = [\"There are times when I wonder why it is free. Anything that is free is dangerous. So i will never get it.\"]\n",
    "c = [\"I really don't know. I let time tell me.\"]\n",
    "d = [\" I don't think there's much difference with or without the vaccine, so I don't know what to do.\"]\n",
    "e = [\"I have my two doses and I am still alive. I am waiting for the others to find my freedom.\"]\n",
    "f = [\"Vaccination is very important. Also the vaccination against covid19.\"]\n",
    "\n",
    "print(f\"{Fore.GREEN}------------------- The simulation messages were successfully recorded.. ------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m------------------- The simulation messages cleaning operation is complete.. ------------------- \n"
     ]
    }
   ],
   "source": [
    "# clean the values\n",
    "clean_textA = clean_tweets(a)\n",
    "clean_textB = clean_tweets(b)\n",
    "clean_textC = clean_tweets(c)\n",
    "clean_textD = clean_tweets(d)\n",
    "clean_textE = clean_tweets(e)\n",
    "clean_textF = clean_tweets(f)\n",
    "\n",
    "print(f\"{Fore.GREEN}------------------- The simulation messages cleaning operation is complete.. ------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m 1.sentence. ===>  ['a vaccine no i am not interested.']\n",
      "\u001b[34m 1.sentence. ===>  [[  9   4  30   3  25   6 311   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0]]\n",
      "\u001b[32m 2.sentence. ===>  ['There are times when I wonder why it is free. Anything that is free is dangerous. So i will never get it.']\n",
      "\u001b[32m 2.sentence. ===>  [[  47   17  495   80    3  368   87   10    5  118  354   18    5  118\n",
      "     5 2126   26    3   20  110   21   10    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0]]\n",
      "\u001b[31m 3.sentence. ===>  [\"I really don't know. I let time tell me.\"]\n",
      "\u001b[31m 3.sentence. ===>  [[  3 126 479  86   3 106  89 420  43   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0]]\n",
      "\u001b[30m 4.sentence. ===>  [\" I don't think there's much difference with or without the vaccine, so I don't know what to do.\"]\n",
      "\u001b[30m 4.sentence. ===>  [[  3 479  52 695 115 518  32  38 102   1   4  26   3 479  86  69   2  24\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0]]\n",
      "\u001b[35m 5.sentence. ===>  ['I have my two doses and I am still alive. I am waiting for the others to find my freedom.']\n",
      "\u001b[35m 5.sentence. ===>  [[   3   23   22  120   78    8    3   25   95 1024    3   25  367   13\n",
      "     1  237    2  216   22  451    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0]]\n",
      "\u001b[34m 6.sentence. ===>  ['Vaccination is very important. Also the vaccination against covid19.']\n",
      "\u001b[34m 6.sentence. ===>  [[ 44   5  83 150 140   1  44  64 220   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "We will try to transform each expression in the tokenizer to the length format defined above.\n",
    "This allows us to have expressions of the same length.\n",
    "\"\"\"\n",
    "simulate_sentence_A = tokenizer.texts_to_sequences(clean_textA)\n",
    "simulate_sentence_B = tokenizer.texts_to_sequences(clean_textB)\n",
    "simulate_sentence_C = tokenizer.texts_to_sequences(clean_textC)\n",
    "simulate_sentence_D = tokenizer.texts_to_sequences(clean_textD)\n",
    "simulate_sentence_E = tokenizer.texts_to_sequences(clean_textE)\n",
    "simulate_sentence_F = tokenizer.texts_to_sequences(clean_textF)\n",
    "\n",
    "\n",
    "test_padded1 = pad_sequences(simulate_sentence_A, maxlen=max_length, padding='post', truncating='post')\n",
    "test_padded2 = pad_sequences(simulate_sentence_B, maxlen=max_length, padding='post', truncating='post')\n",
    "test_padded3 = pad_sequences(simulate_sentence_C, maxlen=max_length, padding='post', truncating='post')\n",
    "test_padded4 = pad_sequences(simulate_sentence_D, maxlen=max_length, padding='post', truncating='post')\n",
    "test_padded5 = pad_sequences(simulate_sentence_E, maxlen=max_length, padding='post', truncating='post')\n",
    "test_padded6 = pad_sequences(simulate_sentence_F, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "\n",
    "print(f\"{Fore.BLUE} 1.sentence. ===> \",a)\n",
    "print(f\"{Fore.BLUE} 1.sentence. ===> \",test_padded1)\n",
    "\n",
    "print(f\"{Fore.GREEN} 2.sentence. ===> \",b)\n",
    "print(f\"{Fore.GREEN} 2.sentence. ===> \",test_padded2)\n",
    "\n",
    "print(f\"{Fore.RED} 3.sentence. ===> \",c)\n",
    "print(f\"{Fore.RED} 3.sentence. ===> \",test_padded3)\n",
    "\n",
    "print(f\"{Fore.BLACK} 4.sentence. ===> \",d)\n",
    "print(f\"{Fore.BLACK} 4.sentence. ===> \",test_padded4)\n",
    "\n",
    "print(f\"{Fore.MAGENTA} 5.sentence. ===> \",e)\n",
    "print(f\"{Fore.MAGENTA} 5.sentence. ===> \",test_padded5)\n",
    "\n",
    "print(f\"{Fore.BLUE} 6.sentence. ===> \",f)\n",
    "print(f\"{Fore.BLUE} 6.sentence. ===> \",test_padded6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m------------------- Legend. ------------------- \n",
      "\u001b[31m negative ==> [1 0 0]\n",
      "\u001b[31m Neutral  ==> [0 1 0]\n",
      "\u001b[31m positive ==> [0 0 1]\n",
      "\u001b[32m#####################################################################################################\n",
      "\u001b[30m 1 --> display:  [[1. 0. 0.]]  instead of Negative [1 0 0]\n",
      "\u001b[30m 2 --> display:  [[1. 0. 0.]]  instead of Negative [1 0 0]\n",
      "\u001b[30m 3 --> display:  [[1. 0. 0.]]  instead of Neutral  [0 1 0]\n",
      "\u001b[30m 4 --> display:  [[0. 1. 0.]]  instead of Neutral  [0 1 0]\n",
      "\u001b[30m 5 --> display:  [[0. 0. 1.]]  instead of Positive [0 0 1]\n",
      "\u001b[30m 6 --> display:  [[0. 0. 1.]]  instead of Positive [0 0 1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pred1 = model.predict(test_padded1)\n",
    "pred2 = model.predict(test_padded2)\n",
    "pred3 = model.predict(test_padded3)\n",
    "pred4 = model.predict(test_padded4)\n",
    "pred5 = model.predict(test_padded5)\n",
    "pred6 = model.predict(test_padded6)\n",
    "\n",
    "print(f\"{Fore.BLUE}------------------- Legend. ------------------- \")\n",
    "print(f\"{Fore.RED} negative ==> [1 0 0]\")\n",
    "print(f\"{Fore.RED} Neutral  ==> [0 1 0]\")\n",
    "print(f\"{Fore.RED} positive ==> [0 0 1]\")\n",
    "\n",
    "print(f\"{Fore.GREEN}#####################################################################################################\")\n",
    "\n",
    "print(f\"{Fore.BLACK} 1 --> display: \", np.around(pred1, decimals=0),\" instead of Negative [1 0 0]\")\n",
    "print(f\"{Fore.BLACK} 2 --> display: \", np.around(pred2, decimals=0),\" instead of Negative [1 0 0]\")\n",
    "print(f\"{Fore.BLACK} 3 --> display: \", np.around(pred3, decimals=0),\" instead of Neutral  [0 1 0]\")\n",
    "print(f\"{Fore.BLACK} 4 --> display: \", np.around(pred4, decimals=0),\" instead of Neutral  [0 1 0]\")\n",
    "print(f\"{Fore.BLACK} 5 --> display: \", np.around(pred5, decimals=0),\" instead of Positive [0 0 1]\")\n",
    "print(f\"{Fore.BLACK} 6 --> display: \", np.around(pred6, decimals=0),\" instead of Positive [0 0 1]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m------------------- The firsst NN prototype is completed. ------------------- \n"
     ]
    }
   ],
   "source": [
    "print(f\"{Fore.GREEN}------------------- The firsst NN prototype is completed. ------------------- \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
