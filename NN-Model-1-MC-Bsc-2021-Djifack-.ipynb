{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bachelorarbait-2021\n",
    "# Author: Michel Bosris Djifack\n",
    "# Matrikelnummer:7103963"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A sentiment analysis program will be designed to make predictions about the english written expressions to rank them and \n",
    "# determine which ones are in favor of the coronavirus vaccine and which are against.\n",
    "# Method: NN (Neural Network)\n",
    "\n",
    "# ===> three classes (Multiclass) with NN\n",
    "\n",
    "\n",
    "# NN-Prototype-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m------------------- All libraries have been successfully imported.------------------- \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "import all libraries (Math-function, diagram-visualisation, regex, document and NLP functions)\n",
    "\n",
    "\"\"\"\n",
    "# NLP Libraries\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, LSTM, Embedding, Dropout, Activation, BatchNormalization,Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "\n",
    "# Math, documents and visualisation Libraries\n",
    "import numpy as np\n",
    "import preprocessor as p\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import colorama\n",
    "from colorama import Fore\n",
    "\n",
    "print(f\"{Fore.MAGENTA}------------------- All libraries have been successfully imported.------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m------------------- The document has been successfully uploaded. ------------------- \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "upload The dataset, open it and check it.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# upload the DataSet\n",
    "file = open('covidVaccineAdvice_mldata_d1.csv',encoding=\"utf-8\")\n",
    "data = pd.read_csv(file,delimiter=\";\")\n",
    "print(f\"{Fore.MAGENTA}------------------- The document has been successfully uploaded. ------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m -------------------  overview of the dataset ------------------- \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>We need to be vaccinated to protect all person...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>it is a pleasure to see how the govement are w...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>The most popular vaccine that i know is Modern...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Of course we need to be vaccinated if we want ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            message sentiment\n",
       "0   1  We need to be vaccinated to protect all person...  Positive\n",
       "1   2  it is a pleasure to see how the govement are w...  Positive\n",
       "2   3                                          Negative   Negative\n",
       "3   4  The most popular vaccine that i know is Modern...  Positive\n",
       "4   5  Of course we need to be vaccinated if we want ...  Positive"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the document header.\n",
    "print(f\"{Fore.MAGENTA} -------------------  overview of the dataset ------------------- \")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m -------------------  The document has 1023 rows and 3 columns ------------------- \n"
     ]
    }
   ],
   "source": [
    "#count the data set\n",
    "print(f\"{Fore.MAGENTA} -------------------  The document has\", data.shape[0], \"rows and\", data.shape[1],\"columns ------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m------------------- the number and percentage of missing values in the data set. ------------------- \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>message</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count  Percentage\n",
       "id             0         0.0\n",
       "message        0         0.0\n",
       "sentiment      0         0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check missing values\n",
    "count =data.isnull().sum().sort_values(ascending=False)\n",
    "percentage =((data.isnull().sum()/len(data)*100)).sort_values(ascending=False)\n",
    "missing_data =pd.concat([count,percentage],axis=1,keys=['count','Percentage'])\n",
    "\n",
    "print(f\"{Fore.MAGENTA}------------------- the number and percentage of missing values in the data set. ------------------- \")\n",
    "missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAwsAAAD8CAYAAAA42TiGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAA690lEQVR4nO3dd5wcdf3H8ddny6XnUkghBHL0BDwInVADWJBYUJqIsIiKNMECeqA/OZoEEUFAgiLlgCBdQI+mQEBK6IEFpAUOEpKQ3pOr398f37lk726u397c7r2fj8c+9nbqZ2Zn5+Yz3zLmnENERERERKSxWNQBiIiIiIhIz6RkQUREREREQilZEBERERGRUEoWREREREQklJIFEREREREJpWRBRERERERCKVkQkWiZzcAsuj6czW7BzGFWlDGsKBh2S2Rx+Tii3TdhzCowq4g6jJzRU44lEZEOUrIgEoV8u+DyF0OZr0rMFmH2GmZ/w+yrmMWztO7c3ZdhiYq0zOxLmP0Ds3mYVWG2DLP3MbsHszMxswhicpjN6Pb1drfO/tbMCjD7AWblmM0PzhOrMJuF2VWY7dTJ+CYH30Vpp5YjIg0kog5ARPLKBcF7HBgC7AgcD/wAeAWz43Du/UbznAD077YImzoXmAp8FmEMzYl63/QsZucBlwA1wKPAe0AS2BI4EDgSuC4Y31N8BkwAVkQdSKTMtgMewO+LxcC/gU+BAmAH4BTgTMwOx7mHogpTRJpSsiAiXce50ibDzEYB1wBHAf/BbHecW5gxz6fdFV4o5+YD8yONoTlR75uexGwccCGwEtgP59KNxseALwG13R9cC5yrBt6NOoxI+XPAE8BY4CrgPJxb12iakcD5wNDuDk9EWqZqSJJ99UX0ZmMwuw2zhZitw+xVzL7bwnxfwexhzBYHxdWzMbscsyEh01YEr8GY/TH4u7pBcbTZeMxuCsZVBnH8F7NTQ5Y3PqgiMieY9nPM7sBs+5BpN1YlMfsxZmnM1gfz/BWzwoxpJwd10McB4xpV3bklY7rDMbs9qF6xBrPVwf46M7goCttf22F2X1AtYw1mz2M2BbMTg+WfGDLPWMyuxeyjYDuXYPYQZns08620n3OfA98BZgCbA+c1iqFpvXwzwywVbMOiYH/OwewxzI4Jpmnrvqw//kbjq0R9hlnthv3RWlUgfyw8gNnSYL8+i9mXQ6YrDZYzOWRc03rrPvZU8OnjjNgrWtw3fngMs1Mwezk4NtYEf58aenxs3AebBMdkfRWQtzH7fuh2t8asMDh2Pgu+n3doXA3I7zuH2ZMtLCcd/FZHt7LGvfAlVk81SRQAnKvDucdwLmx/7YXZvZgtwFddmoPZXzAbEzLtjCDmBGbnYfZBsK/mYHYZZgUZ056Y8f0c2OgYLA2mCW+zsPG42xKzM4L9tx5/fjpvw340Owqzl4LveGGwz/s2sy+jPW8172J8ovB3nPtZk0QBwLmFOHc6cGfGerfDbCpmr+DPA5WYfRLEN7bJ9sBTwafzG8U4udG0x2L2FP5cuR6z/2H2G8z6hEZvdhy+SuW64Du4Df//rKt/n03PUWZ3BuMPaCa2I4Px14SOF+kCKlmQ7jIUeB5YDtyMr6JyNDAds81w7vIGU5v9Fl+lZSnwL2AhsBNwNnAYZpNwbmWjdRQATwLDgMfxdyA/DpY3BbgH6IOvvvD3IIadgV8C0zLWfShwP756wz+BD/H/6L4NTMHsIJx7LWQbfw98JZjnceAg4EfANsDBwTQVwXb9NPh8Vcb8szL+ngrUAS/iqzEUBsv4E7AHvmpP5v4aDzwXbHs58CawFfAP4OGQWMFs1yDOYcBjwTZvAhwOPIvZt3AufN72cq4Os4uBycCxmP0s9KJuo0vw1YM+Bu7GV+HYFL/tRwF30fZ9CX4bZwKr8dtZB3zehsi3BF4A3gL+EsRwDPAIZt/FubvasIzmXIDf1zvjv9flwfDl4ZM3cBvwXWAO8DfAAd/CV8HZDzguZJ4h+GOkCrgX6IuvtnMTZnU4V9aO2AuA/wTLvDP4fESwHdsDpwPg3LuYPQUchNl2Taqgme0DfAG4D+cWtLLOJcH7VpjFca5tJQg+GboBqAQewu+zbYEfAl/HbO9mSnDuAPYHHsGfSw7DnytGAvUJ1iz893g+8AlwS8b8M9oUH/wB/7uoP298A3/8F2C2FH8ueAD4L77k5HR80tTwJkfPOG81ZdaPjeerC1qaFADnKjM+fRtfPekp/P+PKnzVxvrvbnecq68++EDwngKepuH+r8iI50bgJGAufn8tB/YGLgIOwexLOFeTMf05+H20DCjDn4u+hP8tNVe1rCO/z+bOUdfhzzk/Bp4Jme/k4P2vzcQi0nnOOb30yu4LXPC620EsY/iWDpY6qHKwVcbwg4Lpn3cwpNGyTgzGXdloeEUw/D8OBjQat4mDFcF6DgyJb2zG30MdLHOw2MEOjabb0cFqB681Gn5LsO5PHWyRMTzh4Jlg3J4h8Va0sM+2DhkWc1AWLG+vRuOeCIaf2mj4VzP2/4mNYvvQwfom+wTGOPjMwXwHfdr1Hbc8TR8H1cG0W2YMn9FkXljiYK6D/iHL2aSd+7J++291kAgZX//9FWUMK8qY7/JG0+8ebMcyB4MzhpcG008OWUf98m5pdd0Nx4ftm2ODeV5zMDBj+AAHrwTjvtvMPvibg3jG8B0c1Dh4p03f88b97Rw82+D4gGEOZgfjDsgYfmQw7A8t7PsvtWG9AzLW/YyDk4LfZLyFebYLfvcfOtis0biDHdQ6+EfoPodXHQxrtP4Pg3lGh+zfGc3E0Np3X9EgNhji/PlnjYNFDiY0+g2946DSwciM4T3jvBW+/fsHy5rbrvn8vJu5sHMQfDn4HqY1Gj45WFdpM8ur//9xv4N+jcbV/37Pyhi2VfBbX+Rg84zh5uDvLuy817nfZ3PnqLecP1c3Pvdt6aDOwXPt3rd66dWOl6ohSXepBX6Fc3Ubhjj3MXA1/k5Y5p3yM4P3H+Hc8gZLce4W/J2ssDszAL/AuTWNhqWAwcA0nHu6yRzOzc34dAL+bun5OPdOo+next+h3AWzHULWfSGZdyj93ambg097NhNvOOdmhwyrw9+5BX8n0DPbHH8H8EP83e/MeR7B3wFubAqwNXBNk33i3Dz8nbTRwCHtirsl/o5h/d3hEW2Yo5qw+ufOLe7A2quAs8m8Y9g2K/D15DPX/wowHX+cfKsDsXTWScF7Cc6t3jDUH/e/Cj79MGS+tcDPybwj74/x54AJmA1qZxznknkX2Lml+LuzsPHOO/g7vvOAExtU8/DVCY8GZhN+jDbkt+8b+N///sCN+BKfVZg9jdlpIdVITsWfX85i4x3o+uU9iS9p+Hoz2/6rYJsy1z8dX31391bjbbuLGsTmz3kP4Ru2T8O5/2WMq8SXqhXgGwrX6xnnrXCbBu9zW5wqjHOf0bCkoX7448DbZJ4H2+YsfOP3k2haFeoi/Pkp83/Ld/E1MK7BuTkZ63dACeHtYzr6+2zpHDUNXyqeajT8ZMBofN4X6WKtV0MK74LsFpyrwNf5LWo0bgbOzQjqCE5uNK4C527B1w0+sclS6xtHap25tc62+TRIDhqbgS/C3yVj2CT8heJRmB0VMk8BMAKz4Ti3JGP4enz1m8b2Dt4faUOck4L3nZvZV9sF7xOAdxqNeyVk+vp/MO1rtGc2HDgHX/VhK2BAoyk2y/h7YvD+QoNkbKNngS82Gla/neOa2c5tg/cJNFeNqWPq67O7VqabDvwEeBuze/DVCl7AuY72KFNBZqPqtnsN51aFDJ+B/8e9C75qQnfaFV9FYUbIuKfxFzC7hIz7gKZV92DjMToECNvWMDX4aiGN1ce0cf3O1WD2N+C3+KpKdwRjjgf6AX8NLr5a59yb+Ive3fHVZXbD/74PCF4nB9VtlgVz1B/nBxLeDmckvkrPdsCrjcZ13e+5ZWHrmRe8N44JNvbalVlnv2ect8K19TcfMqcZ/uL9RHx1vaH476teVTuW1T9YxmLgp4T3sFtJwySs/jh+tsmUzn2C2Rya/s/s6O+zpXPUrfjqaCcDVwBglsTvl2X4qpot6y3XI1pn59bZnFaLHzYWj2W+JgfjZoSMKw3GlYaMmxGMmxy6XK0zN9fZtmPohWbGjQ/GP5UxrLqZOBu/xmXMU+Hgk2bW8e9g+uI2xPrvNq47lTFP81VJmisWb6k431dD+CiY70UH1zm4OPgOrgqG35Ix/feCYZc3s7xTgvEnZgy7oY3beX47vmPXyjR9M77boozhYVVt4g7OcvBGRizVDh50sE2b9+XG2J5uYXxL1ZD+3sw8hwbjb84Y1l3VkGocLGphexY4qAvZBzPavP0tf48VDua38B07Bx83Gr5Z8P09nTEs7Xx1mhFtWm/LMe3p4H/Buq/KGP5BG4/zA1vc5xvH1VdjObEd+7f9333Lx1LTGHrCeav576a+GtKcDnyvVwbzznNwu4PLgn1T6uqrpLUl7o3HYFv2kcuY5z/BsB2biW9mF/4+mz9H+WmmBdMdFHyur953ZRv3Ze+4HtE6O7fOZl6tlyw41/wDbpyb3MK4UqC0mXEz2Hi3QevM9XW2zahmhtf3gJJ5x3gFEMO5Ye1ch2tm+PLgfTOgaS8qDdXHsTP+LmYUfohvWHsBjbsiNZuEL0rPVH+3uLl9HDa8fju/Sff1ab4fvjTzc5yraHFKX1XmT8Cf8F0q7ofvUekoYEfMdiSsekILS+xQxO07butLdcLOq0M6uP4wK4BhmCXx3XJuZJbAN1IPK0HoSps008g4bL+Ac59h9k/gW5hNwN8h/gJwF84t6nQ0zr2E2Rn46kwHZ4ypj6OQ8FKVfNETzlvNeQV/x34sZtvj3Httmsv/7s/EVzXbh8YlfGbHtjOO+n30Os7t2sZ5Ms+tb4eMb+7c2pHfZ2vnqGn4xt4/xjf4bl/D5t5yPaJ1dm6dzVCbBekuWxDeNeXk4P31jGEzgaGY7dhF654ZvH+1HdPu30Xrbk4tDYvTM20TvN8XMu7AkGH1+25SaLd8/kK7se7aTs/H9evg0x0tTdqE71Lxfpw7Gt/b1db4C816Le3Lztq1mfrsk4P3zON2WfC+ecj0zdVxr7/Ybk/8r+PP3WFdKR4QLCus15uulAD2CRk+OXh/PWTcdcH7yWy80OnKutb1F5OZ/yS76zivI3vHYFv0hPNWON824Lbg0/+1Ov3Gdidb4Y/zx0MShbHB+LD4CI3Rtx94G3+zoa03ouqP46bnUP/cj7DfenZ+nz4JfA6fcO+Fr1r6DJltWkSyRMmCdJc4cFmDi1mzLfF3jmqA2zOmvTJ4v4HwftAHYLZ3k+HNK8PfyTmVsL6qG/bXfTO+JOJ8zJo27vP9Z09ux7qbswTf7qJfyLiK4L3hesx2wXcn2pBveDcDn2T8uNE8h9K0vQLAg/iGpadjdlhohGaTgnq+nePvEN6J355Pgd+1Mn0fzA7BGlUq9nV06//Jr80Y09K+7KxCfF37zDh2x9ejXoHvmrbeS8H794M7iPXTb95kGRvVt7nZoh0x3RS8X9rg+/F/Tw0+3diO5XXUpY0aLA8DfhN8ujlk+ieA9/FtPY4G3se5p9q8NrM98f3ON/2e/bFR33g0s3vJa/Htn67EP0G48XwFmHXFBfYSwi8cu0tPOG+15Df4Bs7H4Z+VE/YdboLZ1fgSRNh4HtwPs3jGdAPxDbbDSvBa+z39Ed/m7SbCn9czFN+ldL078P+ffhL8juunM+BSwhOnbP4+pwXx34dPiq/v4HJE2kXPWZDu8ib+oUqvYvY4/iLsGHz1jF+S2fuPc09gVoI/GX+A2cP4/vYH4h8KdCC+wdmhbVqzc4vxD3+7F3gKs0eCeAbjn92wOb7aDzi3BLMj8ReBMzF7An83qg7/D2gSMBzfR31nPIF/ZsCjmD2DL6Z/A+f+iW/Mdg5wFWYHAR/gGxx/Dd//9jEhyzsdf9fpuuDiv/45C0fgE4NvsrGaDDhXjdm38c9XKMfseXwvM2uD/bFHMP+mNLwwb9nGRlUx/He7I/6uXAH+Yvo4Wu/NqB++OkkFZi/i+6/vi+/bfALwUKO7aS3ty856BvhhcCfvOTY+ZyEG/LhB1RbnXgzWfwDwEv5BZKOAr+P3c9jF5BP47/oGzO7F97G+HOeubTYi5+7A7Jv4C+63MXsAX4XhcPxxfDfOTe/ENrfFfHzvLG9h9hC+x6Ej8fvnOpxr2h+8cw6z6/EXbND+UoUx+IviazF7Ft9Qd32wzkPxVaA+JLP3Kv+ch5PwF3BvY/YoPmFJ4n/P+wOLgPHtjKWxJ4DvBFWtXsVfYD4Tuh+yoWect1qK73PMDsH3jHU2kMLs3/ibB/U9O03GH1OHB/MswOxOfPIwK+P/xpfw3/ssNnbuUO89fAPw72BWFSzfAbfh3Cc4dxNmuwGnAbMxeyyYZhj+t3MA/hg7JYhhNv6ZP78D3sDsLjY+Z2EY8Ab+f0jmtmbz93kP/mbaZviG2vd3cDki7dPuBkd66dXeV32jHN9//+0OFjrfZ/RrrnF/0w3n28/5ZzPMc76v9EUOZjn4o4PdG03besM739/4rc4/Q6DKwecOnnZwcsi0RQ6udb6B5HoHKx286+A2B4c3mrYjDQUHON9gba7zDeKca9hoeQcHDwX7ao3zfb7/0DXXWNLPM975/sOXB/O84GCKg7ODeQ4PmWekg6nO9+O91vn+2D9wcK/zDaeb9vnd/Hec+ap0vs/3V51vTH2oy3zGRsN5GzYohaSDXzp4xPk+4NcH3/1M5xtrF7RzX/rjr/nYW2rgfIuDCc43rF4W7KPnHHylmWUNCbZ3YbAP3nJwcivf28+db5xbGUxT0ey+2Tg85uA05/ttXxu8XnVweuh+bmkfdKyBc4WDQgd/Dn5PlcE2nOnAWph3qPP94693MLyd55FBzvdhf7ODN4Pjq8b5Z7U876DEwaBm5i0OtvOTINalwXfzFwcHt3g8NhzXXAPnkQ7ucP6cUusaNlLMfgPnhsdtdOet1r/DAgc/cPCw889xqXKwyvnG7le7xp1QQH8Hl7iNz4SZExxzw1v4bezh/HNnVjj/DIKm+xG+5uBfwe+0yvlGxy8535HE+JBlHu/gdbfxXHS78//P3nKwPKu/z6bTXhlMH96hhV56ZeFlzrmo8xXJd2YOeJoONKqRLmA2Hd9f+Hja2rhQJBt8VZingNtx7viWJxbpwcwG45+wPAvnJrU2eReudwa+BGR7nPug29YrvZraLIjkA18neXTI8EPw1WbeUaIgPcAvg/fmq1mJ9CRmI4I2MZnDEvjnHfSlYbulbMeyJ74a7mNKFKQ7qc2CSH4oAOZg9hTwLr7O9I74urVV+DYNIt3PrBjf3mY3fI9k/8K5F6MNSqTNjgAuxOw/+IfVDcPf2d8O327imqxHYHYqvp3C9/HtUM7P+jpFMihZEMkP1fieMQ7GNyTvj28Adw8wFedejzA26d12wzcQXYk/Hk+LNhyRdnkR36HGAfhG4uA73LgEuAzfNWy2/Qr/xO6PgONx7qVWphfpUmqzICIiIiIiodRmQUREREREQilZEBERERGRUEoWREREREQklJIFEREREREJpWRBRERERERCKVkQEREREZFQShZERERERCSUkgUREREREQmlZEFEREREREIpWRARERERkVBKFkREREREJJSSBRERERERCaVkQUREREREQilZEBERERGRUEoWREREREQklJIFEREREREJpWRBRER6PDNzZnZFxuezzaw0C+s5r9Hn57t6HSIiuUTJgoiI5IJK4NtmtkmW19MgWXDO7ZPl9YmI9GhKFkREJBfUAH8FftZ4hJmNMLP7zOzl4LVvxvB/m9lrZvYXM/ukPtkwswfM7FUze9vMTg6GTQX6mdksM5seDFsdvN9lZodlrPMWMzvCzOJmdnmw3jfN7MdZ3xMiIt3InHNRxyAiItKi4KJ9DPAmsDPwI2Cgc67UzO4ArnPOPWtmWwCPOecmmNm1wGfOuUvN7FDgEWCEc26xmQ1zzi01s37Ay8CBzrklZrbaOTcwc73OuYFm9i3gcOdcyswKgNnAdsDxwEjn3MVm1gd4DjjKOfdxt+0cEZEsSkQdgIiISFs451aa2a3AmcC6jFFfBHYws/rPg81sELAf8K1g3kfNbFnGPGcGCQDA5sC2wJIWVv8IcHWQEBwKPOOcW2dmXwZ2MrMjg+kKg2UpWRCRvKBkQUREcslVwGvAzRnDYsAk51xmAoFlZA+Nhk/GJxiTnHNrzWwG0LellTrn1gfTfQU4Bvh7/eKAnzjnHmvndoiI5AQlCyIieayopNyATYGijNdYYDAwqNGrvvpNVchrFbAAmJ/xWgDMBSoqpk6p64bNIag6dDfwA+CmYPDjwBnA5QBmNtE5Nwt4FjgauCwoARgaTF8ILAsShfHA3hmrqDazpHOuOmT1dwI/BHYHTgyGPQacamZPOueqzWw7fNWnNV2zxSIi0VKbBRGRPFFUUj4O2A2YGLy2B8YBfbK86nXAu8BbGa90xdQpc7pqBZltCcxsFL6az++DNgubAH8GJuBvgj3jnDvFzEbiSwCGAk/jSwS2DBb5ALAZ8B4wAih1zs0ws8uAbwCvOeeOa7TeJD5Besg59/1gWAy4GPg6vpRhEb5tw4qu2nYRkSgpWRARyUFBicEuwJeBfYE9gZGRBtXUXPxF+tPAjIqpUz7ozpUH7QtqnXM1ZjYJmOacm9idMYiI5DolCyIiOaKopHwEPjk4NHjvaclBa+bhE4eHgX9WTJ2S1bvvZrYtcDe+TUMVcJpz7uVsrlNEJN8oWRAR6cGKSspHAccGrz3wVV3yQRXwH+Be4IGKqVOWtTK9iIhEQMmCiEgPU1RS3h/f5efx+F574tFGlHXVwFPA7cA9FVOnrI84HhERCShZEBHpIYpKyncBzgKOYGPPRL3NMnzSMK1i6pT/RR2MiEhvp2RBRCRCQUPlrwE/ByZHG02P8x/gGuBf3dU1q4iINKRkQUQkAkUl5f3wffX/FNgu0mB6vv8BFwF3KWkQEeleShZERLpRUUl5EvgR8FtgVMTh5Jp3gAvx7RqUNIiIdAMlCyIi3SCobnQ0/gFe20QcTq57G7gAuLdi6hT9ExMRySIlCyIiWVZUUv5FYCr+6crSdZ4DTq+YOuWNqAMREclXShZERLKkqKR8DHAtvhtUyY5aYBrwm2w/5E1EpDdSsiAi0sWCKkc/xpcmFEYcTm+xEPgVUKaqSSIiXUfJgohIFyoqKZ8A3ADsG3UsvdTTwAkVU6d8GnUgIiL5QMmCiEgXKCopjwHn4ns5Kog4nN5uBb4tw/SoAxERyXVKFkREOqmopHw0/qnDh0QdizTwd+C0iqlTlkcdiIhIrlKyICLSCUUl5YcA09EzE3qqOfhqSTOiDkREJBcpWRAR6YCikvI4UAqcB8SijUZaUQv8omLqlD9FHYiISK5RsiAi0k5FJeVDgPuAgyMORdrnJuDUiqlTqqIOREQkVyhZEBFph6KS8i2Bh4HxUcciHfI88O2KqVM+jzoQEZFcoKJzEZE2Kiop3xOYiRKFXLYP8HJRSfkuUQciIpILlCyIiLRBUUn5t4EZwMiIQ5HO2xx4uqik/ICoAxER6emULIiItKKopPwM4B6gX9SxSJcZBDxaVFJ+aNSBiIj0ZEoWRERaUFRSfjZwDTpf5qN+wINBqZGIiITQPz8RkWZ8+dzrzwIujzoOyaoC4O6ikvLjow5ERKQnUrIgIhKmtPBnjxaU/GYnm/1B1KFI1sWBsqKS8hOiDkREpKdR16kiIo2VFp4CTAOoc7bk8KoLl77ptt424qgk+2qAwyumTimPOhARkZ5CyYKISKbSwhOAWwCrH1TnbMm3qi5Y8obbZrvI4pLushb4YsXUKS9EHYiISE+gZEFEpF5p4VeBf+KrpTRQ52zJt6suWDzLbbN99wcm3WwpsH/F1CnvRB2IiEjUlCyIiACUFm4NvAIMaW6SOmdLj6gqXfS621YJQ/6bC+xTMXXKnKgDERGJkho4i4iUFg4A/kELiQJAzNyw+wrOH7mLffBet8QlURoLPFRUUq5na4hIr6ZkQUQEbgSK2zJhzBh6X8H5I3e199/NckwSvYnA9VEHISISJSULItK7lRb+AjimPbPEjKH3FpSO2s3eU8KQ/04oKik/NeogRESiojYLItJ7lRYeDDxOSIPmtqhzLD+66vz5r7jtJ3RtYNLDVAEHVEyd8mLUgYiIdDclCyLSO5UWbgG8CmzSmcXUOZYfU/Xb+S+78XmXMLiaKhbc8StcTTXU1dF/+30Zsv9xLHrwMqqXzgWgbv0aYn0HMOb71zSZf+60k4gV9INYDIvF2TR1VYPxK168n+UzbmLsT6YT71/I+rnvsPTx67B4kk2+cQ7JoWOoW7+aRQ9exsijL8TMmqyjG80FdquYOmVhlEGIiHS3RNQBiIh0u9LCPsD9dDJRAIgZQ+4uuNCOqfq/d15yE3bofHA9SDzJqO/8jlhBP1xtDQum/5J+W+3GiG/+asMkS5/8G7E+A5pdxKhjf0e8f2GT4TUrF7G+4nXig0dsGLby5X8w4vBzqVmxkFWvP8ywg3/I8ufvpHDS0VEnCuAbPN8CHBZxHCIi3UptFkSkN/otsFtXLcyMwrsKLtpsL3snr/rlNzNfMgC4uhqoq4WMi3bnHGvffZYBEw5o97KXPXEDQw/6PhnPvsNiCVxNFa6mEoslqF42n9pVS+i7RZvanneHrxaVlJ8cdRAiIt1JyYKI9C6lhTsC53T1Ys0ovLPg4rxLGFxdLfNu/glzr/kefYsm0mfMxkdMVM59m/iAISSHbRY+sxkL7/4t8285i1WzHt0weO0HLxIfNJyCkVs1mLxw76NY8ui1rHzlQQbt+jWWP3MrQ/b/Xla2qxOuKCop36r1yURE8oOqIYlI71FaaMBfgGQ2Fh8kDBxb/eu3Z9btuGM21tHdLBZnzPevoW79ahb+4xKqFlVQMKIIgDXvPN1iqcLo435PYtBwatcs5/O7fkNy+FgKRm/DihfuYtQxFzWZvmDUVmx6whUArJ/zFvGBwwBY9OBlWCzO0IN/QHzA0K7fyPYZCNwAHBJ1ICIi3UElCyLSm/wI2DebKzCj8O/JS8buE3vr7Wyup7vF+g6k7+bFrPvoNcCXOKx9/wX6j28+WUgMGg5AfMAQ+m83icp571OzfAE1Kz5n3k0/Ye60k6hdtZj5t/yU2tXLNsznnGPF83dRuO+xLH/uDobs910G7HgQK1/9Z3Y3su0OLiop/1HUQYiIdAclCyLSO5QWjgKmdseqzCicnvzd5vvG3nqrO9aXLbVrV1C3fjUAddWVrP9kFsnhYwFYX+H/TgwObyNeV7Weusq1G/5e//HrFIwYR8GIIjb/yXTGnnoTY0+9ifigTdj0xKuID9xYYrDmrSfot/XuxPsOxFVXgsXAzP/dc/yhqKR8VNRBiIhkm6ohiUhvcSXQbXVYzBh8e/J3WxxffW762briHtNCtz1qVy9lcfmV4OrA1dF//P7032ZPANb875kmVZBqVi1hyaNXM+qoC6hdu5xF91/sR9TVMWCHA+m3Vettyuuq17P6rScYdbSvpjR4j8NZ9I/fYfEEm3zjl127gZ0zGLgYX1olIpK39JwFEcl/pYVfBh6LYtXOser46nMrcjVhkBbVAbtWTJ3yRtSBiIhki6ohiUh+Ky3sB0yLavVmDLoteWnR/rE301HFIFkTw5dYiYjkLSULIpLvzgIi7erSjEG3JqcWHRB7480o45CsOKiopPybUQchIpItqoYkIvnLlypUACMjjgQA51idqv7VR8/U7bxT1LFIl/oA2LFi6pTqqAMREelqKlkQkXz2I3pIogBgxsCy5GVbTY7NUglDftkWODHqIEREskElCyKSn0oLk8BsYPOoQ2nMOVafVH3O7Kfqdtk56liky3wIjK+YOqU26kBERLqSShZEJF+dQA9MFMCXMNyUvHybg2OvqRed/LENcGTUQYiIdDUlCyKSf0oL40BJ1GG0xIwBNyb/sM0hsVdnRR2LdJkefcyJiHSEkgURaZaZOTO7IuPz2WZW2sFlDTGz0zo4b4WZhT8qONxR+Du9PZoZA/6WvGJbJQx5Y2JRSflhUQchItKVlCyISEsqgW+380K9OUOA0GTBzOJdsHyvtNCA87pseVkWJAzbfTn28utRxyJd4tyoAxAR6UpKFkSkJTXAX4GfNR5hZiPM7D4zezl47RsMLzWzszOme8vMioCpwNZmNsvMLjezyWb2lJndAaSDaR8ws1fN7G0zO7mDMX8NyKmnJZvR/y/JK7f/SuwlJQy5b7+ikvIvRB2EiEhXUbIgIq35M3CcmRU2Gv4n4Ern3B7AEcDfWllOCTDbOTfROXdOMGxP4NfOuR2Czyc553YDdgfONLPhHYj39A7MEzkz+l+fvGq8Eoa88IOoAxAR6SpKFkSkRc65lcCtwJmNRn0RuNbMZgEPAYPNbFA7F/+Sc+7jjM9nmtkbwEx8T0bbtmtppYVjgrhykhn9rk9eNf7Q2IuvRR2LdMrxRSXlBVEHISLSFZQsiEhbXIW/WzogY1gMmBSUFEx0zm3mnFuFr7qUeW7p28Jy19T/YWaT8Rf6k5xzOwOvtzJvmOOArmv/EAEz+k1L/mnCYUoYctlw4JtRByEi0hWULIhIq5xzS4G7aVi94nHgjPoPZjYx+LMC2DUYtiuwZTB8FdBSyUMhsMw5t9bMxgN7dyDUVAfm6XHM6Pfn5J8mTInNfDXqWKTDToo6ABGRrqBkQUTa6gogs1ekM4HdzexNM3sHOCUYfh8wLKiedCrwPoBzbgnwXNDg+fKQ5T8KJMzsTeAifFWktist3AXYsV3z9GBm9Ls2efWOX4u9oIQhN325qKR8bNRBiIh0ljnnoo5BRKTzSgt/Rx52W+kc68+sPuOtf9bts3vUsUi7nVUxdcrVUQchItIZKlkQkXxxZNQBZIMZfa9OXvuFb8SeUwlD7vl61AGIiHSWShZEJPeVFu4EvBF1GNnkHJU/rT49/WDdviphyB3VwCYVU6esjDoQEZGOUsmCiOSDI6IOINvM6HNV8s/Fh8eefSXqWKTNksBXow5CRKQzlCyISD44LOoAuoMZfa5MXlf8rdh/X446Fmmzb0QdgIhIZ6gakojkttLC/sAKIBF1KN3FOSrPrj7lzfvqDtgj6likVcuAkRVTp9REHYiISEeoZEFEct2e9KJEAXwJwx+S1+98ZPzpl6KORVo1FNg56iBERDpKyYKI5Lp9umIhJz24jpGXr+IL161uMu4Pz1diF6xk8dq6JuPmrKjjoLI1TPjzana8bjV/mlm5Ydwx965l4vWrmXj9aoquWsXE6/2yn/u0hp2mrWaPG1bz4VK/zOXrHV+5fQ1tLe01o+DyxF8mHhWfoYSh5+uSY1REJAq96m6ciOSlLrkQO3FikjP2LOCEf6xrMHzOijr+/VENWxRa6HyJGFzx5b7summcVZWO3f66hi9tnWCHEXHuOrL/hul+8dh6Cvv6ZVzxQhX3Hd2PiuWOaS9XccVX+nLR05Wct18fzMLXE8aMgt8n/jrRcC/dXXvQnh3YbOke+wDXRB2EiEhHqGRBRHJXaaEBe3fFog4Yl2BYv6YX6j97bD2//2JfmruE33RQjF03jQMwqI8xYUSMz1Y2LB1wznH3O9Uc+wV/fyYZh3U1sLbakYzD7KV1fLaqjgOL2n//xoyCyxI3TDw6/pRKGHoulSyISM5SsiAiuWx7YHi2Fv7Qe9VsNijGzqPjbZq+Ynkdr8+vZa+xDaf/76e1jBpgbDvcDz93vz6c/M/1XPViFWfsWcCvn1zPRQf16XCcQcKwy3fiT77Y4YVINm1RVFI+JuogREQ6QsmCiOSySdla8NpqxyX/reTCNl7Er65yHHH3Wq46tC+D+zQsh/h7uppjv5Dc8Hni6DgzfziAp1ID+GhZHWMGxXD4Ng7fu38dn69u2jaiNWYkL038bddj408oYeiZVLogIjlJyYKI5LKsXYDNXlrHx8scOweNk+eudOz6lzUsCLmQr671icJxxUm+PSHZYFxNneP+d2s45gvJJvM557j4mUr+74A+XPB0JRdM7sP3dkpy9YtVHYrZjOTvEjfu+r34v2d2aAGSTbtGHYCISEeogbOI5LIuaa8QpnhUnIXnDNrwueiqVbxy8gA26d/wHotzjh88tJ4Jm8T5+aSmpRD/+aiW8ZvEGDu46b2ZsjeqmbJtgqH9jLXVEDP/Wlvd8bjNSF6UuHl3YObttV/K2v6Rdtsu6gBERDpCJQsiksu27qoFHXvfWibduIb3ltQx9o+ruPG15u/uz1tVx2HT1wLw3Jxabnuzmic/rtnQTerDH2y82r/zrYZVkOqtrXaUvVHNaXsUAPDzvQs44u51nPvEek7do+n07WFG4qLEzbsfH39cJQw9h5IFEclJeoKziOSm0sLhwOKow+jJnKPm/JrUy7fWfiVrbTukzdYBAyqmTtE/XRHJKSpZEJFcNTbqAHo6MxIXJMr2SMUffSHqWIR+wOZRByEi0l5KFkQkVylZaAMzEqWJW/f4fvwRJQzRU1UkEck5ShZEJFfpLm0bmZH4beK2PU+KP/J81LH0cl3WxkZEpLsoWRCRXKWShXYwI/5/idv2+kH8YSUM0RkRdQAiIu2lZEFEcpVKFtrJjPhvErfv9aN4uRKGaGTtaeMiItmiZEFEcpVKFjrAjPh5iel7nRz/13NRx9ILKVkQkZyjZEFEcpVKFjrIjPi5iTv2/nH8n0oYupeSBRHJOUoWRCRXqf53J5gRL0n8fdIp8YeUMHQfJQsiknOULIhIrtL5q5PMiP0qceek0+IPKmHoHkoWRCTn6J+tiEgvZkbsnMRdk06PP/Bs1LH0Av2iDkBEpL2ULIhIrnJRB5AvzIidnbh7nzPi/1DCkF3xqAMQEWkvJQsiIoIZsV8k7tnnzPj9ShiyR8mCiOScRNQBiIhI91oeiy37JJlY9FEyuXx2QXL9x8lk3dxEomBxPDZgTezFcQN5aWnUMeYnWw5Tog5CRKRdlCyISK5SNaQQa8xWz0kmPv84mVw+O5lc+1FBsnZOIpFYmIj3XxWLDa2GUZgNBYY2twzrxnh7F1cVdQQiIu2lZEFEJEdUQdW8RGJBRUFy6exkcs3sZKL6k2Qy/nki3ndFLFZYaTbSmQ0BBkYdq4SqiToAEZH2UrIgItID1EHd5/H4558kE0tmFyRXzU4mqyqSSZufSBQsi8cGrzPbpA5GYLYFsEXU8UqHVEcdgIhIeylZEBHpBktjsSWf+nYCKz8M2gl8lkgULInHBq6JxYbVwmjMNgU2jTpWyZq1UQcgItJeShZEJFetBoZEHQTAarNVc5KJhR8nk8tmJ5PrPipI1s1JJOKLNrYTGI3ZcPRQrt5uQdQBiIi0l5IFEclVC4Cx2V5JFVR+lkwsCBKBNbMLkjWfJhL2eSLeb0UsNqTSbBRmg4FB2Y5Fcp6SBRHJOUoWRCRXdfrCqxZqP0/EF1YkkotnFyRXz04mqz5JJpifSPQJ2gmMdDAcs3HAuC6IWXo3JQsiknOULIhIrmr1wmtJLLb4k2Ri0UcFyVUfJpPrKpJJ59sJxAeujdkmtTBS7QSkG82POgARkfZSsiAiOWlZLPbp/ET8w+DBYus+SiZr5yYSiUWJ+IDVsdiw4HkCmwCbRB2rSEAlCyKSc5QsiEhOOmDc2AXANlHHIdIOKlkQkZwTizoAEZEO+ijqAETaSSULIpJzlCyISK76OOoARNppbtQBiIi0l5IFEclVnwK1UQch0kYV6VR6ZdRBiIi0l5IFEclJ6VS6Bng/6jhE2uj1qAMQEekIJQsiksteijoAkTZ6LeoAREQ6QsmCiOQyJQuSK1SyICI5ScmCiOQyJQuSK5QsiEhOUrIgIrnsDWB91EGItOLzdCo9L+ogREQ6QsmCiOSsdCpdDcyKOg6RVqhUQURylpIFEcl1qookPd0rUQcgItJRShZEJNe9GHUAIq14NOoAREQ6SsmCiOS6pwEXdRAizVgKzIw6CBGRjlKyICI5LZ1Kf4aqeUjP9Vg6ldaTxkUkZylZEJF88EDUAYg0ozzqAEREOkPJgojkgweiDkAkRB1qryAiOU7JgojkvHQq/Q7wftRxiDQyM51KL4k6CBGRzlCyICL54oGoAxBpRFWQRCTnKVkQkXzxQNQBiDTyYNQBiIh0lpIFEckXM4H5UQchEpiZTqXfjjoIEZHOUrIgInkhnUo74Pao4xAJ/DXqAEREuoKSBRHJJ9PwPdCIRGkFcFfUQYiIdAUlCyKSN9Kp9MfAw1HHIb3e9HQqvTbqIEREuoKSBRHJN9dGHYD0eqqCJCJ5Q8mCiOSbx4EPog5Ceq2X06n0G1EHISLSVZQsiEheCRo6Xxd1HNJrqVRBRPKKkgURyUc3A2uiDkJ6nfnA9KiDEBHpSkoWRCTvpFPpFUBZ1HFIr3NpOpVeF3UQIiJdScmCiOSrSwBduEl3mYOqIIlIHlKyICJ5KZ1KzwP+FHUc0mtckk6lK6MOQkSkqylZEJF8dhmwLOogJO99DNwUdRAiItmgZEFE8lY6lV4OXBp1HJL3Lk6n0tVRByEikg1KFkQk310DzI06CMlbHwK3Rh2EiEi2KFkQkbyWTqXXA6VRxyF569x0Kl0TdRAiItmiZEFEeoNbgLejDkLyzj/TqfS9UQchIpJNShZEJO+lU+la4GSgLupYJG+sAk6LOggRkWxTsiAivUI6lX4edaUqXee8dCqttjAikveULIhIb/Jr4IOog5CcNxO4LuogRES6gznnoo5BRKTbFJcV7ws8Qy+4WeLqHLNLZ5McmmTcz8ax7pN1zCubh6t2EIcxJ4yh/1b9m8w398a5rJq1isTgBNtesu2G4es+9fPXVdZRMLyAsaeMJd4vzpoP1jCvbB6xZIyxp4ylz6g+1K6pZc60OYz7xTjMrDs3O9uqgV3TqfRbUQciItId8v6fpYhIpnQq/RxwddRxdIcljy+hz5g+Gz4vuHsBIw8fyTYXbcOob41iwV0LQucbut9Qin5R1GT4vJvnMfqo0Wx78bYM3m0wix9e7Nfz6BK2OGMLRh0xiqVPLgVg4UMLGfG1EfmWKABcpkRBRHoTJQsi0hudh+8fP29VL61m1RurGHrA0A3DzIy6db6Nd+26WpJDk6HzDth+APEB8SbDK+dX0n97XxIxYMcBrHx1pR8RB1ftqKuqw+JG5cJKapbVMGD8gC7eqsi9BlwcdRAiIt1JyYKI9DrpVHodcCKQt/3jz79jPqOPGQ0ZN/ZHf3c0C+5awLs/f5cFdy5g1JGj2rXMPmP7sOr1VQCsfHkl1Uv9Q4tHTBnBZzd/xpLHlzD8i8NZeO9CRn57ZJdtSw+xFDgynUpXRh2IiEh3UrIgIr1SUB3pF1HHkQ0rZ60kMThBv6J+DYYvfXIpo48dzfg/jmfT727KZzd91q7ljj1pLEueWMKH539I3XpfigDQb1w/tv7t1mxZsiVVi6pIDE0A8Ol1nzLnL3OoWZHzOVkd8L10Kv1x1IGIiHS3RNQBiIhEJZ1KX11cVrwLvpQhb6z9YC0rX1/JqjdW4aodtetrmfOXOayatYpNj9sUgMF7DG53stBnTB+2PGdLACoXVLLqjVUNxjvnWPjQQrY4bQvm3TaPUYePompxFUv+vaTdpRg9zEXpVPqRqIMQEYmCkgUR6e1OASYAe0UdSFcZfdRoRh81GoDV/1vNkkeXsPmPN+eDcz9gzbtrGDhhIGv+t4aCUQXtWm7NyhoSgxO4OseihxYx7KBhDcYvf3Y5g3YeRHxAnLqqOl92HcP/nbseBS6MOggRkaio61QR6fWKy4rHAK8Am0YdS1erTxbG/Wwca95fw/zp86EOLGmMOWEM/Yr6Ub2sms9u/oyinxcBMGfaHNa8u4aa1T45GHn4SIYdOIzFjy9m6RO+t6PBuw1m1FGjNvR2VFdZxydXfkLR2UVYwljz3hrm3TYPixubn7o5fUb3aS7EnqwC2C2dSi+NOhARkagoWRARAYrLiicBM4D23W6XfLUO2C+dSr8WdSAiIlFSA2cRESCdSr8AnBp1HNIj1ABHK1EQEVGyICKyQTqVvgn4v6jjkEg54IfpVPpfUQciItITKFkQEcmQTqUvRg1ae7Nz0ql0WdRBiIj0FEoWREQaSafS5wOXRh2HdLvSdCp9RdRBiIj0JGrgLCLSjOKy4suBs6OOQ7rFJelU+jdRByEi0tMoWRARaUFxWfFVwFlRxyFZdXk6lf5l1EGIiPREShZERFpRXFZ8LXB61HFIl3PAL9Op9B+iDkREpKdSsiAi0gbFZcXnA6VRxyFdphI4IZ1K3x11ICIiPZmSBRGRNiouK04BNwDJqGORTlkKfDOdSj8bdSAiIj2dkgURkXYoLis+BLgHGBp1LNIhHwFfTafS70cdiIhILlDXqSIi7ZBOpZ8A9gL+F3Us0m4vAZOUKIiItJ2SBRGRdkqn0h8AewN6ym/uuBk4KJ1KL4w6EBGRXKJqSCIiHVRcVhwDfgVcgNox9FTLgR+rIbOISMcoWRAR6aTisuKJwO3AjhGHIg09CxyXTqU/jToQEZFcpWpIIiKdlE6lZwG7AVcAddFGI0AtcD4wWYmCiEjnqGRBRKQLFZcVHwiUAeOijqWXqsCXJjwfdSAiIvlAJQsiIl0onUo/DewE3BJxKL1NFfB7oFiJgohI11HJgohIlhSXFe8P/BHYPepY8tzDwE+DXqpERKQLKVkQEcmi4rJiA74LXApsHnE4+eZ94GfpVPrhqAMREclXShZERLpBcVlxX+BnwLnAoIjDyXWrgIuBq9KpdFXUwYiI5DMlCyIi3ai4rHgkcCHwQyAecTi5ZiUwDbgynUp/HnUwIiK9gZIFEZEIFJcVjwN+gk8aCiMOp6ebD1wFXJ9OpVdGHIuISK+iZEFEJELFZcUDgZOAs4CtIg6np3kfuBy4LZ1KV0YdjIhIb6RkQUSkByguK44B38C3azgg4nCiVAc8DVwLPJBOpfWQOxGRCClZEBHpYYrLiifie1A6CiiKNJjuMwuYDtyZTqXnRhyLiIgElCyIiPRgxWXFuwNHk5+JQwVwBzA9nUq/E3EsIiISQsmCiEiOCBKHo4DDge2ijaZDqoGXgaeAR4Dn06m0/gmJiPRgShZERHJQcVnxKGDfjNeuQDLSoJqqAV7BJwczgOfSqfSaSCMSEZF2UbIgIpIHisuK+wF7AvsBewDb4HtX6tdNISwF3gXeC16z8MnB6m5av4iIZIGSBRGRPFZcVrwpPmnYCtg6eB+Hf4p0f3wy0T/jb2u0iEpgDbACWIJPCpYAc/FJwbvAe+lUenG2t0VERLqfkgUREdkgKKHoh29fsDadStdGHJKIiERIyYKIiIiIiISKRR2AiIiIiIj0TEoWREREREQklJIFERFpEzOrNbNZZvaWmd1jZv3bOf8YM7s3+HuimR2WMe4bZlbS1TGLiEjnqM2CiIi0iZmtds4NDP6eDrzqnPtjB5d1IrC7c+6MLgxRRES6mEoWRESkI/4LbGNmw8zsATN708xmmtlOAGZ2YFAKMcvMXjezQWZWFJRKFAAXAscE448xsxPN7FozKzSzCjOLBcvpb2ZzzCxpZlub2aNm9qqZ/dfMxke4/SIivYKSBRERaRczSwBfBdLABcDrzrmdgPOAW4PJzgZOd85NBPYH1tXP75yrAn4L3OWcm+icuytj3ArgDeDAYNDXgcecc9XAX4GfOOd2C5Z/XdY2UkREAEhEHYCIiOSMfmY2K/j7v8CNwIvAEQDOuSfNbLiZFQLPAX8Mqivd75yba9b4eW/Nugs4BngK+A5wnZkNBPYB7slYTp/Ob5KIiLREyYKIiLTVuqCkYAMLzwCcc26qmZUDhwEzzeyLwPo2ruch4FIzGwbsBjwJDACWN16/iIhkl6ohiYhIZzwDHAdgZpOBxc65lWa2tXMu7Zy7DHgFaNy+YBUwKGyBzrnVwEvAn4B/OedqnXMrgY/N7KhgXWZmO2djg0REZCMlCyIi0hmlwO5m9iYwFUgFw38aNGZ+A99e4ZFG8z0F7FDfwDlkuXcB3wve6x0H/CBY5tvAN7tuM0REJIy6ThURERERkVAqWRARERERkVBKFkREREREJJSSBRERERERCaVkQUREREREQilZEBERERGRUEoWREREREQklJIFEREREREJpWRBRERERERCKVkQEREREZFQShZERERERCSUkgUREREREQmlZEFEREREREIpWRARERERkVBKFkREREREJJSSBRERERERCaVkQUREREREQv0/fwm7VStB5YAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#check the Distributin of Sentiments\n",
    "category = ['Negative','Neutral','Positive']\n",
    "values = [data.sentiment.str.count(\"Negative\").sum(),data.sentiment.str.count(\"Neutral\").sum(),data.sentiment.str.count(\"Positive\").sum()]\n",
    "plt.pie(values, labels= category,autopct ='%0.2f%%')\n",
    "plt.title('------------------- percentage Distribution by Sentiment Category -------------------',fontsize=20,color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m------------------- Special characters and punctuation cleaning operations completed. ------------------- \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "We will now clean the data by removing the special characters.\n",
    "\n",
    "\"\"\"\n",
    "#set up punctuations we want to be replaced\n",
    "REPLACE_NO_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\')|(\\?)|(\\,)|(\\\")|(\\|)|(\\()|(\\))|(\\[)|(\\])|(\\%)|(\\$)|(\\>)|(\\<)|(\\{)|(\\})|(\\=)|(\\#)|(\\ยง)\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s/><br\\s/?)|(-)|(/)|(:).\")\n",
    "print(f\"{Fore.BLUE}------------------- Special characters and punctuation cleaning operations completed. ------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m------------------- preparation of the cleaning functions completed. ------------------- \n"
     ]
    }
   ],
   "source": [
    "# custum function to clean the dataset (combining tweet_preprocessor and reguar expression)\n",
    "def clean_tweets(df):\n",
    "  tempArr = []\n",
    "  for line in df:\n",
    "    # send to tweet_processor\n",
    "    tmpL = p.clean(line)\n",
    "    # remove puctuation\n",
    "    tmpL = REPLACE_NO_SPACE.sub(\"\", tmpL.lower()) # convert all tweets to lower cases\n",
    "    tmpL = REPLACE_WITH_SPACE.sub(\" \", tmpL)\n",
    "    tempArr.append(tmpL)\n",
    "  return tempArr\n",
    "\n",
    "print(f\"{Fore.BLUE}------------------- preparation of the cleaning functions completed. ------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m------------------- The message cleaning operation is complete. ------------------- \n"
     ]
    }
   ],
   "source": [
    "# Cleaning up tweets\n",
    "clean_tweet = clean_tweets(data[\"message\"])\n",
    "print(f\"{Fore.BLUE}------------------- The message cleaning operation is complete. ------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m------------------- The clean data column has been successfully added to the dataset. ------------------- \n"
     ]
    }
   ],
   "source": [
    "# append cleaned tweets to the training data\n",
    "clean_tweet = pd.DataFrame(clean_tweet)\n",
    "data[\"clean\"] = clean_tweet\n",
    "print(f\"{Fore.BLUE}------------------- The clean data column has been successfully added to the dataset. ------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m------------------- overview of the dataset with the clean_data column. ------------------- \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>We need to be vaccinated to protect all person...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>we need to be vaccinated to protect all person...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>it is a pleasure to see how the govement are w...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>it is a pleasure to see how the govement are w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>The most popular vaccine that i know is Modern...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>the most popular vaccine that i know is modern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Of course we need to be vaccinated if we want ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>of course we need to be vaccinated if we want ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            message sentiment  \\\n",
       "0   1  We need to be vaccinated to protect all person...  Positive   \n",
       "1   2  it is a pleasure to see how the govement are w...  Positive   \n",
       "2   3                                          Negative   Negative   \n",
       "3   4  The most popular vaccine that i know is Modern...  Positive   \n",
       "4   5  Of course we need to be vaccinated if we want ...  Positive   \n",
       "\n",
       "                                               clean  \n",
       "0  we need to be vaccinated to protect all person...  \n",
       "1  it is a pleasure to see how the govement are w...  \n",
       "2                                           negative  \n",
       "3  the most popular vaccine that i know is modern...  \n",
       "4  of course we need to be vaccinated if we want ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare the cleaned and uncleaned tweets\n",
    "print(f\"{Fore.BLUE}------------------- overview of the dataset with the clean_data column. ------------------- \")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function who help to count unique words\n",
    "\n",
    "def wordCount(text):\n",
    "    count = Counter()\n",
    "    for i in text.values:\n",
    "        for word in i.split():\n",
    "            count[word]+=1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m------------------- The column 'clean' contains:  2540  unique words ------------------- \n"
     ]
    }
   ],
   "source": [
    "# count the number of unique words contained in the set of cleaned expressions. \n",
    "text= data.clean\n",
    "counter = wordCount(text)\n",
    "print(f\"{Fore.BLUE}------------------- The column 'clean' contains: \",len(counter),\" unique words ------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive [0 0 1]\n",
      "Positive [0 0 1]\n",
      "Negative [1 0 0]\n",
      "Positive [0 0 1]\n",
      "Positive [0 0 1]\n",
      "Neutral [0 1 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert sentiment into numeric value\n",
    "y = pd.get_dummies(data['sentiment']).values\n",
    "[print(data['sentiment'][i], y[i]) for i in range(0,6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m------------------- The data was successfully split. ------------------- \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "In this section, we will divide the file (the 'clean' column) \n",
    "into two parts: one part for training and one part for testing.\n",
    "\n",
    "X_train ==> train_sentences\n",
    "X_test ==> test_sentences\n",
    "y_train ==> train_labels\n",
    "y_test ==> test_labels\n",
    "\n",
    "\"\"\"\n",
    "X = data['clean']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "print(f\"{Fore.GREEN}------------------- The data was successfully split. ------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m------------------- Operations completed. ------------------- \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "We will now define the maximum length of a sentence in terms of the number of words it can contain.\n",
    "But first, we define the word count as the number of unique words.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# define the number of words.\n",
    "num_words = len(counter)\n",
    "# maximum number of words in a sentence.\n",
    "max_length = 42\n",
    "print(f\"{Fore.GREEN}------------------- Operations completed. ------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m------------------- tokenization process complete. ------------------- \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "We will now tokenize the text ('clean' column):\n",
    "This means that a unique number is associated with each unique word in the text.\n",
    "\"\"\"\n",
    "\n",
    "tokenizer = Tokenizer(num_words=num_words, split=\" \")\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "print(f\"{Fore.GREEN}------------------- tokenization process complete. ------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m------------------- visualization of the result obtained after tokenization. ------------------- \n",
      "\u001b[30m {'the': 1, 'to': 2, 'i': 3, 'vaccine': 4, 'is': 5, 'not': 6, 'of': 7, 'and': 8, 'a': 9, 'it': 10, 'vaccinated': 11, 'in': 12, 'covid': 13, 'for': 14, 'are': 15, 'that': 16, 'vaccines': 17, 'this': 18, 'be': 19, 'get': 20, 'will': 21, 'do': 22, 'am': 23, 'have': 24, 'my': 25, 'we': 26, 'so': 27, 'all': 28, 'no': 29, 'you': 30, 'people': 31, '19': 32, 'as': 33, 'but': 34, 'with': 35, 'they': 36, 'us': 37, 'on': 38, 'if': 39, 'effects': 40, 'who': 41, 'at': 42, 'side': 43, 'first': 44, 'there': 45, 'vaccination': 46, 'more': 47, 'pfizer': 48, 'take': 49, 'was': 50, 'me': 51, 'want': 52, 'or': 53, 'about': 54, 'think': 55, 'good': 56, 'against': 57, 'can': 58, 'just': 59, 'virus': 60, 'these': 61, 'has': 62, 'our': 63, 'because': 64, 'their': 65, 'been': 66, 'by': 67, 'today': 68, 'dose': 69, 'does': 70, 'after': 71, 'why': 72, 'getting': 73, 'what': 74, 'everyone': 75, 'when': 76, 'very': 77, 'one': 78, 'would': 79, 'should': 80, 'know': 81, 'from': 82, 'got': 83, 'than': 84, 'let': 85, 'doses': 86, 'now': 87, 'going': 88, 'lives': 89, 'any': 90, 'like': 91, 'make': 92, 'only': 93, 'without': 94, 'how': 95, 'those': 96, 'go': 97, 'stop': 98, 'your': 99, 'time': 100, 'still': 101, 'many': 102, 'them': 103, 'need': 104, 'free': 105, 'up': 106, 'even': 107, 'world': 108, 'health': 109, 'being': 110, 'never': 111, 'two': 112, 'had': 113, 'disease': 114, 'pandemic': 115, 'life': 116, 'an': 117, 'some': 118, 'coronavirus': 119, 'received': 120, 'day': 121, 'thing': 122, 'other': 123, 'out': 124, 'which': 125, 'vaccinate': 126, 'enough': 127, 'save': 128, 'nothing': 129, 'much': 130, 'companies': 131, 'effective': 132, 'were': 133, 'risk': 134, 'thank': 135, 'most': 136, 'case': 137, 'believe': 138, 'way': 139, 'did': 140, 'long': 141, 'corona': 142, 'see': 143, 'sure': 144, 'moderna': 145, 'well': 146, 'say': 147, 'its': 148, 'wait': 149, 'years': 150, 'prices': 151, 'money': 152, 'safe': 153, 'also': 154, 'happy': 155, 'allergic': 156, 'children': 157, 'trust': 158, 'receive': 159, 'protect': 160, 'really': 161, 'biontech': 162, 'cannot': 163, 'must': 164, 'new': 165, 'live': 166, 'use': 167, 'caign': 168, 'thanks': 169, 'far': 170, 'choice': 171, 'better': 172, 'bad': 173, 'consequences': 174, 'point': 175, 'same': 176, 'year': 177, 'problem': 178, 'others': 179, 'feeling': 180, 'injection': 181, 'shot': 182, 'end': 183, 'taken': 184, 'real': 185, 'said': 186, 'afraid': 187, 'term': 188, 'important': 189, 'ones': 190, 'possible': 191, 'less': 192, 'taking': 193, 'then': 194, 'yes': 195, 'news': 196, 'whether': 197, 'maybe': 198, 'prevent': 199, 'die': 200, 'best': 201, 'family': 202, 'please': 203, 'might': 204, 'reaction': 205, 'necessary': 206, 'severe': 207, 'care': 208, 'second': 209, 'laboratories': 210, 'finally': 211, 'able': 212, 'before': 213, 'again': 214, 'myself': 215, 'hope': 216, 'big': 217, 'young': 218, 'pharmaceutical': 219, 'reactions': 220, 'soon': 221, 'here': 222, 'great': 223, 'business': 224, 'useful': 225, 'find': 226, 'astrazeneca': 227, 'done': 228, 'yet': 229, 'person': 230, 'future': 231, 'could': 232, 'yourself': 233, 'fed': 234, 'cases': 235, 'question': 236, 'testing': 237, 'safety': 238, 'too': 239, 'covid19': 240, 'excited': 241, 'work': 242, 'week': 243, 'scientists': 244, 'anyone': 245, 'working': 246, 'mind': 247, 'come': 248, 'solution': 249, 'normal': 250, 'population': 251, 'since': 252, 'tests': 253, 'last': 254, 'mrna': 255, 'decision': 256, 'quickly': 257, 'negative': 258, 'country': 259, 'his': 260, 'already': 261, 'shows': 262, 'help': 263, 'media': 264, 'serious': 265, 'government': 266, 'public': 267, 'encourage': 268, 'remain': 269, 'im': 270, 'grateful': 271, 'frankly': 272, 'every': 273, 'approves': 274, 'into': 275, 'million': 276, 'danger': 277, 'st': 278, 'given': 279, 'ive': 280, 'made': 281, 'old': 282, 'yesterday': 283, 'lot': 284, 'days': 285, 'always': 286, 'keep': 287, 'authorities': 288, 'g': 289, 'right': 290, 'own': 291, 'rather': 292, 'option': 293, 'propaganda': 294, 'turn': 295, 'order': 296, 'drugs': 297, 'drug': 298, 'injected': 299, 'course': 300, 'develop': 301, 'five': 302, 'continue': 303, 'put': 304, 'personally': 305, 'fact': 306, 'emergency': 307, 'hospital': 308, 'off': 309, 'part': 310, 'until': 311, 'supermarket': 312, 'information': 313, 'while': 314, 'around': 315, 'immunity': 316, 'prefer': 317, 'hours': 318, 'fine': 319, 'another': 320, 'down': 321, 'next': 322, 'gates': 323, 'effect': 324, 'seen': 325, 'set': 326, 't': 327, 'between': 328, 'respect': 329, 'doctors': 330, 'vaccin': 331, 'later': 332, 'alone': 333, 'vaccinations': 334, 'immune': 335, 'fear': 336, 'adverse': 337, 'few': 338, 'effectiveness': 339, 'anti': 340, 'makes': 341, 'risks': 342, 'he': 343, 'wonder': 344, 'reduce': 345, 'cure': 346, 'patients': 347, 'africa': 348, 'ourselves': 349, 'share': 350, 'over': 351, 'humanity': 352, 'contamination': 353, 'change': 354, 'administration': 355, 'anyway': 356, 'data': 357, 'taxpayers': 358, 'rate': 359, 'shame': 360, 'situation': 361, 'stay': 362, 'social': 363, 'reason': 364, 'known': 365, 'give': 366, 'ever': 367, 'price': 368, 'cost': 369, 'everything': 370, 'approved': 371, 'available': 372, 'body': 373, 'kind': 374, 'exle': 375, 'gets': 376, 'loved': 377, 'months': 378, 'found': 379, 'rid': 380, 'programme': 381, 'residents': 382, 'stock': 383, 'least': 384, 'works': 385, 'developed': 386, 'advise': 387, 'nurse': 388, 'opinion': 389, 'company': 390, 'beginning': 391, 'natural': 392, 'access': 393, 'certainly': 394, 'millions': 395, 'pharma': 396, 'politicians': 397, 'arrived': 398, 'says': 399, 'arrive': 400, 'night': 401, 'bill': 402, 'crisis': 403, 'including': 404, 'mass': 405, 'form': 406, 'afterwards': 407, 'hospitals': 408, 'infected': 409, 'science': 410, 'passport': 411, 'test': 412, 'choose': 413, 'conspiracy': 414, 'approve': 415, 'away': 416, 'protein': 417, 'wear': 418, 'contagious': 419, 'otherwise': 420, 'barrier': 421, 'fighting': 422, 'lose': 423, 'light': 424, 'mean': 425, 'present': 426, 'deaths': 427, 'food': 428, 'seems': 429, 'comes': 430, 'doing': 431, 'something': 432, 'back': 433, 'decide': 434, 'spread': 435, 'weeks': 436, 'according': 437, 'likely': 438, 'fake': 439, 'healthcare': 440, 'opportunity': 441, 'themselves': 442, 'friends': 443, 'avoid': 444, 'global': 445, 'dying': 446, 'explain': 447, 'variants': 448, 'matter': 449, 'human': 450, 'moment': 451, 'happened': 452, 'kiss': 453, 'difficult': 454, 'interested': 455, 'except': 456, 'diseases': 457, 'story': 458, 'variant': 459, 'therefore': 460, 'using': 461, 'favour': 462, 'shown': 463, 'unexpected': 464, 'impossible': 465, 'little': 466, 'trump': 467, 'affect': 468, 'took': 469, 'useless': 470, 'stand': 471, 'create': 472, 'market': 473, 'forms': 474, 'inject': 475, 'pseudo': 476, 'democrats': 477, 'support': 478, 'harmful': 479, 'where': 480, 'experts': 481, 'show': 482, 'simply': 483, 'private': 484, 'allowed': 485, 'uk': 486, 'clear': 487, 'joe': 488, 'biden': 489, 'pfizers': 490, 'minutes': 491, 'refuse': 492, 'parents': 493, 'wish': 494, 'begins': 495, 'waiting': 496, 'scams': 497, 'administering': 498, 'listen': 499, 'travel': 500, 'goes': 501, 'thinking': 502, 'proud': 503, 'honest': 504, 'capitalism': 505, 'developing': 506, 'hand': 507, 'sanitizer': 508, 'compulsory': 509, 'means': 510, 'moreover': 511, 'panic': 512, 'evil': 513, 'third': 514, 'allow': 515, 'thankful': 516, 'administered': 517, 'wants': 518, 'control': 519, 'cause': 520, 'reliable': 521, 'trials': 522, 'dubai': 523, 'announced': 524, 'positive': 525, 'receiving': 526, 'idea': 527, 'grocery': 528, 'employees': 529, 'stores': 530, 'possibility': 531, 'saved': 532, 'scary': 533, 'happens': 534, 'large': 535, 'frightening': 536, 'scientific': 537, 'research': 538, 'imagine': 539, 'especially': 540, 'history': 541, 'room': 542, 'such': 543, 'roll': 544, 'bit': 545, 'zero': 546, 'nice': 547, 'approval': 548, 'response': 549, 'countries': 550, 'older': 551, 'system': 552, 'treatment': 553, 'measures': 554, 'ready': 555, 'rich': 556, 'profit': 557, 'view': 558, 'etc': 559, 'needs': 560, 'changed': 561, 'self': 562, 'called': 563, 'experimental': 564, 'heres': 565, 'authorized': 566, 'pessimistic': 567, 'raise': 568, 'whole': 569, 'causing': 570, 'via': 571, 'realy': 572, 'force': 573, 'asked': 574, 'essential': 575, 'workers': 576, 'remember': 577, 'angry': 578, 'gov': 579, 'lets': 580, 'charge': 581, 'despite': 582, 'fda': 583, 'russian': 584, 'affected': 585, 'together': 586, 'doubt': 587, 'longer': 588, 'type': 589, 'true': 590, 'rna': 591, 'technology': 592, 'potential': 593, 'consumer': 594, 'conditions': 595, 'confinement': 596, 'quite': 597, 'follow': 598, 'told': 599, 'may': 600, 'nobody': 601, 'authorizes': 602, 'times': 603, 'tired': 604, 'west': 605, 'questions': 606, 'usa': 607, 'almost': 608, 'mother': 609, 'ahead': 610, 'problems': 611, 'treatments': 612, 'dr': 613, 'both': 614, 'produce': 615, 'past': 616, 'industry': 617, 'products': 618, 'coming': 619, 'helps': 620, 'cancer': 621, 'rights': 622, 'community': 623, 'look': 624, 'gestures': 625, 'imperative': 626, 'name': 627, 'suggests': 628, 'predict': 629, 'leaky': 630, 'transmission': 631, 'shed': 632, 'reports': 633, 'reliability': 634, 'hesitate': 635, 'measure': 636, 'barier': 637, 'containment': 638, 'hospitalized': 639, 'affraid': 640, 'tetanus': 641, 'procurement': 642, 'pay': 643, 'r': 644, 'd': 645, 'manufacturing': 646, 'makers': 647, 'costs': 648, 'commercial': 649, 'london': 650, 'press': 651, 'linked': 652, 'home': 653, 'design': 654, 'incentives': 655, 'ventilators': 656, 'economists': 657, 'navigate': 658, 'specialy': 659, 'teenagers': 660, 'mine': 661, 'hands': 662, 'mouth': 663, 'biggest': 664, 'fought': 665, 'affordable': 666, 'efficacy': 667, 'start': 668, 'refused': 669, 'careful': 670, 'bosses': 671, 'poison': 672, 'ass': 673, 'toxic': 674, 'smallpox': 675, 'worker': 676, 'suffers': 677, 'bion': 678, 'once': 679, 'mask': 680, 'currently': 681, 'started': 682, 'traditional': 683, 'doctor': 684, 'wouldnt': 685, 'certainty': 686, 'protects': 687, 'tells': 688, 'read': 689, 'distancing': 690, 'happening': 691, 'she': 692, 'bullshit': 693, 'protection': 694, 'caught': 695, 'protected': 696, 'wanting': 697, 'post': 698, 'death': 699, 'run': 700, 'cant': 701, 'herd': 702, 'nonsense': 703, 'debate': 704, 'common': 705, 'during': 706, 'power': 707, 'definitely': 708, 'flexible': 709, 'broken': 710, 'johnson': 711, 'economy': 712, 'hostile': 713, 'morning': 714, 'offer': 715, 'confident': 716, 'humans': 717, 'prevents': 718, 'worse': 719, 'toll': 720, 'don': 721, 'newly': 722, 'interest': 723, 'giving': 724, 'ok': 725, 'whats': 726, 'poisson': 727, 'major': 728, 'condition': 729, 'damn': 730, 'scale': 731, 'assure': 732, 'invented': 733, 'contribute': 734, 'unknown': 735, 'impact': 736, 'saying': 737, 'based': 738, 'labs': 739, 'billions': 740, 'become': 741, 'receives': 742, 'greatest': 743, 'record': 744, 'african': 745, 'medicines': 746, 'ridiculous': 747, 'seem': 748, 'holiday': 749, 'special': 750, 'lockdown': 751, 'distributed': 752, 'substance': 753, 'unvaccinated': 754, 'dangerous': 755, 'european': 756, 'united': 757, 'site': 758, 'freedom': 759, 'leave': 760, 'transmitting': 761, 'spike': 762, 'governments': 763, 'age': 764, 'object': 765, 'ppe': 766, 'tell': 767, 'patents': 768, 'masks': 769, 'created': 770, 'fully': 771, 'europe': 772, 'december': 773, 'green': 774, 'suffered': 775, 'making': 776, 'high': 777, 're': 778, 'adapt': 779, 'supply': 780, 'apparently': 781, 'mutation': 782, 'multiple': 783, 'difference': 784, 'worries': 785, 'proven': 786, 'requires': 787, 'each': 788, 'wednesday': 789, 'basic': 790, 'concern': 791, 'things': 792, 'judgment': 793, 'unsafe': 794, 'worst': 795, 'feels': 796, 'historic': 797, 'fresh': 798, 'awareness': 799, 'tunnel': 800, 'used': 801, 'relatives': 802, 'kills': 803, 'convinced': 804, 'experience': 805, 'nd': 806, 'vaxxers': 807, 'knows': 808, 'school': 809, 'bar': 810, 'through': 811, 'putting': 812, 'excellent': 813, 'latest': 814, 'involved': 815, 'experiencing': 816, 'plants': 817, 'majority': 818, 'investor': 819, 'paywall': 820, 'warning': 821, 'offering': 822, 'fight': 823, 'number': 824, 'increasing': 825, 'shipments': 826, 'canada': 827, 'sunday': 828, 'assume': 829, 'guinea': 830, 'amazing': 831, 'stopped': 832, 'development': 833, 'stocks': 834, 'knew': 835, 'illness': 836, 'friend': 837, 'area': 838, 'indeed': 839, 'wiser': 840, 'allergy': 841, 'low': 842, 'rush': 843, 'expected': 844, 'particular': 845, 'lost': 846, 'member': 847, 'fighter': 848, 'planes': 849, 'missiles': 850, 'weapons': 851, 'controlled': 852, 'resistant': 853, 'cool': 854, 'return': 855, 'advice': 856, 'suspicious': 857, 'success': 858, 'animals': 859, 'regulator': 860, 'friday': 861, 'theres': 862, 'autoimmune': 863, 'advised': 864, 'feel': 865, 'becoming': 866, 'women': 867, 'destroy': 868, 'resuscitation': 869, 'super': 870, 'keeping': 871, 'ways': 872, 'hesitating': 873, 'neighbours': 874, 'biontechs': 875, 'dont': 876, 'man': 877, 'listening': 878, 'him': 879, 'beat': 880, 'unnecessary': 881, 'call': 882, 'deadly': 883, 'pity': 884, 'vaccinating': 885, 'june': 886, 'investigating': 887, 'mandatory': 888, 'gonna': 889, 'anyways': 890, 'chinese': 891, 'americans': 892, 'rollout': 893, 'ensure': 894, 'treated': 895, 'hearing': 896, 'popular': 897, 'compared': 898, 'china': 899, 'chain': 900, 'producing': 901, 'someone': 902, 'jennifer': 903, 'haller': 904, 'bravery': 905, 'spirit': 906, 'six': 907, 'pretty': 908, 'responsible': 909, 'talk': 910, 'teach': 911, 'cells': 912, 'trigger': 913, 'medical': 914, 'needed': 915, 'leading': 916, 'update': 917, 'beware': 918, 'fraudulent': 919, 'try': 920, 'touch': 921, 'gene': 922, 'therapy': 923, 'chip': 924, 'honestly': 925, 'credible': 926, 'tested': 927, 'sick': 928, 'lucky': 929, 'january': 930, 'cobbled': 931, 'though': 932, 'worried': 933, 'decided': 934, 'respecting': 935, 'citizen': 936, 'sudden': 937, 'bacterial': 938, 'paul': 939, 'respected': 940, 'hesitation': 941, 'favor': 942, 'rodents': 943, 'local': 944, 'rare': 945, 'wife': 946, 'thousands': 947, 'hiv': 948, 'idiot': 949, 'alaskan': 950, 'forever': 951, 'anything': 952, 'gain': 953, 'matters': 954, 'stories': 955, 'looking': 956, 'begin': 957, 'christmas': 958, 'suffering': 959, 'confirmed': 960, 'hurry': 961, 'researchers': 962, 'hard': 963, 'law': 964, 'preserve': 965, 'close': 966, 'came': 967, 'county': 968, 'false': 969, 'production': 970, 'quality': 971, 'russia': 972, 'thats': 973, 'pregnant': 974, 'understand': 975, 'suffer': 976, 'pleasure': 977, 'glad': 978, 'moderne': 979, 'woman': 980, 'wary': 981, 'scam': 982, 'damage': 983, 'pharmacists': 984, 'scare': 985, 'capable': 986, 'decimating': 987, 'act': 988, 'foreseen': 989, 'interessed': 990, 'york': 991, 'city': 992, 'uncertain': 993, 'cameroon': 994, 'claiming': 995, 'occurred': 996, 'tuesday': 997, 'heath': 998, 'hurt': 999, 'rusty': 1000, 'piece': 1001, 'iron': 1002, 'financial': 1003, 'scandal': 1004, 'survival': 1005, 'clearly': 1006, 'operation': 1007, 'baby': 1008, 'hear': 1009, 'professor': 1010, 'eyeing': 1011, 'urges': 1012, 'canadians': 1013, 'reasonable': 1014, 'whose': 1015, 'medium': 1016, 'writing': 1017, 'book': 1018, 'properly': 1019, 'washed': 1020, 'nose': 1021, 'hate': 1022, 'heist': 1023, 'looting': 1024, 'half': 1025, 'africas': 1026, 'resources': 1027, 'drop': 1028, 'looked': 1029, 'nonprofits': 1030, 'medicaid': 1031, 'thankfully': 1032, 'pleased': 1033, 'insisting': 1034, 'wors': 1035, 'recherches': 1036, 'basis': 1037, 'property': 1038, 'consent': 1039, 'wonderful': 1040, 'speaking': 1041, 'besides': 1042, 'forgot': 1043, 'iran': 1044, 'helpfully': 1045, 'consideration': 1046, 'stick': 1047, 'delaware': 1048, 'honored': 1049, 'gettin': 1050, 'mankind': 1051, 'wreaked': 1052, 'havoc': 1053, 'centuries': 1054, 'quiet': 1055, 'tonight': 1056, 'flexing': 1057, 'complaining': 1058, 'wearing': 1059, 'piss': 1060, 'totally': 1061, 'irresponsible': 1062, 'reassuring': 1063, 'undecided': 1064, 'quebec': 1065, 'maimonides': 1066, 'among': 1067, 'seniors': 1068, 'region': 1069, 'todayimpressive': 1070, 'resource': 1071, 'mobilization': 1072, 'massive': 1073, 'novel': 1074, 'minister': 1075, 'proliferate': 1076, 'watch': 1077, 'victim': 1078, 'donation': 1079, 'mule': 1080, 'recruitment': 1081, 'tactics': 1082, 'vogue': 1083, 'coronavirusdo': 1084, 'fooled': 1085, 'propagation': 1086, 'exists': 1087, 'optimistic': 1088, 'takes': 1089, 'began': 1090, 'ago': 1091, 'jabs': 1092, 'conscience': 1093, 'wont': 1094, 'report': 1095, 'automatically': 1096, 'enters': 1097, 'bloodstream': 1098, 'adds': 1099, 'suppository': 1100, 'icu': 1101, 'sandra': 1102, 'lindsay': 1103, 'waking': 1104, 'viruses': 1105, 'astra': 1106, 'astrazeneka': 1107, 'controversy': 1108, 'horrible': 1109, 'marketing': 1110, 'misleading': 1111, 'produces': 1112, 'claim': 1113, 'built': 1114, 'employer': 1115, 'inform': 1116, 'epidemic': 1117, 'observe': 1118, 'contracting': 1119, 'civic': 1120, 'minded': 1121, 'fragile': 1122, 'discussing': 1123, 'annihilate': 1124, 'imminent': 1125, 'paranormal': 1126, 'girl': 1127, 'kids': 1128, 'towards': 1129, 'poisons': 1130, 'left': 1131, 'flocking': 1132, 'tragedy': 1133, 'corporate': 1134, 'greed': 1135, 'astraastrazeneka': 1136, 'kill': 1137, 'officially': 1138, 'senators': 1139, 'insider': 1140, 'trading': 1141, 'doubles': 1142, 'capitol': 1143, 'hill': 1144, 'folk': 1145, 'hopeful': 1146, 'showed': 1147, 'god': 1148, 'spoke': 1149, 'dull': 1150, 'achey': 1151, 'sore': 1152, 'arm': 1153, 'deltoid': 1154, 'nor': 1155, 'magnitude': 1156, 'action': 1157, 'brake': 1158, 'deeply': 1159, 'types': 1160, 'ligma': 1161, 'fast': 1162, 'clinical': 1163, 'skeptics': 1164, 'mama': 1165, 'michel': 1166, 'rages': 1167, 'poooor': 1168, 'yay': 1169, 'ummc': 1170, 'store': 1171, 'employee': 1172, 'respectfully': 1173, 'request': 1174, 'truck': 1175, 'drivers': 1176, 'managers': 1177, 'asap': 1178, 'continuation': 1179, 'percent': 1180, 'saudis': 1181, 'expats': 1182, 'lucrative': 1183, 'model': 1184, 'permanent': 1185, 'men': 1186, 'enjoy': 1187, 'holidays': 1188, 'bonus': 1189, 'delighted': 1190, 'sometimes': 1191, 'kinda': 1192, 'reassured': 1193, 'shall': 1194, 'secondary': 1195, 'departure': 1196, 'capitalists': 1197, 'charade': 1198, 'emotional': 1199, 'credibility': 1200, 'models': 1201, 'dead': 1202, 'heavily': 1203, 'convicted': 1204, 'fraud': 1205, 'stake': 1206, 'motivated': 1207, 'nura': 1208, 'emir': 1209, 'festi': 1210, 'brave': 1211, 'cat': 1212, 'mouse': 1213, 'game': 1214, 'obviously': 1215, 'iv': 1216, 'state': 1217, 'relevant': 1218, 'eric': 1219, 'shawn': 1220, 'herein': 1221, 'chloroquine': 1222, 'eyes': 1223, 'sanitary': 1224, 'leaders': 1225, 'vacations': 1226, 'altruists': 1227, '21': 1228, 'month': 1229, 'formally': 1230, 'casts': 1231, 'votes': 1232, 'responsibility': 1233, 'poorly': 1234, 'researched': 1235, 'realise': 1236, 'rome': 1237, 'commission': 1238, 'eu': 1239, 'tend': 1240, 'ignoramuses': 1241, 'charlatans': 1242, 'theorists': 1243, 'sorry': 1244, 'efforts': 1245, 'kingdom': 1246, 'scotland': 1247, 'place': 1248, 'key': 1249, 'tiniest': 1250, 'soreness': 1251, 'invite': 1252, 'regain': 1253, 'throwing': 1254, 'shitty': 1255, 'wrap': 1256, 'process': 1257, 'having': 1258, 'induce': 1259, 'carried': 1260, 'speed': 1261, 'forget': 1262, 'tragic': 1263, 'episode': 1264, 'century': 1265, 'recover': 1266, 'recommended': 1267, 'persons': 1268, 'under': 1269, 'maturity': 1270, 'humanitarian': 1271, 'liable': 1272, 'strong': 1273, 'denial': 1274, 'preventive': 1275, 'curative': 1276, 'infancy': 1277, 'inspire': 1278, 'socially': 1279, 'distant': 1280, 'fail': 1281, 'publicity': 1282, 'warned': 1283, 'desolation': 1284, 'bottom': 1285, 'top': 1286, 'billionaires': 1287, 'naivety': 1288, 'tomorrow': 1289, 'meeting': 1290, 'review': 1291, 'possibly': 1292, 'approving': 1293, 'bumped': 1294, 'oregon': 1295, 'peaceful': 1296, 'proper': 1297, 'bra': 1298, 'agree': 1299, 'taxpayer': 1300, 'impression': 1301, 'maximum': 1302, 'leads': 1303, 'whatever': 1304, 'immunizes': 1305, 'partnership': 1306, 'count': 1307, 'experiment': 1308, 'monopolies': 1309, 'unaffordable': 1310, 'vulnerable': 1311, 'amoral': 1312, 'dangerously': 1313, 'stupid': 1314, 'bc': 1315, 'defeat': 1316, 'definition': 1317, 'vocation': 1318, 'mutating': 1319, 'empty': 1320, 'detected': 1321, 'clue': 1322, 'thesis': 1323, 'convincing': 1324, 'contradictions': 1325, 'difficulty': 1326, 'picking': 1327, 'solved': 1328, 'operator': 1329, 'join': 1330, 'ranks': 1331, 'energy': 1332, 'shop': 1333, 'restaurant': 1334, 'collect': 1335, 'barely': 1336, 'text': 1337, 'altruism': 1338, 'imposed': 1339, 'fundamental': 1340, 'organisation': 1341, 'agns': 1342, 'buzyn': 1343, 'laugh': 1344, 'loud': 1345, 'names': 1346, 'gloves': 1347, 'volatility': 1348, 'levels': 1349, 'growing': 1350, 'tiktok': 1351, 'losing': 1352, 'minds': 1353, 'handled': 1354, 'polished': 1355, 'theories': 1356, 'neither': 1357, 'produced': 1358, 'image': 1359, 'compares': 1360, 'scenario': 1361, 'exciting': 1362, 'fair': 1363, 'equitable': 1364, 'phase': 1365, 'dec': 1366, 'sat': 1367, 'cup': 1368, 'coffee': 1369, 'witness': 1370, 'choices': 1371, 'trustworthy': 1372, 'menstruation': 1373, 'expectedcovid': 1374, 'superior': 1375, 'batch': 1376, 'arrives': 1377, 'oman': 1378, 'hot': 1379, 'commodity': 1380, 'primarily': 1381, 'destined': 1382, 'u': 1383, 'becoime': 1384, 'desired': 1385, 'faster': 1386, 'spy': 1387, 'underestimate': 1388, 'single': 1389, 'wonders': 1390, 'certificate': 1391, 'fly': 1392, 'cruise': 1393, 'subway': 1394, 'concert': 1395, 'road': 1396, 'pressure': 1397, 'thead': 1398, 'epidemiologist': 1399, 'chance': 1400, 'armor': 1401, 'recalls': 1402, 'supposed': 1403, 'autumn': 1404, 'else': 1405, 'undergo': 1406, 'huge': 1407, 'ensuring': 1408, 'governors': 1409, 'mayors': 1410, 'shops': 1411, 'concessions': 1412, 'hardware': 1413, 'determining': 1414, 'similar': 1415, 'artemesia': 1416, 'officialized': 1417, 'organizations': 1418, 'neglected': 1419, 'allergies': 1420, 'tolerating': 1421, 'building': 1422, 'trial': 1423, 'extending': 1424, 'effort': 1425, 'spending': 1426, 'afternoon': 1427, 'volunteering': 1428, 'prescribe': 1429, 'following': 1430, 'helped': 1431, 'sydney': 1432, 'interact': 1433, 'small': 1434, 'summer': 1435, 'officials': 1436, 'medicare': 1437, 'claims': 1438, 'identity': 1439, 'theft': 1440, 'schemes': 1441, 'senior': 1442, 'packages': 1443, 'ap': 1444, 'professionals': 1445, 'nurses': 1446, 'caregivers': 1447, 'seriously': 1448, '4': 1449, 'highly': 1450, 'risked': 1451, 'job': 1452, 'firefighters': 1453, 'rd': 1454, 'th': 1455, 'alarmed': 1456, 'mainly': 1457, 'massively': 1458, 'implore': 1459, 'initial': 1460, 'selected': 1461, 'ports': 1462, 'entry': 1463, 'adults': 1464, 'savinghuman': 1465, 'arabian': 1466, 'peninsula': 1467, 'street': 1468, 'regret': 1469, 'sheep': 1470, 'pigs': 1471, 'frontline': 1472, 'neutral': 1473, 'oclock': 1474, 'revisit': 1475, 'museums': 1476, 'rolling': 1477, 's': 1478, 'bogus': 1479, 'kit': 1480, 'transparent': 1481, 'worked': 1482, 'expensive': 1483, 'soared': 1484, 'lying': 1485, 'winning': 1486, 'joke': 1487, 'exposed': 1488, 'cimas': 1489, 'recommends': 1490, 'heroes': 1491, 'total': 1492, 'everybody': 1493, 'grey': 1494, 'played': 1495, 'role': 1496, 'unbelievably': 1497, 'clearconfirmed': 1498, 'complications': 1499, 'o': 1500, 'thag': 1501, 'statistics': 1502, 'percentage': 1503, 'harm': 1504, 'naturally': 1505, 'fewer': 1506, 'naysayers': 1507, 'concussion': 1508, 'nuclear': 1509, 'several': 1510, 'tinkered': 1511, 'marketed': 1512, 'messenger': 1513, 'sufficiently': 1514, 'advanced': 1515, 'actually': 1516, 'limit': 1517, 'worlds': 1518, 'pension': 1519, 'guidance': 1520, 'whilst': 1521, 'breastfeeding': 1522, 'further': 1523, 'incentive': 1524, 'anyones': 1525, 'treats': 1526, 'leaving': 1527, 'begun': 1528, 'prototype': 1529, 'laboratory': 1530, 'siberia': 1531, 'russias': 1532, 'historical': 1533, 'daughter': 1534, 'becerra': 1535, 'medicine': 1536, 'cdc': 1537, 'surprised': 1538, 'learn': 1539, 'immunosuppressed': 1540, 'lung': 1541, 'obligation': 1542, 'guilty': 1543, 'ontarian': 1544, 'p': 1545, 'grandchildren': 1546, 'usually': 1547, 'technique': 1548, 'berlin': 1549, 'union': 1550, 'crowded': 1551, 'rots': 1552, 'opt': 1553, 'boom': 1554, 'delt': 1555, 'astrazaneca': 1556, 'learned': 1557, 'sent': 1558, 'victims': 1559, 'compensated': 1560, 'concerning': 1561, 'tv': 1562, 'modernas': 1563, 'joins': 1564, 'battle': 1565, 'level': 1566, 'beautiful': 1567, 'summary': 1568, 'mot': 1569, 'daft': 1570, 'hurts': 1571, 'ears': 1572, 'expenditure': 1573, 'purposes': 1574, 'coffin': 1575, 'oripire': 1576, 'intriguing': 1577, 'outcome': 1578, 'precipitation': 1579, 'dromois': 1580, 'reserves': 1581, 'mid': 1582, 'july': 1583, 'complete': 1584, 'ill': 1585, 'benefit': 1586, 'achieve': 1587, 'delta': 1588, 'mockery': 1589, 'dizzy': 1590, 'faints': 1591, 'tennessee': 1592, 'hospita': 1593, 'different': 1594, 'prevention': 1595, 'everywhere': 1596, 'results': 1597, 'entire': 1598, 'amid': 1599, 'tick': 1600, 'remembers': 1601, 'early': 1602, 'childhood': 1603, 'ship': 1604, 'missouris': 1605, 'agency': 1606, 'ability': 1607, 'defend': 1608, 'expire': 1609, 'challenge': 1610, 'accessible': 1611, 'rest': 1612, 'approvals': 1613, 'expects': 1614, 'shots': 1615, 'tp': 1616, 'hoarding': 1617, 'workso': 1618, 'africans': 1619, 'cured': 1620, 'medication': 1621, 'remains': 1622, 'guys': 1623, 'eliminate': 1624, 'anymore': 1625, 'advantages': 1626, 'outweigh': 1627, 'disadvantages': 1628, 'guarantee': 1629, 'non': 1630, 'suspicion': 1631, 'mistrust': 1632, 'holding': 1633, 'deliveries': 1634, 'banning': 1635, 'exports': 1636, 'initiative': 1637, 'intrigued': 1638, 'four': 1639, 'dread': 1640, 'aware': 1641, 'healthy': 1642, 'became': 1643, 'owe': 1644, 'her': 1645, 'stepping': 1646, 'debt': 1647, 'gratitude': 1648, 'guide': 1649, 'notgiven': 1650, 'gives': 1651, 'uae': 1652, 'timely': 1653, 'selection': 1654, 'marc': 1655, 'siegel': 1656, 'nyu': 1657, 'langone': 1658, 'comparison': 1659, 'water': 1660, 'vijay': 1661, 'reddy': 1662, 'deplore': 1663, 'team': 1664, 'rotten': 1665, 'bribing': 1666, 'heh': 1667, 'purely': 1668, 'write': 1669, 'pays': 1670, 'mutant': 1671, 'unbelievable': 1672, 'ha': 1673, 'medicin': 1674, 'citizens': 1675, 'families': 1676, 'gone': 1677, 'deceived': 1678, 'arms': 1679, 'peace': 1680, 'unfortunately': 1681, 'logistics': 1682, 'kits': 1683, 'equipment': 1684, 'contain': 1685, 'flu': 1686, 'complain': 1687, 'saturate': 1688, 'hijacked': 1689, 'personal': 1690, 'dosis': 1691, 'memorial': 1692, 'mir': 1693, 'issued': 1694, 'advising': 1695, 'rapidly': 1696, 'facilitate': 1697, 'contains': 1698, 'pristine': 1699, 'advance': 1700, 'notice': 1701, 'nhs': 1702, 'picture': 1703, 'video': 1704, 'actual': 1705, 'remedy': 1706, 'accepted': 1707, 'auditioned': 1708, 'product': 1709, 'visible': 1710, 'ehpad': 1711, 'testify': 1712, 'misinformation': 1713, 'believing': 1714, 'm': 1715, 'gild': 1716, 'monthly': 1717, 'calling': 1718, 'higher': 1719, 'appears': 1720, 'positioned': 1721, 'nursing': 1722, 'homes': 1723, 'pennsylvania': 1724, 'prepare': 1725, 'distribut': 1726, 'enrouged': 1727, 'arses': 1728, 'eager': 1729, 'drama': 1730, 'tears': 1731, 'gave': 1732, 'joy': 1733, 'accept': 1734, 'talking': 1735, 'repeat': 1736, 'mistake': 1737, 'jeopardized': 1738, 'president': 1739, 'pushed': 1740, 'arriving': 1741, 'harmless': 1742, 'comorbidity': 1743, 'article': 1744, 'explaining': 1745, 'doesnt': 1746, 'trusts': 1747, 'republic': 1748, 'tiring': 1749, 'victimisation': 1750, 'secret': 1751, 'deceiving': 1752, 'innocent': 1753, 'bringing': 1754, 'air': 1755, 'prediction': 1756, 'overuse': 1757, 'antibacterial': 1758, 'lead': 1759, 'mutations': 1760, 'bacteria': 1761, 'retrovirus': 1762, 'sinopharm': 1763, 'ceo': 1764, 'firsti': 1765, 'takeanother': 1766, 'biya': 1767, 'wave': 1768, 'regions': 1769, 'aspire': 1770, 'unless': 1771, 'eat': 1772, 'singapore': 1773, 'watching': 1774, 'smooth': 1775, 'operating': 1776, 'machine': 1777, 'prisoner': 1778, 'reuters': 1779, 'limits': 1780, 'risking': 1781, 'c': 1782, 'graveling': 1783, 'feet': 1784, 'killed': 1785, 'k': 1786, 'appreciate': 1787, 'prepping': 1788, 'shipment': 1789, 'sites': 1790, 'arise': 1791, 'malaria': 1792, 'shaken': 1793, 'international': 1794, 'affair': 1795, 'deal': 1796, 'chemo': 1797, 'alzheimers': 1798, 'parkinsons': 1799, 'aids': 1800, 'miracle': 1801, 'sides': 1802, 'tolerated': 1803, 'sickness': 1804, 'itself': 1805, 'versus': 1806, 'polyethylene': 1807, 'glycol': 1808, 'displays': 1809, 'heightened': 1810, 'propensity': 1811, 'initiate': 1812, 'origin': 1813, 'logistical': 1814, 'pharmacy': 1815, 'kept': 1816, 'specialized': 1817, 'disparity': 1818, 'warm': 1819, 'spreading': 1820, 'react': 1821, 'trying': 1822, 'hold': 1823, 'accountable': 1824, 'brothers': 1825, 'suppose': 1826, 'documents': 1827, 'id': 1828, 'fourth': 1829, 'fifth': 1830, 'sixth': 1831, 'seventh': 1832, 'loop': 1833, 'ends': 1834, 'lasts': 1835, 'sell': 1836, 'theyd': 1837, 'buy': 1838, 'extrapolated': 1839, 'cartels': 1840, 'payback': 1841, 'smells': 1842, 'war': 1843, 'concretely': 1844, 'motivates': 1845, 'inventors': 1846, 'none': 1847, 'courage': 1848, 'sheet': 1849, 'providers': 1850, 'molecules': 1851, 'treat': 1852, 'sham': 1853, 'toronto': 1854, 'ontarios': 1855, 'sterile': 1856, 'importance': 1857, 'successfully': 1858, 'within': 1859, 'programm': 1860, 'tourists': 1861, 'bring': 1862, 'usual': 1863, 'dictatorship': 1864, 'liquidate': 1865, 'ideal': 1866, 'targets': 1867, 'meanwhile': 1868, 'significant': 1869, 'breaking': 1870, 'reasons': 1871, 'stella': 1872, 'maris': 1873, 'plan': 1874, 'questionable': 1875, 'pressuring': 1876, 'license': 1877, 'politicized': 1878, 'play': 1879, 'anyhow': 1880, 'confidence': 1881, 'releases': 1882, 'lack': 1883, 'hindsight': 1884, 'annoyed': 1885, 'proportion': 1886, 'disorders': 1887, 'caused': 1888, 'whereas': 1889, 'hardly': 1890, 'painless': 1891, 'above': 1892, 'status': 1893, 'announce': 1894, 'experiments': 1895, 'w': 1896, 'potentially': 1897, 'saving': 1898, 'raised': 1899, 'wondering': 1900, 'tol': 1901, 'congratulate': 1902, 'vloggers': 1903, 'promotion': 1904, 'promote': 1905, 'australia': 1906, 'outbreak': 1907, 'woolworths': 1908, 'shopping': 1909, 'elderly': 1910, 'disabled': 1911, 'aged': 1912, 'pre': 1913, 'existing': 1914, 'include': 1915, 'hypertension': 1916, 'diabetes': 1917, 'asthma': 1918, 'respiratory': 1919, 'liver': 1920, 'kidney': 1921, 'stabilised': 1922, 'chronic': 1923, 'shut': 1924, 'certified': 1925, 'contrary': 1926, 'technological': 1927, 'prowess': 1928, 'task': 1929, 'hey': 1930, 'terfs': 1931, 'heard': 1932, 'trans': 1933, 'vax': 1934, 'lick': 1935, 'counters': 1936, 'transit': 1937, 'seats': 1938, 'boose': 1939, 'tough': 1940, 'myth': 1941, 'terf': 1942, 'meet': 1943, 'evidence': 1944, 'states': 1945, 'starting': 1946, 'wrong': 1947, 'injections': 1948, 'slip': 1949, 'animal': 1950, 'pig': 1951, 'disappear': 1952, 'mild': 1953, 'moderate': 1954, 'lie': 1955, 'catch': 1956, 'bug': 1957, 'coma': 1958, 'traumatic': 1959, 'british': 1960, 'airways': 1961, 'suspend': 1962, 'staff': 1963, 'encouraging': 1964, 'childrens': 1965, 'sosomething': 1966, 'stable': 1967, 'inconvenients': 1968, 'probably': 1969, 'somewhere': 1970, 'priority': 1971, 'queue': 1972, 'noway': 1973, 'chipped': 1974, 'regionals': 1975, 'sullivan': 1976, 'flocked': 1977, 'purchase': 1978, 'cleaning': 1979, 'supplies': 1980, 'toilet': 1981, 'paper': 1982, 'goods': 1983, 'neonuclear': 1984, 'approv': 1985, 'clinic': 1986, 'lots': 1987, 'listed': 1988, 'various': 1989, 'markets': 1990, 'pushing': 1991, 'finding': 1992, 'cures': 1993, 'push': 1994, 'identified': 1995, 'undoubtably': 1996, 'regulators': 1997, 'step': 1998, 'surreal': 1999, 'dropping': 2000, 'lethal': 2001, 'patented': 2002, 'warp': 2003, 'speedplease': 2004, 'calm': 2005, 'nation': 2006, 'senate': 2007, 'republicans': 2008, 'direct': 2009, 'investors': 2010, 'jab': 2011, 'current': 2012, 'attacks': 2013, 'okay': 2014, 'sceptical': 2015, 'tan': 2016, 'fill': 2017, 'coffers': 2018, 'contact': 2019, 'prejorative': 2020, 'unbearable': 2021, 'ego': 2022, 'roof': 2023, 'scarier': 2024, 'issues': 2025, 'transporting': 2026, 'slaves': 2027, 'california': 2028, 'nightgov': 2029, 'gav': 2030, 'licensed': 2031, 'greater': 2032, 'vary': 2033, 'pperson': 2034, 'hence': 2035, 'neutrality': 2036, 'whitout': 2037, 'cold': 2038, 'across': 2039, 'atshmatic': 2040, 'mucus': 2041, 'karens': 2042, 'antivaxxers': 2043, 'lining': 2044, 'messing': 2045, 'heads': 2046, 'uphow': 2047, 'ride': 2048, 'pfeizer': 2049, 'kuwait': 2050, 'urgent': 2051, 'warnings': 2052, 'chaos': 2053, 'hunt': 2054, 'liveplease': 2055, 'notbeen': 2056, 'corresponds': 2057, 'supervising': 2058, 'torn': 2059, 'firstish': 2060, 'incredible': 2061, 'jam': 2062, 'taxes': 2063, 'pisses': 2064, 'legacy': 2065, 'registered': 2066, 'bosnia': 2067, 'sinovac': 2068, 'confused': 2069, 'contradictory': 2070, 'circulating': 2071, 'als': 2072, 'vi': 2073, 'competition': 2074, 'recipe': 2075, 'grandmother': 2076, 'composition': 2077, 'happiest': 2078, 'texting': 2079, 'shes': 2080, 'yours': 2081, 'govement': 2082, 'sad': 2083, 'organization': 2084, 'intend': 2085, 'import': 2086, 'football': 2087, 'stadium': 2088, 'imagined': 2089, 'pendemia': 2090, 'vehemently': 2091, 'opposed': 2092, 'partly': 2093, 'folks': 2094, 'eff': 2095, 'pain': 2096, 'shoulder': 2097, 'sister': 2098, 'sim': 2099, 'trouble': 2100, 'passing': 2101, 'f': 2102, 'value': 2103, 'convince': 2104, 'word': 2105, 'although': 2106, 'designed': 2107, 'threatened': 2108, 'increase': 2109, 'restrictions': 2110, 'decrease': 2111, 'israel': 2112, 'conscious': 2113, 'adolescents': 2114, 'reassure': 2115, 'harmlessness': 2116, 'manufacturers': 2117, 'participate': 2118, 'thr': 2119, 'compagnie': 2120, 'corp': 2121, 'rising': 2122, 'pharmaceuticals': 2123, 'doubled': 2124, 'safeguards': 2125, 'jacking': 2126, 'booked': 2127, 'appointment': 2128, 'guaranteed': 2129, 'unlike': 2130, 'paid': 2131, 'died': 2132, 'manufactured': 2133, 'monthsall': 2134, 'confined': 2135, 'house': 2136, 'bothering': 2137, 'insist': 2138, 'desperately': 2139, 'sign': 2140, 'petition': 2141, 'demanding': 2142, 'reasearch': 2143, 'cheap': 2144, 'laughing': 2145, 'thought': 2146, 'schools': 2147, 'closed': 2148, 'carriers': 2149, 'relieved': 2150, 'fo': 2151, 'george': 2152, 'soros': 2153, 'arose': 2154, 'hundred': 2155, 'easing': 2156, 'patient': 2157, 'concerns': 2158, 'safest': 2159, 'forcing': 2160, 'full': 2161, 'ceased': 2162, 'passed': 2163, 'military': 2164, 'industrialists': 2165, 'main': 2166, 'objects': 2167, 'bothered': 2168, 'directly': 2169, 'decisions': 2170, 'youre': 2171, 'shape': 2172, 'warns': 2173, 'numbers': 2174, 'serving': 2175, 'cobaille': 2176, 'consider': 2177, 'eligible': 2178, 'scammers': 2179, 'surrounding': 2180, 'aka': 2181, 'concentrate': 2182, 'plans': 2183, 'inoculation': 2184, 'views': 2185, 'saves': 2186, 'starts': 2187, 'hopes': 2188, 'launch': 2189, 'watchdog': 2190, 'rospotrebnadzor': 2191, 'evening': 2192, 'playing': 2193, 'noir': 2194, 'thomasall': 2195, 'founder': 2196, 'biotechnology': 2197, 'hat': 2198, 'attention': 2199, 'sfr': 2200, 'day3': 2201, 'purpose': 2202, 'appearance': 2203, 'management': 2204, 'reinforced': 2205, 'pessimism': 2206, 'efficient': 2207, 'extent': 2208, 'figures': 2209, 'inflated': 2210, 'pessimist': 2211, 'existence': 2212, 'antibodies': 2213, 'excuse': 2214, 'council': 2215, 'communicate': 2216, 'warn': 2217, 'society': 2218, 'extreme': 2219, 'starvation': 2220, 'malnutrition': 2221, 'pure': 2222, 'invention': 2223, 'offered': 2224, 'recently': 2225, 'creation': 2226, 'atrocities': 2227, 'peoples': 2228, 'traumatize': 2229, 'refusing': 2230, 'collective': 2231, 'suicide': 2232, 'per': 2233, 'saturated': 2234, 'deprogramming': 2235, 'catastrophic': 2236, 'polishes': 2237, 'decades': 2238, 'conflicting': 2239, 'urgently': 2240, 'failed': 2241, 'deliver': 2242, 'promises': 2243, 'mortality': 2244, 'contract': 2245, 'transmit': 2246, 'listened': 2247, 'gp': 2248, 'morons': 2249, 'hurraah': 2250}\n"
     ]
    }
   ],
   "source": [
    "# visualization of the result obtained after tokenization.\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print(f\"{Fore.GREEN}------------------- visualization of the result obtained after tokenization. ------------------- \")\n",
    "print(f\"{Fore.BLACK}\",word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    " Let's apply the tokenisation operation to each expression in column x. \n",
    "This will allow us to observe that each expression is identifiable by a group of numbers.\n",
    "\"\"\"\n",
    "\n",
    "train_sequences = tokenizer.texts_to_sequences(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we need to be vaccinated to protect all person around us\n",
      "\u001b[34m first sentence. ===>  we need to be vaccinated to protect all person around us\n",
      "\u001b[34m first sentence. ===>  [147, 29, 2, 13, 32, 17]\n",
      "\u001b[32m second sentence.  ===> it is a pleasure to see how the govement are working for our help i thing the vaccination is good for all of us\n",
      "\u001b[34m second sentence. ===>  [3, 23, 11, 8, 77, 155, 2, 24, 184, 18, 256]\n",
      "\u001b[35m third sentence.  ===>  negative\n",
      "\u001b[34m third sentence. ===>  [3, 138, 16, 2, 128, 352, 10, 5, 626, 16, 26, 28, 19, 11, 18, 114, 5, 986, 7, 987, 37, 26, 164, 988, 77, 257]\n"
     ]
    }
   ],
   "source": [
    "# Let's see what the first three expressions of the document look like after the tokenisation operation.\n",
    "print(data.clean[0])\n",
    "print(f\"{Fore.BLUE} first sentence. ===> \",data.clean[0])\n",
    "print(f\"{Fore.BLUE} first sentence. ===> \",train_sequences[0])\n",
    "\n",
    "print(f\"{Fore.GREEN} second sentence.  ===>\",data.clean[1])\n",
    "print(f\"{Fore.BLUE} second sentence. ===> \",train_sequences[1])\n",
    "\n",
    "print(f\"{Fore.MAGENTA} third sentence.  ===> \",data.clean[2])\n",
    "print(f\"{Fore.BLUE} third sentence. ===> \",train_sequences[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We will try to transform each expression in the tokenizer to the length format defined above.\n",
    "This allows us to have expressions of the same length.\n",
    "\"\"\"\n",
    "\n",
    "train_padded = pad_sequences(train_sequences, maxlen=max_length, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m first sentence. ===>  [147  29   2  13  32  17   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0]\n",
      "\u001b[32m second sentence.  ===> [  3  23  11   8  77 155   2  24 184  18 256   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0]\n",
      "\u001b[35m third sentence.  ===>  [  3 138  16   2 128 352  10   5 626  16  26  28  19  11  18 114   5 986\n",
      "   7 987  37  26 164 988  77 257   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "# Let's see what the first three expressions of the document look like after the operation.\n",
    "\n",
    "print(f\"{Fore.BLUE} first sentence. ===> \",train_padded[0])\n",
    "print(f\"{Fore.GREEN} second sentence.  ===>\",train_padded[1])\n",
    "print(f\"{Fore.MAGENTA} third sentence.  ===> \",train_padded[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we repeat the same operations on the test sentences\n",
    "\n",
    "\"\"\"\n",
    "We will try to transform each expression in the tokenizer to the length format defined above.\n",
    "This allows us to have expressions of the same length.\n",
    "\"\"\"\n",
    "\n",
    "test_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "test_padded = pad_sequences(test_sequences, maxlen=max_length, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m Shape of train. ===>  {(818, 42)}\n",
      "\u001b[34m Shape of train. ===>  {(205, 42)}\n",
      "\u001b[32m This means that 80% of the training data corresponds to 817 sentences of 42 words each. \n"
     ]
    }
   ],
   "source": [
    "# how our training data is dimensioned.\n",
    "print(f\"{Fore.BLUE} Shape of train. ===> \",{train_padded.shape})\n",
    "print(f\"{Fore.BLUE} Shape of train. ===> \",{test_padded.shape})\n",
    "print(f\"{Fore.GREEN} This means that 80% of the training data corresponds to 817 sentences of 42 words each. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 42, 100)           254000    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 42, 100)           0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 42, 64)            42240     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 32)                12416     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 308,755\n",
      "Trainable params: 308,755\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "We will now create a model that will be adapted to binary data. That is, with two labels, positive and negative\n",
    "\n",
    "positive ==> [0 0 1]\n",
    "Neutral  ==> [1 0 0]\n",
    "Negative ==> [0 1 0]\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# define model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(num_words, 100, input_length=max_length))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.1))\n",
    "model.add(LSTM(32, dropout=0.2, recurrent_dropout=0.1))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "optimizer = Adam()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "52/52 - 96s - loss: 1.0283 - accuracy: 0.4462\n",
      "Epoch 2/10\n",
      "52/52 - 6s - loss: 1.0104 - accuracy: 0.4682\n",
      "Epoch 3/10\n",
      "52/52 - 6s - loss: 1.0021 - accuracy: 0.4841\n",
      "Epoch 4/10\n",
      "52/52 - 6s - loss: 0.9074 - accuracy: 0.6430\n",
      "Epoch 5/10\n",
      "52/52 - 5s - loss: 0.7014 - accuracy: 0.7506\n",
      "Epoch 6/10\n",
      "52/52 - 5s - loss: 0.6436 - accuracy: 0.7628\n",
      "Epoch 7/10\n"
     ]
    }
   ],
   "source": [
    "# now we have to train the model \n",
    "model.fit(train_padded, y_train, epochs=10,batch_size=16,  verbose=2)\n",
    "print(f\"{Fore.GREEN}-------------------  The model was trained. ------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Now we test the model and we print the metrics data\n",
    "\"\"\"\n",
    "\n",
    "predictions = model.predict(test_padded)\n",
    "y_pred = (predictions > 0.5)\n",
    "print('Accuracy of the model : ', \"%.2f\" % (accuracy_score(y_pred, y_test)*100))\n",
    "# print(\"F1-score:  : \", \"%.2f\" %  (f1_score(y_pred, y_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simulate the model with unknow values\n",
    "\n",
    "\n",
    "# you cn write your own sentences on e and f nd check the result\n",
    "a = [\"a vaccine no i am not interested.\"]\n",
    "b = [\"There are times when I wonder why it is free. Anything that is free is dangerous. So i will never get it.\"]\n",
    "c = [\"I really don't know. I let time tell me.\"]\n",
    "d = [\" I don't think there's much difference with or without the vaccine, so I don't know what to do.\"]\n",
    "e = [\"I have my two doses and I am still alive. I am waiting for the others to find my freedom.\"]\n",
    "f = [\"Vaccination is very important. Also the vaccination against covid19.\"]\n",
    "\n",
    "print(f\"{Fore.GREEN}------------------- The simulation messages were successfully recorded.. ------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the values\n",
    "clean_textA = clean_tweets(a)\n",
    "clean_textB = clean_tweets(b)\n",
    "clean_textC = clean_tweets(c)\n",
    "clean_textD = clean_tweets(d)\n",
    "clean_textE = clean_tweets(e)\n",
    "clean_textF = clean_tweets(f)\n",
    "\n",
    "print(f\"{Fore.GREEN}------------------- The simulation messages cleaning operation is complete.. ------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We will try to transform each expression in the tokenizer to the length format defined above.\n",
    "This allows us to have expressions of the same length.\n",
    "\"\"\"\n",
    "simulate_sentence_A = tokenizer.texts_to_sequences(clean_textA)\n",
    "simulate_sentence_B = tokenizer.texts_to_sequences(clean_textB)\n",
    "simulate_sentence_C = tokenizer.texts_to_sequences(clean_textC)\n",
    "simulate_sentence_D = tokenizer.texts_to_sequences(clean_textD)\n",
    "simulate_sentence_E = tokenizer.texts_to_sequences(clean_textE)\n",
    "simulate_sentence_F = tokenizer.texts_to_sequences(clean_textF)\n",
    "\n",
    "\n",
    "test_padded1 = pad_sequences(simulate_sentence_A, maxlen=max_length, padding='post', truncating='post')\n",
    "test_padded2 = pad_sequences(simulate_sentence_B, maxlen=max_length, padding='post', truncating='post')\n",
    "test_padded3 = pad_sequences(simulate_sentence_C, maxlen=max_length, padding='post', truncating='post')\n",
    "test_padded4 = pad_sequences(simulate_sentence_D, maxlen=max_length, padding='post', truncating='post')\n",
    "test_padded5 = pad_sequences(simulate_sentence_E, maxlen=max_length, padding='post', truncating='post')\n",
    "test_padded6 = pad_sequences(simulate_sentence_F, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "\n",
    "print(f\"{Fore.BLUE} 1.sentence. ===> \",a)\n",
    "print(f\"{Fore.BLUE} 1.sentence. ===> \",test_padded1)\n",
    "\n",
    "print(f\"{Fore.GREEN} 2.sentence. ===> \",b)\n",
    "print(f\"{Fore.GREEN} 2.sentence. ===> \",test_padded2)\n",
    "\n",
    "print(f\"{Fore.RED} 3.sentence. ===> \",c)\n",
    "print(f\"{Fore.RED} 3.sentence. ===> \",test_padded3)\n",
    "\n",
    "print(f\"{Fore.BLACK} 4.sentence. ===> \",d)\n",
    "print(f\"{Fore.BLACK} 4.sentence. ===> \",test_padded4)\n",
    "\n",
    "print(f\"{Fore.MAGENTA} 5.sentence. ===> \",e)\n",
    "print(f\"{Fore.MAGENTA} 5.sentence. ===> \",test_padded5)\n",
    "\n",
    "print(f\"{Fore.BLUE} 6.sentence. ===> \",f)\n",
    "print(f\"{Fore.BLUE} 6.sentence. ===> \",test_padded6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pred1 = model.predict(test_padded1)\n",
    "pred2 = model.predict(test_padded2)\n",
    "pred3 = model.predict(test_padded3)\n",
    "pred4 = model.predict(test_padded4)\n",
    "pred5 = model.predict(test_padded5)\n",
    "pred6 = model.predict(test_padded6)\n",
    "\n",
    "print(f\"{Fore.BLUE}------------------- Legend. ------------------- \")\n",
    "print(f\"{Fore.RED} negative ==> [1 0 0]\")\n",
    "print(f\"{Fore.RED} Neutral  ==> [0 1 0]\")\n",
    "print(f\"{Fore.RED} positive ==> [0 0 1]\")\n",
    "\n",
    "print(f\"{Fore.GREEN}#####################################################################################################\")\n",
    "\n",
    "print(f\"{Fore.BLACK} 1 --> display: \", np.around(pred1, decimals=0),\" instead of Negative [1 0 0]\")\n",
    "print(f\"{Fore.BLACK} 2 --> display: \", np.around(pred2, decimals=0),\" instead of Negative [1 0 0]\")\n",
    "print(f\"{Fore.BLACK} 3 --> display: \", np.around(pred3, decimals=0),\" instead of Neutral  [0 1 0]\")\n",
    "print(f\"{Fore.BLACK} 4 --> display: \", np.around(pred4, decimals=0),\" instead of Neutral  [0 1 0]\")\n",
    "print(f\"{Fore.BLACK} 5 --> display: \", np.around(pred5, decimals=0),\" instead of Positive [0 0 1]\")\n",
    "print(f\"{Fore.BLACK} 6 --> display: \", np.around(pred6, decimals=0),\" instead of Positive [0 0 1]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{Fore.GREEN}------------------- The firsst NN prototype is completed. ------------------- \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
