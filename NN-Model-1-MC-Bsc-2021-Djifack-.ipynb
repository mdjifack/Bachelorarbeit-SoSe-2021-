{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bachelorarbait-2021\n",
    "# Author: Michel Bosris Djifack\n",
    "# Matrikelnummer:7103963"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A sentiment analysis program will be designed to make predictions about the english written expressions to rank them and \n",
    "# determine which ones are in favor of the coronavirus vaccine and which are against.\n",
    "# Method: NN (Neural Network)\n",
    "\n",
    "# ===> three classes (Multiclass) with NN\n",
    "\n",
    "\n",
    "# NN-Prototype-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m------------------- All libraries have been successfully imported.------------------- \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "import all libraries (Math-function, diagram-visualisation, regex, document and NLP functions)\n",
    "\n",
    "\"\"\"\n",
    "# NLP Libraries\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, LSTM, Embedding, Dropout, Activation, BatchNormalization,Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "\n",
    "# Math, documents and visualisation Libraries\n",
    "import numpy as np\n",
    "import preprocessor as p\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import colorama\n",
    "from colorama import Fore\n",
    "\n",
    "print(f\"{Fore.MAGENTA}------------------- All libraries have been successfully imported.------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m------------------- The document has been successfully uploaded. ------------------- \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "upload The dataset, open it and check it.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# upload the DataSet\n",
    "file = open('covidVaccineAdvice_mldata_d1.csv',encoding=\"utf-8\")\n",
    "data = pd.read_csv(file,delimiter=\";\")\n",
    "print(f\"{Fore.MAGENTA}------------------- The document has been successfully uploaded. ------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m -------------------  overview of the dataset ------------------- \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>We need to be vaccinated to protect all person...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>it is a pleasure to see how the govement are w...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>The most popular vaccine that i know is Modern...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Of course we need to be vaccinated if we want ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            message sentiment\n",
       "0   1  We need to be vaccinated to protect all person...  Positive\n",
       "1   2  it is a pleasure to see how the govement are w...  Positive\n",
       "2   3                                          Negative   Negative\n",
       "3   4  The most popular vaccine that i know is Modern...  Positive\n",
       "4   5  Of course we need to be vaccinated if we want ...  Positive"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the document header.\n",
    "print(f\"{Fore.MAGENTA} -------------------  overview of the dataset ------------------- \")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m -------------------  The document has 1023 rows and 3 columns ------------------- \n"
     ]
    }
   ],
   "source": [
    "#count the data set\n",
    "print(f\"{Fore.MAGENTA} -------------------  The document has\", data.shape[0], \"rows and\", data.shape[1],\"columns ------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m------------------- the number and percentage of missing values in the data set. ------------------- \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>message</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count  Percentage\n",
       "id             0         0.0\n",
       "message        0         0.0\n",
       "sentiment      0         0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check missing values\n",
    "count =data.isnull().sum().sort_values(ascending=False)\n",
    "percentage =((data.isnull().sum()/len(data)*100)).sort_values(ascending=False)\n",
    "missing_data =pd.concat([count,percentage],axis=1,keys=['count','Percentage'])\n",
    "\n",
    "print(f\"{Fore.MAGENTA}------------------- the number and percentage of missing values in the data set. ------------------- \")\n",
    "missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAwsAAAD8CAYAAAA42TiGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAA690lEQVR4nO3dd5wcdf3H8ddny6XnUkghBHL0BDwInVADWJBYUJqIsIiKNMECeqA/OZoEEUFAgiLlgCBdQI+mQEBK6IEFpAUOEpKQ3pOr398f37lk726u397c7r2fj8c+9nbqZ2Zn5+Yz3zLmnENERERERKSxWNQBiIiIiIhIz6RkQUREREREQilZEBERERGRUEoWREREREQklJIFEREREREJpWRBRERERERCKVkQkWiZzcAsuj6czW7BzGFWlDGsKBh2S2Rx+Tii3TdhzCowq4g6jJzRU44lEZEOUrIgEoV8u+DyF0OZr0rMFmH2GmZ/w+yrmMWztO7c3ZdhiYq0zOxLmP0Ds3mYVWG2DLP3MbsHszMxswhicpjN6Pb1drfO/tbMCjD7AWblmM0PzhOrMJuF2VWY7dTJ+CYH30Vpp5YjIg0kog5ARPLKBcF7HBgC7AgcD/wAeAWz43Du/UbznAD077YImzoXmAp8FmEMzYl63/QsZucBlwA1wKPAe0AS2BI4EDgSuC4Y31N8BkwAVkQdSKTMtgMewO+LxcC/gU+BAmAH4BTgTMwOx7mHogpTRJpSsiAiXce50ibDzEYB1wBHAf/BbHecW5gxz6fdFV4o5+YD8yONoTlR75uexGwccCGwEtgP59KNxseALwG13R9cC5yrBt6NOoxI+XPAE8BY4CrgPJxb12iakcD5wNDuDk9EWqZqSJJ99UX0ZmMwuw2zhZitw+xVzL7bwnxfwexhzBYHxdWzMbscsyEh01YEr8GY/TH4u7pBcbTZeMxuCsZVBnH8F7NTQ5Y3PqgiMieY9nPM7sBs+5BpN1YlMfsxZmnM1gfz/BWzwoxpJwd10McB4xpV3bklY7rDMbs9qF6xBrPVwf46M7goCttf22F2X1AtYw1mz2M2BbMTg+WfGDLPWMyuxeyjYDuXYPYQZns08620n3OfA98BZgCbA+c1iqFpvXwzwywVbMOiYH/OwewxzI4Jpmnrvqw//kbjq0R9hlnthv3RWlUgfyw8gNnSYL8+i9mXQ6YrDZYzOWRc03rrPvZU8OnjjNgrWtw3fngMs1Mwezk4NtYEf58aenxs3AebBMdkfRWQtzH7fuh2t8asMDh2Pgu+n3doXA3I7zuH2ZMtLCcd/FZHt7LGvfAlVk81SRQAnKvDucdwLmx/7YXZvZgtwFddmoPZXzAbEzLtjCDmBGbnYfZBsK/mYHYZZgUZ056Y8f0c2OgYLA2mCW+zsPG42xKzM4L9tx5/fjpvw340Owqzl4LveGGwz/s2sy+jPW8172J8ovB3nPtZk0QBwLmFOHc6cGfGerfDbCpmr+DPA5WYfRLEN7bJ9sBTwafzG8U4udG0x2L2FP5cuR6z/2H2G8z6hEZvdhy+SuW64Du4Df//rKt/n03PUWZ3BuMPaCa2I4Px14SOF+kCKlmQ7jIUeB5YDtyMr6JyNDAds81w7vIGU5v9Fl+lZSnwL2AhsBNwNnAYZpNwbmWjdRQATwLDgMfxdyA/DpY3BbgH6IOvvvD3IIadgV8C0zLWfShwP756wz+BD/H/6L4NTMHsIJx7LWQbfw98JZjnceAg4EfANsDBwTQVwXb9NPh8Vcb8szL+ngrUAS/iqzEUBsv4E7AHvmpP5v4aDzwXbHs58CawFfAP4OGQWMFs1yDOYcBjwTZvAhwOPIvZt3AufN72cq4Os4uBycCxmP0s9KJuo0vw1YM+Bu7GV+HYFL/tRwF30fZ9CX4bZwKr8dtZB3zehsi3BF4A3gL+EsRwDPAIZt/FubvasIzmXIDf1zvjv9flwfDl4ZM3cBvwXWAO8DfAAd/CV8HZDzguZJ4h+GOkCrgX6IuvtnMTZnU4V9aO2AuA/wTLvDP4fESwHdsDpwPg3LuYPQUchNl2Taqgme0DfAG4D+cWtLLOJcH7VpjFca5tJQg+GboBqAQewu+zbYEfAl/HbO9mSnDuAPYHHsGfSw7DnytGAvUJ1iz893g+8AlwS8b8M9oUH/wB/7uoP298A3/8F2C2FH8ueAD4L77k5HR80tTwJkfPOG81ZdaPjeerC1qaFADnKjM+fRtfPekp/P+PKnzVxvrvbnecq68++EDwngKepuH+r8iI50bgJGAufn8tB/YGLgIOwexLOFeTMf05+H20DCjDn4u+hP8tNVe1rCO/z+bOUdfhzzk/Bp4Jme/k4P2vzcQi0nnOOb30yu4LXPC620EsY/iWDpY6qHKwVcbwg4Lpn3cwpNGyTgzGXdloeEUw/D8OBjQat4mDFcF6DgyJb2zG30MdLHOw2MEOjabb0cFqB681Gn5LsO5PHWyRMTzh4Jlg3J4h8Va0sM+2DhkWc1AWLG+vRuOeCIaf2mj4VzP2/4mNYvvQwfom+wTGOPjMwXwHfdr1Hbc8TR8H1cG0W2YMn9FkXljiYK6D/iHL2aSd+7J++291kAgZX//9FWUMK8qY7/JG0+8ebMcyB4MzhpcG008OWUf98m5pdd0Nx4ftm2ODeV5zMDBj+AAHrwTjvtvMPvibg3jG8B0c1Dh4p03f88b97Rw82+D4gGEOZgfjDsgYfmQw7A8t7PsvtWG9AzLW/YyDk4LfZLyFebYLfvcfOtis0biDHdQ6+EfoPodXHQxrtP4Pg3lGh+zfGc3E0Np3X9EgNhji/PlnjYNFDiY0+g2946DSwciM4T3jvBW+/fsHy5rbrvn8vJu5sHMQfDn4HqY1Gj45WFdpM8ur//9xv4N+jcbV/37Pyhi2VfBbX+Rg84zh5uDvLuy817nfZ3PnqLecP1c3Pvdt6aDOwXPt3rd66dWOl6ohSXepBX6Fc3Ubhjj3MXA1/k5Y5p3yM4P3H+Hc8gZLce4W/J2ssDszAL/AuTWNhqWAwcA0nHu6yRzOzc34dAL+bun5OPdOo+next+h3AWzHULWfSGZdyj93ambg097NhNvOOdmhwyrw9+5BX8n0DPbHH8H8EP83e/MeR7B3wFubAqwNXBNk33i3Dz8nbTRwCHtirsl/o5h/d3hEW2Yo5qw+ufOLe7A2quAs8m8Y9g2K/D15DPX/wowHX+cfKsDsXTWScF7Cc6t3jDUH/e/Cj79MGS+tcDPybwj74/x54AJmA1qZxznknkX2Lml+LuzsPHOO/g7vvOAExtU8/DVCY8GZhN+jDbkt+8b+N///sCN+BKfVZg9jdlpIdVITsWfX85i4x3o+uU9iS9p+Hoz2/6rYJsy1z8dX31391bjbbuLGsTmz3kP4Ru2T8O5/2WMq8SXqhXgGwrX6xnnrXCbBu9zW5wqjHOf0bCkoX7448DbZJ4H2+YsfOP3k2haFeoi/Pkp83/Ld/E1MK7BuTkZ63dACeHtYzr6+2zpHDUNXyqeajT8ZMBofN4X6WKtV0MK74LsFpyrwNf5LWo0bgbOzQjqCE5uNK4C527B1w0+sclS6xtHap25tc62+TRIDhqbgS/C3yVj2CT8heJRmB0VMk8BMAKz4Ti3JGP4enz1m8b2Dt4faUOck4L3nZvZV9sF7xOAdxqNeyVk+vp/MO1rtGc2HDgHX/VhK2BAoyk2y/h7YvD+QoNkbKNngS82Gla/neOa2c5tg/cJNFeNqWPq67O7VqabDvwEeBuze/DVCl7AuY72KFNBZqPqtnsN51aFDJ+B/8e9C75qQnfaFV9FYUbIuKfxFzC7hIz7gKZV92DjMToECNvWMDX4aiGN1ce0cf3O1WD2N+C3+KpKdwRjjgf6AX8NLr5a59yb+Ive3fHVZXbD/74PCF4nB9VtlgVz1B/nBxLeDmckvkrPdsCrjcZ13e+5ZWHrmRe8N44JNvbalVlnv2ect8K19TcfMqcZ/uL9RHx1vaH476teVTuW1T9YxmLgp4T3sFtJwySs/jh+tsmUzn2C2Rya/s/s6O+zpXPUrfjqaCcDVwBglsTvl2X4qpot6y3XI1pn59bZnFaLHzYWj2W+JgfjZoSMKw3GlYaMmxGMmxy6XK0zN9fZtmPohWbGjQ/GP5UxrLqZOBu/xmXMU+Hgk2bW8e9g+uI2xPrvNq47lTFP81VJmisWb6k431dD+CiY70UH1zm4OPgOrgqG35Ix/feCYZc3s7xTgvEnZgy7oY3beX47vmPXyjR9M77boozhYVVt4g7OcvBGRizVDh50sE2b9+XG2J5uYXxL1ZD+3sw8hwbjb84Y1l3VkGocLGphexY4qAvZBzPavP0tf48VDua38B07Bx83Gr5Z8P09nTEs7Xx1mhFtWm/LMe3p4H/Buq/KGP5BG4/zA1vc5xvH1VdjObEd+7f9333Lx1LTGHrCeav576a+GtKcDnyvVwbzznNwu4PLgn1T6uqrpLUl7o3HYFv2kcuY5z/BsB2biW9mF/4+mz9H+WmmBdMdFHyur953ZRv3Ze+4HtE6O7fOZl6tlyw41/wDbpyb3MK4UqC0mXEz2Hi3QevM9XW2zahmhtf3gJJ5x3gFEMO5Ye1ch2tm+PLgfTOgaS8qDdXHsTP+LmYUfohvWHsBjbsiNZuEL0rPVH+3uLl9HDa8fju/Sff1ab4fvjTzc5yraHFKX1XmT8Cf8F0q7ofvUekoYEfMdiSsekILS+xQxO07butLdcLOq0M6uP4wK4BhmCXx3XJuZJbAN1IPK0HoSps008g4bL+Ac59h9k/gW5hNwN8h/gJwF84t6nQ0zr2E2Rn46kwHZ4ypj6OQ8FKVfNETzlvNeQV/x34sZtvj3Httmsv/7s/EVzXbh8YlfGbHtjOO+n30Os7t2sZ5Ms+tb4eMb+7c2pHfZ2vnqGn4xt4/xjf4bl/D5t5yPaJ1dm6dzVCbBekuWxDeNeXk4P31jGEzgaGY7dhF654ZvH+1HdPu30Xrbk4tDYvTM20TvN8XMu7AkGH1+25SaLd8/kK7se7aTs/H9evg0x0tTdqE71Lxfpw7Gt/b1db4C816Le3Lztq1mfrsk4P3zON2WfC+ecj0zdVxr7/Ybk/8r+PP3WFdKR4QLCus15uulAD2CRk+OXh/PWTcdcH7yWy80OnKutb1F5OZ/yS76zivI3vHYFv0hPNWON824Lbg0/+1Ov3Gdidb4Y/zx0MShbHB+LD4CI3Rtx94G3+zoa03ouqP46bnUP/cj7DfenZ+nz4JfA6fcO+Fr1r6DJltWkSyRMmCdJc4cFmDi1mzLfF3jmqA2zOmvTJ4v4HwftAHYLZ3k+HNK8PfyTmVsL6qG/bXfTO+JOJ8zJo27vP9Z09ux7qbswTf7qJfyLiK4L3hesx2wXcn2pBveDcDn2T8uNE8h9K0vQLAg/iGpadjdlhohGaTgnq+nePvEN6J355Pgd+1Mn0fzA7BGlUq9nV06//Jr80Y09K+7KxCfF37zDh2x9ejXoHvmrbeS8H794M7iPXTb95kGRvVt7nZoh0x3RS8X9rg+/F/Tw0+3diO5XXUpY0aLA8DfhN8ujlk+ieA9/FtPY4G3se5p9q8NrM98f3ON/2e/bFR33g0s3vJa/Htn67EP0G48XwFmHXFBfYSwi8cu0tPOG+15Df4Bs7H4Z+VE/YdboLZ1fgSRNh4HtwPs3jGdAPxDbbDSvBa+z39Ed/m7SbCn9czFN+ldL078P+ffhL8juunM+BSwhOnbP4+pwXx34dPiq/v4HJE2kXPWZDu8ib+oUqvYvY4/iLsGHz1jF+S2fuPc09gVoI/GX+A2cP4/vYH4h8KdCC+wdmhbVqzc4vxD3+7F3gKs0eCeAbjn92wOb7aDzi3BLMj8ReBMzF7An83qg7/D2gSMBzfR31nPIF/ZsCjmD2DL6Z/A+f+iW/Mdg5wFWYHAR/gGxx/Dd//9jEhyzsdf9fpuuDiv/45C0fgE4NvsrGaDDhXjdm38c9XKMfseXwvM2uD/bFHMP+mNLwwb9nGRlUx/He7I/6uXAH+Yvo4Wu/NqB++OkkFZi/i+6/vi+/bfALwUKO7aS3ty856BvhhcCfvOTY+ZyEG/LhB1RbnXgzWfwDwEv5BZKOAr+P3c9jF5BP47/oGzO7F97G+HOeubTYi5+7A7Jv4C+63MXsAX4XhcPxxfDfOTe/ENrfFfHzvLG9h9hC+x6Ej8fvnOpxr2h+8cw6z6/EXbND+UoUx+IviazF7Ft9Qd32wzkPxVaA+JLP3Kv+ch5PwF3BvY/YoPmFJ4n/P+wOLgPHtjKWxJ4DvBFWtXsVfYD4Tuh+yoWect1qK73PMDsH3jHU2kMLs3/ibB/U9O03GH1OHB/MswOxOfPIwK+P/xpfw3/ssNnbuUO89fAPw72BWFSzfAbfh3Cc4dxNmuwGnAbMxeyyYZhj+t3MA/hg7JYhhNv6ZP78D3sDsLjY+Z2EY8Ab+f0jmtmbz93kP/mbaZviG2vd3cDki7dPuBkd66dXeV32jHN9//+0OFjrfZ/RrrnF/0w3n28/5ZzPMc76v9EUOZjn4o4PdG03besM739/4rc4/Q6DKwecOnnZwcsi0RQ6udb6B5HoHKx286+A2B4c3mrYjDQUHON9gba7zDeKca9hoeQcHDwX7ao3zfb7/0DXXWNLPM975/sOXB/O84GCKg7ODeQ4PmWekg6nO9+O91vn+2D9wcK/zDaeb9vnd/Hec+ap0vs/3V51vTH2oy3zGRsN5GzYohaSDXzp4xPk+4NcH3/1M5xtrF7RzX/rjr/nYW2rgfIuDCc43rF4W7KPnHHylmWUNCbZ3YbAP3nJwcivf28+db5xbGUxT0ey+2Tg85uA05/ttXxu8XnVweuh+bmkfdKyBc4WDQgd/Dn5PlcE2nOnAWph3qPP94693MLyd55FBzvdhf7ODN4Pjq8b5Z7U876DEwaBm5i0OtvOTINalwXfzFwcHt3g8NhzXXAPnkQ7ucP6cUusaNlLMfgPnhsdtdOet1r/DAgc/cPCw889xqXKwyvnG7le7xp1QQH8Hl7iNz4SZExxzw1v4bezh/HNnVjj/DIKm+xG+5uBfwe+0yvlGxy8535HE+JBlHu/gdbfxXHS78//P3nKwPKu/z6bTXhlMH96hhV56ZeFlzrmo8xXJd2YOeJoONKqRLmA2Hd9f+Hja2rhQJBt8VZingNtx7viWJxbpwcwG45+wPAvnJrU2eReudwa+BGR7nPug29YrvZraLIjkA18neXTI8EPw1WbeUaIgPcAvg/fmq1mJ9CRmI4I2MZnDEvjnHfSlYbulbMeyJ74a7mNKFKQ7qc2CSH4oAOZg9hTwLr7O9I74urVV+DYNIt3PrBjf3mY3fI9k/8K5F6MNSqTNjgAuxOw/+IfVDcPf2d8O327imqxHYHYqvp3C9/HtUM7P+jpFMihZEMkP1fieMQ7GNyTvj28Adw8wFedejzA26d12wzcQXYk/Hk+LNhyRdnkR36HGAfhG4uA73LgEuAzfNWy2/Qr/xO6PgONx7qVWphfpUmqzICIiIiIiodRmQUREREREQilZEBERERGRUEoWREREREQklJIFEREREREJpWRBRERERERCKVkQEREREZFQShZERERERCSUkgUREREREQmlZEFEREREREIpWRARERERkVBKFkREREREJJSSBRERERERCaVkQUREREREQilZEBERERGRUEoWREREREQklJIFEREREREJpWRBRER6PDNzZnZFxuezzaw0C+s5r9Hn57t6HSIiuUTJgoiI5IJK4NtmtkmW19MgWXDO7ZPl9YmI9GhKFkREJBfUAH8FftZ4hJmNMLP7zOzl4LVvxvB/m9lrZvYXM/ukPtkwswfM7FUze9vMTg6GTQX6mdksM5seDFsdvN9lZodlrPMWMzvCzOJmdnmw3jfN7MdZ3xMiIt3InHNRxyAiItKi4KJ9DPAmsDPwI2Cgc67UzO4ArnPOPWtmWwCPOecmmNm1wGfOuUvN7FDgEWCEc26xmQ1zzi01s37Ay8CBzrklZrbaOTcwc73OuYFm9i3gcOdcyswKgNnAdsDxwEjn3MVm1gd4DjjKOfdxt+0cEZEsSkQdgIiISFs451aa2a3AmcC6jFFfBHYws/rPg81sELAf8K1g3kfNbFnGPGcGCQDA5sC2wJIWVv8IcHWQEBwKPOOcW2dmXwZ2MrMjg+kKg2UpWRCRvKBkQUREcslVwGvAzRnDYsAk51xmAoFlZA+Nhk/GJxiTnHNrzWwG0LellTrn1gfTfQU4Bvh7/eKAnzjnHmvndoiI5AQlCyIieayopNyATYGijNdYYDAwqNGrvvpNVchrFbAAmJ/xWgDMBSoqpk6p64bNIag6dDfwA+CmYPDjwBnA5QBmNtE5Nwt4FjgauCwoARgaTF8ILAsShfHA3hmrqDazpHOuOmT1dwI/BHYHTgyGPQacamZPOueqzWw7fNWnNV2zxSIi0VKbBRGRPFFUUj4O2A2YGLy2B8YBfbK86nXAu8BbGa90xdQpc7pqBZltCcxsFL6az++DNgubAH8GJuBvgj3jnDvFzEbiSwCGAk/jSwS2DBb5ALAZ8B4wAih1zs0ws8uAbwCvOeeOa7TeJD5Besg59/1gWAy4GPg6vpRhEb5tw4qu2nYRkSgpWRARyUFBicEuwJeBfYE9gZGRBtXUXPxF+tPAjIqpUz7ozpUH7QtqnXM1ZjYJmOacm9idMYiI5DolCyIiOaKopHwEPjk4NHjvaclBa+bhE4eHgX9WTJ2S1bvvZrYtcDe+TUMVcJpz7uVsrlNEJN8oWRAR6cGKSspHAccGrz3wVV3yQRXwH+Be4IGKqVOWtTK9iIhEQMmCiEgPU1RS3h/f5efx+F574tFGlHXVwFPA7cA9FVOnrI84HhERCShZEBHpIYpKyncBzgKOYGPPRL3NMnzSMK1i6pT/RR2MiEhvp2RBRCRCQUPlrwE/ByZHG02P8x/gGuBf3dU1q4iINKRkQUQkAkUl5f3wffX/FNgu0mB6vv8BFwF3KWkQEeleShZERLpRUUl5EvgR8FtgVMTh5Jp3gAvx7RqUNIiIdAMlCyIi3SCobnQ0/gFe20QcTq57G7gAuLdi6hT9ExMRySIlCyIiWVZUUv5FYCr+6crSdZ4DTq+YOuWNqAMREclXShZERLKkqKR8DHAtvhtUyY5aYBrwm2w/5E1EpDdSsiAi0sWCKkc/xpcmFEYcTm+xEPgVUKaqSSIiXUfJgohIFyoqKZ8A3ADsG3UsvdTTwAkVU6d8GnUgIiL5QMmCiEgXKCopjwHn4ns5Kog4nN5uBb4tw/SoAxERyXVKFkREOqmopHw0/qnDh0QdizTwd+C0iqlTlkcdiIhIrlKyICLSCUUl5YcA09EzE3qqOfhqSTOiDkREJBcpWRAR6YCikvI4UAqcB8SijUZaUQv8omLqlD9FHYiISK5RsiAi0k5FJeVDgPuAgyMORdrnJuDUiqlTqqIOREQkVyhZEBFph6KS8i2Bh4HxUcciHfI88O2KqVM+jzoQEZFcoKJzEZE2Kiop3xOYiRKFXLYP8HJRSfkuUQciIpILlCyIiLRBUUn5t4EZwMiIQ5HO2xx4uqik/ICoAxER6emULIiItKKopPwM4B6gX9SxSJcZBDxaVFJ+aNSBiIj0ZEoWRERaUFRSfjZwDTpf5qN+wINBqZGIiITQPz8RkWZ8+dzrzwIujzoOyaoC4O6ikvLjow5ERKQnUrIgIhKmtPBnjxaU/GYnm/1B1KFI1sWBsqKS8hOiDkREpKdR16kiIo2VFp4CTAOoc7bk8KoLl77ptt424qgk+2qAwyumTimPOhARkZ5CyYKISKbSwhOAWwCrH1TnbMm3qi5Y8obbZrvI4pLushb4YsXUKS9EHYiISE+gZEFEpF5p4VeBf+KrpTRQ52zJt6suWDzLbbN99wcm3WwpsH/F1CnvRB2IiEjUlCyIiACUFm4NvAIMaW6SOmdLj6gqXfS621YJQ/6bC+xTMXXKnKgDERGJkho4i4iUFg4A/kELiQJAzNyw+wrOH7mLffBet8QlURoLPFRUUq5na4hIr6ZkQUQEbgSK2zJhzBh6X8H5I3e199/NckwSvYnA9VEHISISJSULItK7lRb+AjimPbPEjKH3FpSO2s3eU8KQ/04oKik/NeogRESiojYLItJ7lRYeDDxOSIPmtqhzLD+66vz5r7jtJ3RtYNLDVAEHVEyd8mLUgYiIdDclCyLSO5UWbgG8CmzSmcXUOZYfU/Xb+S+78XmXMLiaKhbc8StcTTXU1dF/+30Zsv9xLHrwMqqXzgWgbv0aYn0HMOb71zSZf+60k4gV9INYDIvF2TR1VYPxK168n+UzbmLsT6YT71/I+rnvsPTx67B4kk2+cQ7JoWOoW7+aRQ9exsijL8TMmqyjG80FdquYOmVhlEGIiHS3RNQBiIh0u9LCPsD9dDJRAIgZQ+4uuNCOqfq/d15yE3bofHA9SDzJqO/8jlhBP1xtDQum/5J+W+3GiG/+asMkS5/8G7E+A5pdxKhjf0e8f2GT4TUrF7G+4nXig0dsGLby5X8w4vBzqVmxkFWvP8ywg3/I8ufvpHDS0VEnCuAbPN8CHBZxHCIi3UptFkSkN/otsFtXLcyMwrsKLtpsL3snr/rlNzNfMgC4uhqoq4WMi3bnHGvffZYBEw5o97KXPXEDQw/6PhnPvsNiCVxNFa6mEoslqF42n9pVS+i7RZvanneHrxaVlJ8cdRAiIt1JyYKI9C6lhTsC53T1Ys0ovLPg4rxLGFxdLfNu/glzr/kefYsm0mfMxkdMVM59m/iAISSHbRY+sxkL7/4t8285i1WzHt0weO0HLxIfNJyCkVs1mLxw76NY8ui1rHzlQQbt+jWWP3MrQ/b/Xla2qxOuKCop36r1yURE8oOqIYlI71FaaMBfgGQ2Fh8kDBxb/eu3Z9btuGM21tHdLBZnzPevoW79ahb+4xKqFlVQMKIIgDXvPN1iqcLo435PYtBwatcs5/O7fkNy+FgKRm/DihfuYtQxFzWZvmDUVmx6whUArJ/zFvGBwwBY9OBlWCzO0IN/QHzA0K7fyPYZCNwAHBJ1ICIi3UElCyLSm/wI2DebKzCj8O/JS8buE3vr7Wyup7vF+g6k7+bFrPvoNcCXOKx9/wX6j28+WUgMGg5AfMAQ+m83icp571OzfAE1Kz5n3k0/Ye60k6hdtZj5t/yU2tXLNsznnGPF83dRuO+xLH/uDobs910G7HgQK1/9Z3Y3su0OLiop/1HUQYiIdAclCyLSO5QWjgKmdseqzCicnvzd5vvG3nqrO9aXLbVrV1C3fjUAddWVrP9kFsnhYwFYX+H/TgwObyNeV7Weusq1G/5e//HrFIwYR8GIIjb/yXTGnnoTY0+9ifigTdj0xKuID9xYYrDmrSfot/XuxPsOxFVXgsXAzP/dc/yhqKR8VNRBiIhkm6ohiUhvcSXQbXVYzBh8e/J3WxxffW762briHtNCtz1qVy9lcfmV4OrA1dF//P7032ZPANb875kmVZBqVi1hyaNXM+qoC6hdu5xF91/sR9TVMWCHA+m3Vettyuuq17P6rScYdbSvpjR4j8NZ9I/fYfEEm3zjl127gZ0zGLgYX1olIpK39JwFEcl/pYVfBh6LYtXOser46nMrcjVhkBbVAbtWTJ3yRtSBiIhki6ohiUh+Ky3sB0yLavVmDLoteWnR/rE301HFIFkTw5dYiYjkLSULIpLvzgIi7erSjEG3JqcWHRB7480o45CsOKiopPybUQchIpItqoYkIvnLlypUACMjjgQA51idqv7VR8/U7bxT1LFIl/oA2LFi6pTqqAMREelqKlkQkXz2I3pIogBgxsCy5GVbTY7NUglDftkWODHqIEREskElCyKSn0oLk8BsYPOoQ2nMOVafVH3O7Kfqdtk56liky3wIjK+YOqU26kBERLqSShZEJF+dQA9MFMCXMNyUvHybg2OvqRed/LENcGTUQYiIdDUlCyKSf0oL40BJ1GG0xIwBNyb/sM0hsVdnRR2LdJkefcyJiHSEkgURaZaZOTO7IuPz2WZW2sFlDTGz0zo4b4WZhT8qONxR+Du9PZoZA/6WvGJbJQx5Y2JRSflhUQchItKVlCyISEsqgW+380K9OUOA0GTBzOJdsHyvtNCA87pseVkWJAzbfTn28utRxyJd4tyoAxAR6UpKFkSkJTXAX4GfNR5hZiPM7D4zezl47RsMLzWzszOme8vMioCpwNZmNsvMLjezyWb2lJndAaSDaR8ws1fN7G0zO7mDMX8NyKmnJZvR/y/JK7f/SuwlJQy5b7+ikvIvRB2EiEhXUbIgIq35M3CcmRU2Gv4n4Ern3B7AEcDfWllOCTDbOTfROXdOMGxP4NfOuR2Czyc553YDdgfONLPhHYj39A7MEzkz+l+fvGq8Eoa88IOoAxAR6SpKFkSkRc65lcCtwJmNRn0RuNbMZgEPAYPNbFA7F/+Sc+7jjM9nmtkbwEx8T0bbtmtppYVjgrhykhn9rk9eNf7Q2IuvRR2LdMrxRSXlBVEHISLSFZQsiEhbXIW/WzogY1gMmBSUFEx0zm3mnFuFr7qUeW7p28Jy19T/YWaT8Rf6k5xzOwOvtzJvmOOArmv/EAEz+k1L/mnCYUoYctlw4JtRByEi0hWULIhIq5xzS4G7aVi94nHgjPoPZjYx+LMC2DUYtiuwZTB8FdBSyUMhsMw5t9bMxgN7dyDUVAfm6XHM6Pfn5J8mTInNfDXqWKTDToo6ABGRrqBkQUTa6gogs1ekM4HdzexNM3sHOCUYfh8wLKiedCrwPoBzbgnwXNDg+fKQ5T8KJMzsTeAifFWktist3AXYsV3z9GBm9Ls2efWOX4u9oIQhN325qKR8bNRBiIh0ljnnoo5BRKTzSgt/Rx52W+kc68+sPuOtf9bts3vUsUi7nVUxdcrVUQchItIZKlkQkXxxZNQBZIMZfa9OXvuFb8SeUwlD7vl61AGIiHSWShZEJPeVFu4EvBF1GNnkHJU/rT49/WDdviphyB3VwCYVU6esjDoQEZGOUsmCiOSDI6IOINvM6HNV8s/Fh8eefSXqWKTNksBXow5CRKQzlCyISD44LOoAuoMZfa5MXlf8rdh/X446Fmmzb0QdgIhIZ6gakojkttLC/sAKIBF1KN3FOSrPrj7lzfvqDtgj6likVcuAkRVTp9REHYiISEeoZEFEct2e9KJEAXwJwx+S1+98ZPzpl6KORVo1FNg56iBERDpKyYKI5Lp9umIhJz24jpGXr+IL161uMu4Pz1diF6xk8dq6JuPmrKjjoLI1TPjzana8bjV/mlm5Ydwx965l4vWrmXj9aoquWsXE6/2yn/u0hp2mrWaPG1bz4VK/zOXrHV+5fQ1tLe01o+DyxF8mHhWfoYSh5+uSY1REJAq96m6ciOSlLrkQO3FikjP2LOCEf6xrMHzOijr+/VENWxRa6HyJGFzx5b7summcVZWO3f66hi9tnWCHEXHuOrL/hul+8dh6Cvv6ZVzxQhX3Hd2PiuWOaS9XccVX+nLR05Wct18fzMLXE8aMgt8n/jrRcC/dXXvQnh3YbOke+wDXRB2EiEhHqGRBRHJXaaEBe3fFog4Yl2BYv6YX6j97bD2//2JfmruE33RQjF03jQMwqI8xYUSMz1Y2LB1wznH3O9Uc+wV/fyYZh3U1sLbakYzD7KV1fLaqjgOL2n//xoyCyxI3TDw6/pRKGHoulSyISM5SsiAiuWx7YHi2Fv7Qe9VsNijGzqPjbZq+Ynkdr8+vZa+xDaf/76e1jBpgbDvcDz93vz6c/M/1XPViFWfsWcCvn1zPRQf16XCcQcKwy3fiT77Y4YVINm1RVFI+JuogREQ6QsmCiOSySdla8NpqxyX/reTCNl7Er65yHHH3Wq46tC+D+zQsh/h7uppjv5Dc8Hni6DgzfziAp1ID+GhZHWMGxXD4Ng7fu38dn69u2jaiNWYkL038bddj408oYeiZVLogIjlJyYKI5LKsXYDNXlrHx8scOweNk+eudOz6lzUsCLmQr671icJxxUm+PSHZYFxNneP+d2s45gvJJvM557j4mUr+74A+XPB0JRdM7sP3dkpy9YtVHYrZjOTvEjfu+r34v2d2aAGSTbtGHYCISEeogbOI5LIuaa8QpnhUnIXnDNrwueiqVbxy8gA26d/wHotzjh88tJ4Jm8T5+aSmpRD/+aiW8ZvEGDu46b2ZsjeqmbJtgqH9jLXVEDP/Wlvd8bjNSF6UuHl3YObttV/K2v6Rdtsu6gBERDpCJQsiksu27qoFHXvfWibduIb3ltQx9o+ruPG15u/uz1tVx2HT1wLw3Jxabnuzmic/rtnQTerDH2y82r/zrYZVkOqtrXaUvVHNaXsUAPDzvQs44u51nPvEek7do+n07WFG4qLEzbsfH39cJQw9h5IFEclJeoKziOSm0sLhwOKow+jJnKPm/JrUy7fWfiVrbTukzdYBAyqmTtE/XRHJKSpZEJFcNTbqAHo6MxIXJMr2SMUffSHqWIR+wOZRByEi0l5KFkQkVylZaAMzEqWJW/f4fvwRJQzRU1UkEck5ShZEJFfpLm0bmZH4beK2PU+KP/J81LH0cl3WxkZEpLsoWRCRXKWShXYwI/5/idv2+kH8YSUM0RkRdQAiIu2lZEFEcpVKFtrJjPhvErfv9aN4uRKGaGTtaeMiItmiZEFEcpVKFjrAjPh5iel7nRz/13NRx9ILKVkQkZyjZEFEcpVKFjrIjPi5iTv2/nH8n0oYupeSBRHJOUoWRCRXqf53J5gRL0n8fdIp8YeUMHQfJQsiknOULIhIrtL5q5PMiP0qceek0+IPKmHoHkoWRCTn6J+tiEgvZkbsnMRdk06PP/Bs1LH0Av2iDkBEpL2ULIhIrnJRB5AvzIidnbh7nzPi/1DCkF3xqAMQEWkvJQsiIoIZsV8k7tnnzPj9ShiyR8mCiOScRNQBiIhI91oeiy37JJlY9FEyuXx2QXL9x8lk3dxEomBxPDZgTezFcQN5aWnUMeYnWw5Tog5CRKRdlCyISK5SNaQQa8xWz0kmPv84mVw+O5lc+1FBsnZOIpFYmIj3XxWLDa2GUZgNBYY2twzrxnh7F1cVdQQiIu2lZEFEJEdUQdW8RGJBRUFy6exkcs3sZKL6k2Qy/nki3ndFLFZYaTbSmQ0BBkYdq4SqiToAEZH2UrIgItID1EHd5/H4558kE0tmFyRXzU4mqyqSSZufSBQsi8cGrzPbpA5GYLYFsEXU8UqHVEcdgIhIeylZEBHpBktjsSWf+nYCKz8M2gl8lkgULInHBq6JxYbVwmjMNgU2jTpWyZq1UQcgItJeShZEJFetBoZEHQTAarNVc5KJhR8nk8tmJ5PrPipI1s1JJOKLNrYTGI3ZcPRQrt5uQdQBiIi0l5IFEclVC4Cx2V5JFVR+lkwsCBKBNbMLkjWfJhL2eSLeb0UsNqTSbBRmg4FB2Y5Fcp6SBRHJOUoWRCRXdfrCqxZqP0/EF1YkkotnFyRXz04mqz5JJpifSPQJ2gmMdDAcs3HAuC6IWXo3JQsiknOULIhIrmr1wmtJLLb4k2Ri0UcFyVUfJpPrKpJJ59sJxAeujdkmtTBS7QSkG82POgARkfZSsiAiOWlZLPbp/ET8w+DBYus+SiZr5yYSiUWJ+IDVsdiw4HkCmwCbRB2rSEAlCyKSc5QsiEhOOmDc2AXANlHHIdIOKlkQkZwTizoAEZEO+ijqAETaSSULIpJzlCyISK76OOoARNppbtQBiIi0l5IFEclVnwK1UQch0kYV6VR6ZdRBiIi0l5IFEclJ6VS6Bng/6jhE2uj1qAMQEekIJQsiksteijoAkTZ6LeoAREQ6QsmCiOQyJQuSK1SyICI5ScmCiOQyJQuSK5QsiEhOUrIgIrnsDWB91EGItOLzdCo9L+ogREQ6QsmCiOSsdCpdDcyKOg6RVqhUQURylpIFEcl1qookPd0rUQcgItJRShZEJNe9GHUAIq14NOoAREQ6SsmCiOS6pwEXdRAizVgKzIw6CBGRjlKyICI5LZ1Kf4aqeUjP9Vg6ldaTxkUkZylZEJF88EDUAYg0ozzqAEREOkPJgojkgweiDkAkRB1qryAiOU7JgojkvHQq/Q7wftRxiDQyM51KL4k6CBGRzlCyICL54oGoAxBpRFWQRCTnKVkQkXzxQNQBiDTyYNQBiIh0lpIFEckXM4H5UQchEpiZTqXfjjoIEZHOUrIgInkhnUo74Pao4xAJ/DXqAEREuoKSBRHJJ9PwPdCIRGkFcFfUQYiIdAUlCyKSN9Kp9MfAw1HHIb3e9HQqvTbqIEREuoKSBRHJN9dGHYD0eqqCJCJ5Q8mCiOSbx4EPog5Ceq2X06n0G1EHISLSVZQsiEheCRo6Xxd1HNJrqVRBRPKKkgURyUc3A2uiDkJ6nfnA9KiDEBHpSkoWRCTvpFPpFUBZ1HFIr3NpOpVeF3UQIiJdScmCiOSrSwBduEl3mYOqIIlIHlKyICJ5KZ1KzwP+FHUc0mtckk6lK6MOQkSkqylZEJF8dhmwLOogJO99DNwUdRAiItmgZEFE8lY6lV4OXBp1HJL3Lk6n0tVRByEikg1KFkQk310DzI06CMlbHwK3Rh2EiEi2KFkQkbyWTqXXA6VRxyF569x0Kl0TdRAiItmiZEFEeoNbgLejDkLyzj/TqfS9UQchIpJNShZEJO+lU+la4GSgLupYJG+sAk6LOggRkWxTsiAivUI6lX4edaUqXee8dCqttjAikveULIhIb/Jr4IOog5CcNxO4LuogRES6gznnoo5BRKTbFJcV7ws8Qy+4WeLqHLNLZ5McmmTcz8ax7pN1zCubh6t2EIcxJ4yh/1b9m8w398a5rJq1isTgBNtesu2G4es+9fPXVdZRMLyAsaeMJd4vzpoP1jCvbB6xZIyxp4ylz6g+1K6pZc60OYz7xTjMrDs3O9uqgV3TqfRbUQciItId8v6fpYhIpnQq/RxwddRxdIcljy+hz5g+Gz4vuHsBIw8fyTYXbcOob41iwV0LQucbut9Qin5R1GT4vJvnMfqo0Wx78bYM3m0wix9e7Nfz6BK2OGMLRh0xiqVPLgVg4UMLGfG1EfmWKABcpkRBRHoTJQsi0hudh+8fP29VL61m1RurGHrA0A3DzIy6db6Nd+26WpJDk6HzDth+APEB8SbDK+dX0n97XxIxYMcBrHx1pR8RB1ftqKuqw+JG5cJKapbVMGD8gC7eqsi9BlwcdRAiIt1JyYKI9DrpVHodcCKQt/3jz79jPqOPGQ0ZN/ZHf3c0C+5awLs/f5cFdy5g1JGj2rXMPmP7sOr1VQCsfHkl1Uv9Q4tHTBnBZzd/xpLHlzD8i8NZeO9CRn57ZJdtSw+xFDgynUpXRh2IiEh3UrIgIr1SUB3pF1HHkQ0rZ60kMThBv6J+DYYvfXIpo48dzfg/jmfT727KZzd91q7ljj1pLEueWMKH539I3XpfigDQb1w/tv7t1mxZsiVVi6pIDE0A8Ol1nzLnL3OoWZHzOVkd8L10Kv1x1IGIiHS3RNQBiIhEJZ1KX11cVrwLvpQhb6z9YC0rX1/JqjdW4aodtetrmfOXOayatYpNj9sUgMF7DG53stBnTB+2PGdLACoXVLLqjVUNxjvnWPjQQrY4bQvm3TaPUYePompxFUv+vaTdpRg9zEXpVPqRqIMQEYmCkgUR6e1OASYAe0UdSFcZfdRoRh81GoDV/1vNkkeXsPmPN+eDcz9gzbtrGDhhIGv+t4aCUQXtWm7NyhoSgxO4OseihxYx7KBhDcYvf3Y5g3YeRHxAnLqqOl92HcP/nbseBS6MOggRkaio61QR6fWKy4rHAK8Am0YdS1erTxbG/Wwca95fw/zp86EOLGmMOWEM/Yr6Ub2sms9u/oyinxcBMGfaHNa8u4aa1T45GHn4SIYdOIzFjy9m6RO+t6PBuw1m1FGjNvR2VFdZxydXfkLR2UVYwljz3hrm3TYPixubn7o5fUb3aS7EnqwC2C2dSi+NOhARkagoWRARAYrLiicBM4D23W6XfLUO2C+dSr8WdSAiIlFSA2cRESCdSr8AnBp1HNIj1ABHK1EQEVGyICKyQTqVvgn4v6jjkEg54IfpVPpfUQciItITKFkQEcmQTqUvRg1ae7Nz0ql0WdRBiIj0FEoWREQaSafS5wOXRh2HdLvSdCp9RdRBiIj0JGrgLCLSjOKy4suBs6OOQ7rFJelU+jdRByEi0tMoWRARaUFxWfFVwFlRxyFZdXk6lf5l1EGIiPREShZERFpRXFZ8LXB61HFIl3PAL9Op9B+iDkREpKdSsiAi0gbFZcXnA6VRxyFdphI4IZ1K3x11ICIiPZmSBRGRNiouK04BNwDJqGORTlkKfDOdSj8bdSAiIj2dkgURkXYoLis+BLgHGBp1LNIhHwFfTafS70cdiIhILlDXqSIi7ZBOpZ8A9gL+F3Us0m4vAZOUKIiItJ2SBRGRdkqn0h8AewN6ym/uuBk4KJ1KL4w6EBGRXKJqSCIiHVRcVhwDfgVcgNox9FTLgR+rIbOISMcoWRAR6aTisuKJwO3AjhGHIg09CxyXTqU/jToQEZFcpWpIIiKdlE6lZwG7AVcAddFGI0AtcD4wWYmCiEjnqGRBRKQLFZcVHwiUAeOijqWXqsCXJjwfdSAiIvlAJQsiIl0onUo/DewE3BJxKL1NFfB7oFiJgohI11HJgohIlhSXFe8P/BHYPepY8tzDwE+DXqpERKQLKVkQEcmi4rJiA74LXApsHnE4+eZ94GfpVPrhqAMREclXShZERLpBcVlxX+BnwLnAoIjDyXWrgIuBq9KpdFXUwYiI5DMlCyIi3ai4rHgkcCHwQyAecTi5ZiUwDbgynUp/HnUwIiK9gZIFEZEIFJcVjwN+gk8aCiMOp6ebD1wFXJ9OpVdGHIuISK+iZEFEJELFZcUDgZOAs4CtIg6np3kfuBy4LZ1KV0YdjIhIb6RkQUSkByguK44B38C3azgg4nCiVAc8DVwLPJBOpfWQOxGRCClZEBHpYYrLiifie1A6CiiKNJjuMwuYDtyZTqXnRhyLiIgElCyIiPRgxWXFuwNHk5+JQwVwBzA9nUq/E3EsIiISQsmCiEiOCBKHo4DDge2ijaZDqoGXgaeAR4Dn06m0/gmJiPRgShZERHJQcVnxKGDfjNeuQDLSoJqqAV7BJwczgOfSqfSaSCMSEZF2UbIgIpIHisuK+wF7AvsBewDb4HtX6tdNISwF3gXeC16z8MnB6m5av4iIZIGSBRGRPFZcVrwpPmnYCtg6eB+Hf4p0f3wy0T/jb2u0iEpgDbACWIJPCpYAc/FJwbvAe+lUenG2t0VERLqfkgUREdkgKKHoh29fsDadStdGHJKIiERIyYKIiIiIiISKRR2AiIiIiIj0TEoWREREREQklJIFERFpEzOrNbNZZvaWmd1jZv3bOf8YM7s3+HuimR2WMe4bZlbS1TGLiEjnqM2CiIi0iZmtds4NDP6eDrzqnPtjB5d1IrC7c+6MLgxRRES6mEoWRESkI/4LbGNmw8zsATN708xmmtlOAGZ2YFAKMcvMXjezQWZWFJRKFAAXAscE448xsxPN7FozKzSzCjOLBcvpb2ZzzCxpZlub2aNm9qqZ/dfMxke4/SIivYKSBRERaRczSwBfBdLABcDrzrmdgPOAW4PJzgZOd85NBPYH1tXP75yrAn4L3OWcm+icuytj3ArgDeDAYNDXgcecc9XAX4GfOOd2C5Z/XdY2UkREAEhEHYCIiOSMfmY2K/j7v8CNwIvAEQDOuSfNbLiZFQLPAX8Mqivd75yba9b4eW/Nugs4BngK+A5wnZkNBPYB7slYTp/Ob5KIiLREyYKIiLTVuqCkYAMLzwCcc26qmZUDhwEzzeyLwPo2ruch4FIzGwbsBjwJDACWN16/iIhkl6ohiYhIZzwDHAdgZpOBxc65lWa2tXMu7Zy7DHgFaNy+YBUwKGyBzrnVwEvAn4B/OedqnXMrgY/N7KhgXWZmO2djg0REZCMlCyIi0hmlwO5m9iYwFUgFw38aNGZ+A99e4ZFG8z0F7FDfwDlkuXcB3wve6x0H/CBY5tvAN7tuM0REJIy6ThURERERkVAqWRARERERkVBKFkREREREJJSSBRERERERCaVkQUREREREQilZEBERERGRUEoWREREREQklJIFEREREREJpWRBRERERERCKVkQEREREZFQShZERERERCSUkgUREREREQmlZEFEREREREIpWRARERERkVBKFkREREREJJSSBRERERERCaVkQUREREREQv0/fwm7VStB5YAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#check the Distributin of Sentiments\n",
    "category = ['Negative','Neutral','Positive']\n",
    "values = [data.sentiment.str.count(\"Negative\").sum(),data.sentiment.str.count(\"Neutral\").sum(),data.sentiment.str.count(\"Positive\").sum()]\n",
    "plt.pie(values, labels= category,autopct ='%0.2f%%')\n",
    "plt.title('------------------- percentage Distribution by Sentiment Category -------------------',fontsize=20,color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m------------------- Special characters and punctuation cleaning operations completed. ------------------- \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "We will now clean the data by removing the special characters.\n",
    "\n",
    "\"\"\"\n",
    "#set up punctuations we want to be replaced\n",
    "REPLACE_NO_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\')|(\\?)|(\\,)|(\\\")|(\\|)|(\\()|(\\))|(\\[)|(\\])|(\\%)|(\\$)|(\\>)|(\\<)|(\\{)|(\\})|(\\=)|(\\#)|(\\ยง)\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s/><br\\s/?)|(-)|(/)|(:).\")\n",
    "print(f\"{Fore.BLUE}------------------- Special characters and punctuation cleaning operations completed. ------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m------------------- preparation of the cleaning functions completed. ------------------- \n"
     ]
    }
   ],
   "source": [
    "# custum function to clean the dataset (combining tweet_preprocessor and reguar expression)\n",
    "def clean_tweets(df):\n",
    "  tempArr = []\n",
    "  for line in df:\n",
    "    # send to tweet_processor\n",
    "    tmpL = p.clean(line)\n",
    "    # remove puctuation\n",
    "    tmpL = REPLACE_NO_SPACE.sub(\"\", tmpL.lower()) # convert all tweets to lower cases\n",
    "    tmpL = REPLACE_WITH_SPACE.sub(\" \", tmpL)\n",
    "    tempArr.append(tmpL)\n",
    "  return tempArr\n",
    "\n",
    "print(f\"{Fore.BLUE}------------------- preparation of the cleaning functions completed. ------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m------------------- The message cleaning operation is complete. ------------------- \n"
     ]
    }
   ],
   "source": [
    "# Cleaning up tweets\n",
    "clean_tweet = clean_tweets(data[\"message\"])\n",
    "print(f\"{Fore.BLUE}------------------- The message cleaning operation is complete. ------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m------------------- The clean data column has been successfully added to the dataset. ------------------- \n"
     ]
    }
   ],
   "source": [
    "# append cleaned tweets to the training data\n",
    "clean_tweet = pd.DataFrame(clean_tweet)\n",
    "data[\"clean\"] = clean_tweet\n",
    "print(f\"{Fore.BLUE}------------------- The clean data column has been successfully added to the dataset. ------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m------------------- overview of the dataset with the clean_data column. ------------------- \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>We need to be vaccinated to protect all person...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>we need to be vaccinated to protect all person...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>it is a pleasure to see how the govement are w...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>it is a pleasure to see how the govement are w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>The most popular vaccine that i know is Modern...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>the most popular vaccine that i know is modern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Of course we need to be vaccinated if we want ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>of course we need to be vaccinated if we want ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            message sentiment  \\\n",
       "0   1  We need to be vaccinated to protect all person...  Positive   \n",
       "1   2  it is a pleasure to see how the govement are w...  Positive   \n",
       "2   3                                          Negative   Negative   \n",
       "3   4  The most popular vaccine that i know is Modern...  Positive   \n",
       "4   5  Of course we need to be vaccinated if we want ...  Positive   \n",
       "\n",
       "                                               clean  \n",
       "0  we need to be vaccinated to protect all person...  \n",
       "1  it is a pleasure to see how the govement are w...  \n",
       "2                                           negative  \n",
       "3  the most popular vaccine that i know is modern...  \n",
       "4  of course we need to be vaccinated if we want ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare the cleaned and uncleaned tweets\n",
    "print(f\"{Fore.BLUE}------------------- overview of the dataset with the clean_data column. ------------------- \")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function who help to count unique words\n",
    "\n",
    "def wordCount(text):\n",
    "    count = Counter()\n",
    "    for i in text.values:\n",
    "        for word in i.split():\n",
    "            count[word]+=1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m------------------- The column 'clean' contains:  2540  unique words ------------------- \n"
     ]
    }
   ],
   "source": [
    "# count the number of unique words contained in the set of cleaned expressions. \n",
    "text= data.clean\n",
    "counter = wordCount(text)\n",
    "print(f\"{Fore.BLUE}------------------- The column 'clean' contains: \",len(counter),\" unique words ------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive [0 0 1]\n",
      "Positive [0 0 1]\n",
      "Negative [1 0 0]\n",
      "Positive [0 0 1]\n",
      "Positive [0 0 1]\n",
      "Neutral [0 1 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert sentiment into numeric value\n",
    "y = pd.get_dummies(data['sentiment']).values\n",
    "[print(data['sentiment'][i], y[i]) for i in range(0,6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m------------------- The data was successfully split. ------------------- \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "In this section, we will divide the file (the 'clean' column) \n",
    "into two parts: one part for training and one part for testing.\n",
    "\n",
    "X_train ==> train_sentences\n",
    "X_test ==> test_sentences\n",
    "y_train ==> train_labels\n",
    "y_test ==> test_labels\n",
    "\n",
    "\"\"\"\n",
    "X = data['clean']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "print(f\"{Fore.GREEN}------------------- The data was successfully split. ------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m------------------- Operations completed. ------------------- \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "We will now define the maximum length of a sentence in terms of the number of words it can contain.\n",
    "But first, we define the word count as the number of unique words.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# define the number of words.\n",
    "num_words = len(counter)\n",
    "# maximum number of words in a sentence.\n",
    "max_length = 42\n",
    "print(f\"{Fore.GREEN}------------------- Operations completed. ------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m------------------- tokenization process complete. ------------------- \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "We will now tokenize the text ('clean' column):\n",
    "This means that a unique number is associated with each unique word in the text.\n",
    "\"\"\"\n",
    "\n",
    "tokenizer = Tokenizer(num_words=num_words, split=\" \")\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "print(f\"{Fore.GREEN}------------------- tokenization process complete. ------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m------------------- visualization of the result obtained after tokenization. ------------------- \n",
      "\u001b[30m {'the': 1, 'to': 2, 'i': 3, 'vaccine': 4, 'of': 5, 'is': 6, 'not': 7, 'and': 8, 'a': 9, 'it': 10, 'vaccinated': 11, 'in': 12, 'for': 13, 'vaccines': 14, 'covid': 15, 'are': 16, 'that': 17, 'this': 18, 'be': 19, 'will': 20, 'get': 21, 'my': 22, 'do': 23, 'have': 24, 'am': 25, 'so': 26, 'we': 27, 'you': 28, 'as': 29, 'all': 30, 'people': 31, 'with': 32, 'no': 33, '19': 34, 'us': 35, 'but': 36, 'on': 37, 'vaccination': 38, 'they': 39, 'or': 40, 'if': 41, 'at': 42, 'first': 43, 'me': 44, 'effects': 45, 'take': 46, 'pfizer': 47, 'side': 48, 'want': 49, 'can': 50, 'more': 51, 'good': 52, 'who': 53, 'there': 54, 'about': 55, 'has': 56, 'was': 57, 'because': 58, 'these': 59, 'by': 60, 'been': 61, 'against': 62, 'virus': 63, 'think': 64, 'dose': 65, 'just': 66, 'why': 67, 'like': 68, 'today': 69, 'does': 70, 'when': 71, 'from': 72, 'getting': 73, 'our': 74, 'their': 75, 'should': 76, 'after': 77, 'your': 78, 'got': 79, 'doses': 80, 'very': 81, 'everyone': 82, 'one': 83, 'know': 84, 'those': 85, 'any': 86, 'an': 87, 'would': 88, 'what': 89, 'many': 90, 'than': 91, 'make': 92, 'lives': 93, 'without': 94, 'how': 95, 'go': 96, 'only': 97, 'let': 98, 'going': 99, 'time': 100, 'now': 101, 'never': 102, 'were': 103, 'out': 104, 'still': 105, 'need': 106, 'health': 107, 'free': 108, 'even': 109, 'did': 110, 'disease': 111, 'world': 112, 'being': 113, 'some': 114, 'vaccinate': 115, 'them': 116, 'really': 117, 'up': 118, 'also': 119, 'day': 120, 'well': 121, 'stop': 122, 'two': 123, 'life': 124, 'other': 125, 'coronavirus': 126, 'save': 127, 'thing': 128, 'see': 129, 'enough': 130, 'received': 131, 'trust': 132, 'corona': 133, 'had': 134, 'prices': 135, 'much': 136, 'most': 137, 'years': 138, 'cannot': 139, 'companies': 140, 'money': 141, 'sure': 142, 'wait': 143, 'way': 144, 'safe': 145, 'say': 146, 'risk': 147, 'effective': 148, 'biontech': 149, 'moderna': 150, 'far': 151, 'new': 152, 'its': 153, 'case': 154, 'caign': 155, 'thank': 156, 'end': 157, 'news': 158, 'nothing': 159, 'injection': 160, 'pandemic': 161, 'soon': 162, 'bad': 163, 'which': 164, 'live': 165, 'yes': 166, 'thanks': 167, 'important': 168, 'shot': 169, 'receive': 170, 'protect': 171, 'whether': 172, 'long': 173, 'children': 174, 'believe': 175, 'possible': 176, 'since': 177, 'family': 178, 'same': 179, 'care': 180, 'vaccinations': 181, 'days': 182, 'must': 183, 'again': 184, 'less': 185, 'problem': 186, 'year': 187, 'real': 188, 'great': 189, 'second': 190, 'afraid': 191, 'anyone': 192, 'done': 193, 'find': 194, 'made': 195, 'allergic': 196, 'then': 197, 'best': 198, 'work': 199, 'serious': 200, 'said': 201, 'order': 202, 'hope': 203, 'yet': 204, 'safety': 205, 'laboratories': 206, 'please': 207, 'before': 208, 'others': 209, 'too': 210, 'pharmaceutical': 211, 'covid19': 212, 'use': 213, 'come': 214, 'maybe': 215, 'reactions': 216, 'taken': 217, 'die': 218, 'point': 219, 'might': 220, 'severe': 221, 'ones': 222, 'cure': 223, 'big': 224, 'feeling': 225, 'myself': 226, 'makes': 227, 'taking': 228, 'better': 229, 'given': 230, 'able': 231, 'consequences': 232, 'question': 233, 'choice': 234, 'young': 235, 'own': 236, 'mind': 237, 'prevent': 238, 'excited': 239, 'science': 240, 'patients': 241, 'normal': 242, 'propaganda': 243, 'into': 244, 'tests': 245, 'ive': 246, 'government': 247, 'already': 248, 'population': 249, 'developed': 250, 'effectiveness': 251, 'million': 252, 'happy': 253, 'reaction': 254, 'term': 255, 'personally': 256, 'immunity': 257, 'around': 258, 'fed': 259, 'finally': 260, 'friends': 261, 'such': 262, 'few': 263, 'here': 264, 'course': 265, 'yourself': 266, 'immune': 267, 'back': 268, 'astrazeneca': 269, 'every': 270, 'help': 271, 'option': 272, 'working': 273, 'data': 274, 'arrived': 275, 'last': 276, 'drug': 277, 'useful': 278, 'cases': 279, 'feel': 280, 'available': 281, 'lot': 282, 'testing': 283, 'country': 284, 'business': 285, 'media': 286, 'his': 287, 'human': 288, 'mrna': 289, 'approved': 290, 'person': 291, 'necessary': 292, 'injected': 293, 'administered': 294, 'week': 295, 'alone': 296, 'keep': 297, 'least': 298, 'public': 299, 'future': 300, 'over': 301, 'kind': 302, 'company': 303, 'months': 304, 'weeks': 305, 'infected': 306, 'pharma': 307, 'rid': 308, 'always': 309, 'interested': 310, 'next': 311, 'wonder': 312, 'part': 313, 'dying': 314, 'hospital': 315, 'approves': 316, 'force': 317, 'shows': 318, 'favour': 319, 'respect': 320, 'remain': 321, 'ever': 322, 'old': 323, 'share': 324, 'countries': 325, 'supply': 326, 'stock': 327, 'food': 328, 'could': 329, 'panic': 330, 'until': 331, 'doctors': 332, 'while': 333, 'off': 334, 'scientists': 335, 'st': 336, 'test': 337, 'seen': 338, 'frankly': 339, 'nurse': 340, 'im': 341, 'prefer': 342, 'five': 343, 'consumer': 344, 't': 345, 'africa': 346, 'risks': 347, 'right': 348, 'danger': 349, 'supermarket': 350, 'rather': 351, 'solution': 352, 'almost': 353, 'variant': 354, 'ready': 355, 'between': 356, 'including': 357, 'diseases': 358, 'fear': 359, 'he': 360, 'both': 361, 'certainly': 362, 'system': 363, 'administering': 364, 'reduce': 365, 'contamination': 366, 'pfizers': 367, 'negative': 368, 'allow': 369, 'developing': 370, 'form': 371, 'deaths': 372, 'workers': 373, 'waiting': 374, 'light': 375, 'politicians': 376, 'gets': 377, 'programme': 378, 'put': 379, 'pseudo': 380, 'making': 381, 'adverse': 382, 'except': 383, 'through': 384, 'story': 385, 'works': 386, 'turn': 387, 'reason': 388, 'continue': 389, 'barrier': 390, 'decision': 391, 'third': 392, 'global': 393, 'yesterday': 394, 'emergency': 395, 'according': 396, 'information': 397, 'millions': 398, 'roll': 399, 'ourselves': 400, 'healthcare': 401, 'fact': 402, 'administration': 403, 'positive': 404, 'mass': 405, 'difference': 406, 'charge': 407, 'rollout': 408, 'update': 409, 'americans': 410, 'loved': 411, 'lie': 412, 'employees': 413, 'remember': 414, 'comes': 415, 'coming': 416, 'g': 417, 'stand': 418, 'social': 419, 'him': 420, 'set': 421, 'follow': 422, 'anything': 423, 'announced': 424, 'residents': 425, 'travel': 426, 'situation': 427, 'protein': 428, 'research': 429, 'choose': 430, 'encourage': 431, 'access': 432, 'johnson': 433, 'trials': 434, 'change': 435, 'fake': 436, 'spread': 437, 'body': 438, 'anyway': 439, 'effect': 440, 'mother': 441, 'natural': 442, 'where': 443, 'offering': 444, 'tell': 445, 'look': 446, 'another': 447, 'give': 448, 'drugs': 449, 'happened': 450, 'thinking': 451, 'fda': 452, 'took': 453, 'price': 454, 'down': 455, 'leave': 456, 'grateful': 457, 'trump': 458, 'taxpayers': 459, 'seems': 460, 'thats': 461, 'rate': 462, 'clear': 463, 'true': 464, 'says': 465, 'together': 466, 'conditions': 467, 'impossible': 468, 'thankful': 469, 'known': 470, 'ingredients': 471, 'easier': 472, 'strong': 473, 'pleasure': 474, 'bill': 475, 'gates': 476, 'control': 477, 'avoid': 478, 'industry': 479, 'gives': 480, 'authorities': 481, 'race': 482, 'treatment': 483, 'away': 484, 'cause': 485, 'citizen': 486, 'community': 487, 'dr': 488, 'doing': 489, 'whole': 490, 'scientific': 491, 'fighting': 492, 'her': 493, 'press': 494, 'stay': 495, 'home': 496, 'possibility': 497, 'anti': 498, 'suspicious': 499, 'lets': 500, 'gestures': 501, 'russian': 502, 'mean': 503, 'receiving': 504, 'compulsory': 505, 'affect': 506, 'china': 507, 'west': 508, 'develop': 509, 'changed': 510, 'older': 511, 'honest': 512, 'bullshit': 513, 'during': 514, 'naturally': 515, 'found': 516, 'false': 517, 'problems': 518, 'contagious': 519, 'arrive': 520, 'treatments': 521, 'proud': 522, 'nobody': 523, 'afterwards': 524, 'participate': 525, 'state': 526, 'authorized': 527, 'refuse': 528, 'grocery': 529, 'etc': 530, 'essential': 531, 'private': 532, 'imagine': 533, 'exle': 534, 'dubai': 535, 'doubt': 536, 'everything': 537, 'capitalism': 538, 'harmful': 539, 'useless': 540, 'response': 541, 'causing': 542, 'therefore': 543, 'produce': 544, 'suffer': 545, 'hesitation': 546, 'moment': 547, 'breaking': 548, 'medical': 549, 'hesitate': 550, 'someone': 551, 'usa': 552, 'joe': 553, 'biden': 554, 'view': 555, 'decide': 556, 'begins': 557, 'idea': 558, 'tested': 559, 'talk': 560, 'based': 561, 'pretty': 562, 'create': 563, 'shame': 564, 'cancer': 565, 'forms': 566, 'inject': 567, 'means': 568, 'ridiculous': 569, 'past': 570, 'gov': 571, 'pharmacists': 572, 'matter': 573, 'democrats': 574, 'support': 575, 'profit': 576, 'history': 577, 'humanity': 578, 'pessimistic': 579, 'lose': 580, 'questions': 581, 'hours': 582, 'especially': 583, 'careful': 584, 'wish': 585, 'products': 586, 'potential': 587, 'explain': 588, 'type': 589, 'each': 590, 'commercial': 591, 'cost': 592, 'zero': 593, 'wear': 594, 'fully': 595, 'simply': 596, 'actually': 597, 'raise': 598, 'goes': 599, 'present': 600, 'regulator': 601, 'advise': 602, 'death': 603, 'mask': 604, 'crisis': 605, 'whats': 606, 'experts': 607, 'number': 608, 'wary': 609, 'production': 610, 'fast': 611, 'angry': 612, 'majority': 613, 'governments': 614, 'needs': 615, 'sick': 616, 'conspiracy': 617, 'night': 618, 'self': 619, 'affraid': 620, 'rights': 621, 'ago': 622, 'autoimmune': 623, 'definitely': 624, 'forever': 625, 'sell': 626, 'local': 627, 'experience': 628, 'certainty': 629, 'preserve': 630, 'wants': 631, 'antibodies': 632, 'peace': 633, 'freedom': 634, 'tired': 635, 'house': 636, 'green': 637, 'putting': 638, 'something': 639, 'poison': 640, 'senior': 641, 'difficult': 642, 'certain': 643, 'personal': 644, 'doctor': 645, 'advised': 646, 'awareness': 647, 'producing': 648, 'she': 649, 'london': 650, 'month': 651, 'hands': 652, 'mouth': 653, 'pure': 654, 'deeply': 655, 'confidence': 656, 'scary': 657, 'neutral': 658, 'passport': 659, 'labs': 660, 'honestly': 661, 'apparently': 662, 'impact': 663, 'theres': 664, 'proven': 665, 'rich': 666, 'shipments': 667, 'canada': 668, 'sunday': 669, 'created': 670, 'hostile': 671, 'confident': 672, 'leaky': 673, 'transmission': 674, 'shed': 675, 'may': 676, 'likely': 677, 'gonna': 678, 'anyways': 679, 'popular': 680, 'christmas': 681, 'mutation': 682, 'uk': 683, 'nonsense': 684, 'evil': 685, 'scam': 686, 'scale': 687, 'ppe': 688, 'chain': 689, 'plants': 690, 'interest': 691, 'age': 692, 'hesitating': 693, 'neighbours': 694, 'sent': 695, 'room': 696, 'wouldnt': 697, 'cool': 698, 'full': 699, 'moderne': 700, 'opinion': 701, 'offer': 702, 'stopped': 703, 'debate': 704, 'united': 705, 'approve': 706, 'unexpected': 707, 'african': 708, 'medicines': 709, 'probably': 710, 'beware': 711, 'fraudulent': 712, 'toxic': 713, 'experimental': 714, 'empty': 715, 'special': 716, 'variants': 717, 'tunnel': 718, 'wondering': 719, 'approval': 720, 'opportunity': 721, 'responsible': 722, 'newly': 723, 'guarantee': 724, 'agree': 725, 'stores': 726, 'high': 727, 'specialy': 728, 'arm': 729, 'speed': 730, 'talking': 731, 'hear': 732, 'happens': 733, 'longer': 734, 'paul': 735, 'contribute': 736, 'fight': 737, 'parents': 738, 'matters': 739, 'billions': 740, 'teach': 741, 'cells': 742, 'trigger': 743, 'using': 744, 'stocks': 745, 'knew': 746, 'review': 747, 'europe': 748, 'december': 749, 'expected': 750, 'particular': 751, 'worries': 752, 'understand': 753, 'dont': 754, 'disadvantages': 755, 'assure': 756, 'confinement': 757, 'begin': 758, 'latest': 759, 'women': 760, 'deplore': 761, 'caused': 762, 'things': 763, 'quickly': 764, 'wife': 765, 'low': 766, 'hospitalized': 767, 'measure': 768, 'barier': 769, 'containment': 770, 'little': 771, 'convinced': 772, 'unknown': 773, 'allowed': 774, 'consent': 775, 'substance': 776, 'unvaccinated': 777, 'dangerous': 778, 'requires': 779, 'short': 780, 'rna': 781, 'sufficiently': 782, 'technology': 783, 'traumatic': 784, 'ass': 785, 'mandatory': 786, 'deadly': 787, 'acquired': 788, 'nd': 789, 'spike': 790, 'pity': 791, 'yay': 792, 'fine': 793, 'friday': 794, 'multiple': 795, 'inflated': 796, 'reliability': 797, 'rush': 798, 'per': 799, 'hospitals': 800, 'used': 801, 'unsafe': 802, 'market': 803, 'teenagers': 804, 'hot': 805, 'water': 806, 'prevention': 807, 'rest': 808, 'concern': 809, 'technological': 810, 'run': 811, 'strange': 812, 'kits': 813, 'react': 814, 'poisson': 815, 'via': 816, 'advice': 817, 'saves': 818, 'vulnerable': 819, 'fought': 820, 'affordable': 821, 'costs': 822, 'product': 823, 'credible': 824, 'greatest': 825, 'idiot': 826, 'under': 827, 'agreement': 828, 'though': 829, 'quite': 830, 'starting': 831, 'damn': 832, 'asked': 833, 'success': 834, 'suffering': 835, 'called': 836, 'morning': 837, 'warning': 838, 'lockdown': 839, 'saying': 840, 'shown': 841, 'tetanus': 842, 'post': 843, 'region': 844, 'development': 845, 'recommended': 846, 'vaccin': 847, 'stepping': 848, 'bravery': 849, 'respected': 850, 'wiser': 851, 'require': 852, 'operation': 853, 'kills': 854, 'biggest': 855, 'drop': 856, 'caught': 857, 'beginning': 858, 'epidemic': 859, 'protected': 860, 'receives': 861, 'socially': 862, 'lucky': 863, 'researchers': 864, 'harm': 865, 'large': 866, 'moreover': 867, 'frightening': 868, 'hell': 869, 'scare': 870, 'helps': 871, 'nice': 872, 'member': 873, 'close': 874, 'friend': 875, 'toll': 876, 'tomorrow': 877, 'word': 878, 'later': 879, 'spirit': 880, 'ahead': 881, 'shots': 882, 'fighter': 883, 'planes': 884, 'missiles': 885, 'weapons': 886, 'alaskan': 887, 'worker': 888, 'suffered': 889, 'easing': 890, 'concerns': 891, 'bion': 892, 'transmitting': 893, 'calling': 894, 'distancing': 895, 'happening': 896, 'protection': 897, 'hopefully': 898, 'distributed': 899, 'show': 900, 'childrens': 901, 'vaccinating': 902, 'adolescents': 903, 'publicity': 904, 'excellent': 905, 'task': 906, 'announces': 907, 'shut': 908, 'wont': 909, 'read': 910, 'report': 911, 'procurement': 912, 'pay': 913, 'r': 914, 'd': 915, 'manufacturing': 916, 'makers': 917, 'investor': 918, 'paywall': 919, 'god': 920, 'power': 921, 'six': 922, 'stories': 923, 'step': 924, 'once': 925, 'employer': 926, 'protects': 927, 'indeed': 928, 'man': 929, 'contact': 930, 'three': 931, 'quality': 932, 'russia': 933, 'sheep': 934, 'guinea': 935, 'efficacy': 936, 'affected': 937, 'otherwise': 938, 'everybody': 939, 'gain': 940, 'program': 941, 'keeping': 942, 'june': 943, 'times': 944, 'herd': 945, 'humans': 946, 'allergy': 947, 'intend': 948, 'rodents': 949, 'eat': 950, 'super': 951, 'january': 952, 'thermally': 953, 'stable': 954, 'direct': 955, 'respecting': 956, 'worried': 957, 'refused': 958, 'shape': 959, 'destroy': 960, 'legacy': 961, 'registered': 962, 'told': 963, 'delta': 964, 'cobbled': 965, 'flexible': 966, 'broken': 967, 'don': 968, 'biontechs': 969, 'beat': 970, 'measures': 971, 'relatives': 972, 's': 973, 'appointment': 974, 'advance': 975, 'none': 976, 'bosses': 977, 'pleased': 978, 'suffers': 979, 'minutes': 980, 'prowess': 981, 'reliable': 982, 'saved': 983, 'interesting': 984, 'usually': 985, 'increasing': 986, 'unnecessary': 987, 'started': 988, 'aged': 989, 'pre': 990, 'existing': 991, 'include': 992, 'hypertension': 993, 'diabetes': 994, 'asthma': 995, 'respiratory': 996, 'liver': 997, 'kidney': 998, 'stabilised': 999, 'controlled': 1000, 'chronic': 1001, 'revisit': 1002, 'museums': 1003, 'lasts': 1004, 'alive': 1005, 'proposals': 1006, 'syringes': 1007, 'clever': 1008, 'heh': 1009, 'purely': 1010, 'write': 1011, 'pays': 1012, 'hopeful': 1013, 'humanitarian': 1014, 'watching': 1015, 'smooth': 1016, 'operating': 1017, 'machine': 1018, 'prisoner': 1019, 'leading': 1020, 'resuscitation': 1021, 'four': 1022, 'dread': 1023, 'liveplease': 1024, 'armed': 1025, 'frontline': 1026, 'arms': 1027, 'confined': 1028, 'pressure': 1029, 'funny': 1030, 'absolutely': 1031, 'image': 1032, 'todayimpressive': 1033, 'resource': 1034, 'mobilization': 1035, 'ligma': 1036, 'emirati': 1037, 'logistical': 1038, 'pharmacy': 1039, 'kept': 1040, 'specialized': 1041, 'approv': 1042, 'limited': 1043, 'areas': 1044, 'hijacked': 1045, 'jam': 1046, 'congratulate': 1047, 'vloggers': 1048, 'promotion': 1049, 'promote': 1050, 'successfully': 1051, 'within': 1052, 'programm': 1053, 'huge': 1054, 'involved': 1055, 'ensuring': 1056, 'dit': 1057, 'linked': 1058, 'professor': 1059, 'eyeing': 1060, 'urges': 1061, 'canadians': 1062, 'busting': 1063, 'balls': 1064, 'regions': 1065, 'properly': 1066, 'washed': 1067, 'nose': 1068, 'hate': 1069, 'conceived': 1070, 'haste': 1071, 'aim': 1072, 'inspire': 1073, 'liable': 1074, 'singapore': 1075, 'listened': 1076, 'gp': 1077, 'listen': 1078, 'morons': 1079, 'imagined': 1080, 'road': 1081, 'plan': 1082, 'questionable': 1083, 'govement': 1084, 'starvation': 1085, 'malnutrition': 1086, 'invention': 1087, 'menstruation': 1088, 'status': 1089, 'purpose': 1090, 'initial': 1091, 'selected': 1092, 'ports': 1093, 'entry': 1094, '4': 1095, 'types': 1096, 'extreme': 1097, 'accept': 1098, 'interessed': 1099, 'illness': 1100, 'sad': 1101, 'gift': 1102, 'grandmothers': 1103, 'retirement': 1104, 'slaves': 1105, 'receivers': 1106, 'momentous': 1107, 'detected': 1108, 'astraastrazeneka': 1109, 'suspicion': 1110, 'mistrust': 1111, 'holding': 1112, 'deliveries': 1113, 'major': 1114, 'banning': 1115, 'exports': 1116, 'artemesia': 1117, 'officialized': 1118, 'organizations': 1119, 'neglected': 1120, 'article': 1121, 'limits': 1122, 'doesnt': 1123, 'learned': 1124, 'departure': 1125, 'forcing': 1126, 'bosnia': 1127, 'sinovac': 1128, 'confused': 1129, 'contradictory': 1130, 'circulating': 1131, 'bogus': 1132, 'kit': 1133, 'senators': 1134, 'insider': 1135, 'trading': 1136, 'doubles': 1137, 'capitol': 1138, 'hill': 1139, 'common': 1140, 'folk': 1141, 'supporter': 1142, 'efforts': 1143, 'kingdom': 1144, 'scotland': 1145, 'place': 1146, 'chloroquine': 1147, 'traditional': 1148, 'eyes': 1149, 'professionals': 1150, 'nurses': 1151, 'caregivers': 1152, 'bothering': 1153, 'insist': 1154, 'authorization': 1155, 'developer': 1156, 'vijay': 1157, 'reddy': 1158, 'berlin': 1159, 'astra': 1160, 'astrazeneka': 1161, 'controversy': 1162, 'brought': 1163, 'perfection': 1164, 'calm': 1165, 'tiktok': 1166, 'losing': 1167, 'minds': 1168, 'throwing': 1169, 'urge': 1170, 'however': 1171, 'willing': 1172, 'corresponds': 1173, 'becerra': 1174, 'medicine': 1175, 'cdc': 1176, 'ways': 1177, 'officially': 1178, 'icu': 1179, 'sandra': 1180, 'lindsay': 1181, 'prepping': 1182, 'shipment': 1183, 'sites': 1184, 'object': 1185, 'ceo': 1186, 'firsti': 1187, 'takeanother': 1188, 'street': 1189, 'regret': 1190, 'tol': 1191, 'nor': 1192, 'implore': 1193, 'amid': 1194, 'historic': 1195, 'imperative': 1196, 'citizens': 1197, 'themselves': 1198, 'families': 1199, 'uses': 1200, 'organisation': 1201, 'agns': 1202, 'buzyn': 1203, 'laugh': 1204, 'loud': 1205, 'heres': 1206, 'compares': 1207, 'provide': 1208, 'outdated': 1209, 'dunno': 1210, 'non': 1211, 'list': 1212, 'previous': 1213, 'governors': 1214, 'mayors': 1215, 'shops': 1216, 'concessions': 1217, 'hardware': 1218, 'determining': 1219, 'patents': 1220, 'arses': 1221, 'sfr': 1222, 'cant': 1223, 'needle': 1224, 'inserted': 1225, 'iv': 1226, 'emmanuel': 1227, 'macron': 1228, 'himself': 1229, 'images': 1230, 'broadcast': 1231, 'television': 1232, 'enjoy': 1233, 'tp': 1234, 'hoarding': 1235, 'played': 1236, 'role': 1237, 'biya': 1238, 'constraints': 1239, 'decided': 1240, 'chinese': 1241, 'tourists': 1242, 'bring': 1243, 'usual': 1244, 'return': 1245, 'politicized': 1246, 'play': 1247, 'anyhow': 1248, 'observe': 1249, 'credibility': 1250, 'forgot': 1251, 'expensive': 1252, 'soared': 1253, 'lying': 1254, 'winning': 1255, 'joke': 1256, 'adds': 1257, 'rd': 1258, 'th': 1259, 'surreal': 1260, 'dropping': 1261, 'meeting': 1262, 'possibly': 1263, 'approving': 1264, 'bumped': 1265, 'assume': 1266, 'concentrate': 1267, 'atshmatic': 1268, 'mucus': 1269, 'store': 1270, 'employee': 1271, 'respectfully': 1272, 'request': 1273, 'truck': 1274, 'drivers': 1275, 'managers': 1276, 'asap': 1277, 'continuation': 1278, 'oh': 1279, 'freer': 1280, 'completely': 1281, 'beings': 1282, 'rushes': 1283, 'september': 1284, 'licensed': 1285, 'pregnant': 1286, 'clinic': 1287, 'lots': 1288, 'slowness': 1289, 'caigns': 1290, 'brussels': 1291, 'bureaucracy': 1292, 'move': 1293, 'inform': 1294, 'sides': 1295, 'tolerated': 1296, 'sickness': 1297, 'itself': 1298, 'happiest': 1299, 'texting': 1300, 'shes': 1301, 'yours': 1302, 'level': 1303, 'realy': 1304, 'm': 1305, 'handled': 1306, 'occurred': 1307, 'tuesday': 1308, 'cameroon': 1309, 'single': 1310, 'graveling': 1311, 'feet': 1312, 'killed': 1313, 'k': 1314, 'appreciate': 1315, 'delaware': 1316, 'displays': 1317, 'heightened': 1318, 'propensity': 1319, 'initiate': 1320, 'origin': 1321, 'property': 1322, 'poorly': 1323, 'researched': 1324, 'realise': 1325, 'barely': 1326, 'text': 1327, 'ie': 1328, 'knowing': 1329, 'founder': 1330, 'biotechnology': 1331, 'hat': 1332, 'attention': 1333, 'phase': 1334, 'dec': 1335, 'resistant': 1336, 'messenger': 1337, 'advanced': 1338, 'catch': 1339, 'bug': 1340, 'law': 1341, 'coma': 1342, 'laughing': 1343, 'thought': 1344, 'schools': 1345, 'closed': 1346, 'carriers': 1347, 'infection': 1348, 'poooor': 1349, 'reputation': 1350, 'premature': 1351, 'adjusted': 1352, 'dominant': 1353, 'melove': 1354, 'verb': 1355, 'council': 1356, 'communicate': 1357, 'warn': 1358, 'society': 1359, 'viruses': 1360, 'ummc': 1361, 'batch': 1362, 'congratulations': 1363, 'uncertain': 1364, 'sue': 1365, 'saturated': 1366, 'deprogramming': 1367, 'catastrophic': 1368, 'rotten': 1369, 'bribing': 1370, 'neither': 1371, 'produced': 1372, 'design': 1373, 'incentives': 1374, 'ventilators': 1375, 'economists': 1376, 'navigate': 1377, 'reasonable': 1378, 'whose': 1379, 'medium': 1380, 'emotional': 1381, 'opted': 1382, 'agency': 1383, 'authorizes': 1384, 'day3': 1385, 'supposedly': 1386, 'advantage': 1387, 'advances': 1388, 'building': 1389, 'trial': 1390, 'extending': 1391, 'effort': 1392, 'eager': 1393, 'drama': 1394, 'calls': 1395, 'emails': 1396, 'visitors': 1397, 'asking': 1398, 'usernames': 1399, 'pasords': 1400, 'links': 1401, 'heavily': 1402, 'convicted': 1403, 'fraud': 1404, 'stake': 1405, 'become': 1406, 'notice': 1407, 'nhs': 1408, 'picture': 1409, 'video': 1410, 'actual': 1411, 'gone': 1412, 'deceived': 1413, 'baby': 1414, 'increase': 1415, 'restrictions': 1416, 'decrease': 1417, 'israel': 1418, 'conscious': 1419, 'team': 1420, 'george': 1421, 'soros': 1422, 'try': 1423, 'views': 1424, 'touch': 1425, 'monopolies': 1426, 'unaffordable': 1427, 'amoral': 1428, 'dangerously': 1429, 'stupid': 1430, 'bc': 1431, 're': 1432, 'defeat': 1433, 'looked': 1434, 'nonprofits': 1435, 'medicaid': 1436, 'thankfully': 1437, 'definition': 1438, 'vocation': 1439, 'adapt': 1440, 'mutating': 1441, 'impression': 1442, 'maximum': 1443, 'leads': 1444, 'positiv': 1445, 'remedy': 1446, 'accepted': 1447, 'auditioned': 1448, 'visible': 1449, 'trying': 1450, 'hold': 1451, 'accountable': 1452, 'brothers': 1453, 'heroes': 1454, 'additional': 1455, 'peoples': 1456, 'traumatize': 1457, 'lost': 1458, 'refusing': 1459, 'collective': 1460, 'suicide': 1461, 'sanitary': 1462, 'leaders': 1463, 'seem': 1464, 'vacations': 1465, 'wrong': 1466, 'suppose': 1467, 'documents': 1468, 'id': 1469, 'hearing': 1470, 'sosomething': 1471, 'initiative': 1472, 'intrigued': 1473, 'australia': 1474, 'outbreak': 1475, 'woolworths': 1476, 'shopping': 1477, 'elderly': 1478, 'disabled': 1479, 'thead': 1480, 'epidemiologist': 1481, 'count': 1482, 'experiment': 1483, 'creation': 1484, 'atrocities': 1485, 'officials': 1486, 'medicare': 1487, 'claims': 1488, 'identity': 1489, 'theft': 1490, 'schemes': 1491, 'packages': 1492, 'ap': 1493, 'models': 1494, 'percent': 1495, 'saudis': 1496, 'expats': 1497, 'messing': 1498, 'heads': 1499, 'uphow': 1500, 'ride': 1501, 'pfeizer': 1502, 'paranoid': 1503, 'litteraly': 1504, 'causes': 1505, 'shortage': 1506, 'bothered': 1507, 'reached': 1508, 'federal': 1509, 'hurt': 1510, 'rusty': 1511, 'piece': 1512, 'iron': 1513, 'financial': 1514, 'scandal': 1515, 'volunteer': 1516, 'nights': 1517, 'shift': 1518, 'paid': 1519, 'sudden': 1520, 'reassuring': 1521, 'undecided': 1522, 'currently': 1523, 'mild': 1524, 'moderate': 1525, 'site': 1526, 'tells': 1527, 'exists': 1528, 'issued': 1529, 'advising': 1530, 'rapidly': 1531, 'facilitate': 1532, 'persons': 1533, 'maturity': 1534, 'key': 1535, 'jennifer': 1536, 'haller': 1537, 'healthy': 1538, 'became': 1539, 'owe': 1540, 'debt': 1541, 'gratitude': 1542, 'came': 1543, 'decisions': 1544, 'acceptable': 1545, 'stick': 1546, 'complications': 1547, 'o': 1548, 'practically': 1549, 'disappeared': 1550, 'specific': 1551, 'heist': 1552, 'looting': 1553, 'half': 1554, 'africas': 1555, 'resources': 1556, 'ruining': 1557, 'prospect': 1558, 'meanwhile': 1559, 'significant': 1560, 'comparison': 1561, 'marc': 1562, 'siegel': 1563, 'nyu': 1564, 'langone': 1565, 'slip': 1566, 'animal': 1567, 'distant': 1568, 'wave': 1569, 'pendemia': 1570, 'vehemently': 1571, 'opposed': 1572, 'partly': 1573, 'catching': 1574, 'desperately': 1575, 'sign': 1576, 'petition': 1577, 'demanding': 1578, 'reasearch': 1579, 'condition': 1580, 'cheap': 1581, 'extent': 1582, 'figures': 1583, 'fourth': 1584, 'fifth': 1585, 'sixth': 1586, 'seventh': 1587, 'loop': 1588, 'ends': 1589, 'weekend': 1590, 'seeing': 1591, 'begun': 1592, 'prototype': 1593, 'animals': 1594, 'laboratory': 1595, 'siberia': 1596, 'russias': 1597, 'holiday': 1598, 'als': 1599, 'confirmed': 1600, 'above': 1601, 'advantages': 1602, 'outweigh': 1603, 'guide': 1604, 'notgiven': 1605, 'approvals': 1606, 'expects': 1607, 'minimal': 1608, 'immense': 1609, 'nuclear': 1610, 'magnitude': 1611, 'action': 1612, 'economy': 1613, 'brake': 1614, 'concerned': 1615, 'check': 1616, 'recap': 1617, 'warm': 1618, 'spreading': 1619, 'repeat': 1620, 'mistake': 1621, 'jeopardized': 1622, 'mine': 1623, 'wednesday': 1624, 'risking': 1625, 'vi': 1626, 'patient': 1627, 'tv': 1628, 'gild': 1629, 'monthly': 1630, 'higher': 1631, 'appears': 1632, 'positioned': 1633, 'automatically': 1634, 'enters': 1635, 'bloodstream': 1636, 'horrible': 1637, 'marketing': 1638, 'misleading': 1639, 'produces': 1640, 'hand': 1641, 'sanitizer': 1642, 'claim': 1643, 'built': 1644, 'quarterly': 1645, 'cured': 1646, 'medication': 1647, 'remains': 1648, 'compared': 1649, 'cold': 1650, 'across': 1651, 'county': 1652, 'chip': 1653, 'woman': 1654, 'died': 1655, 'manufactured': 1656, 'supervising': 1657, 'torn': 1658, 'firstish': 1659, 'gene': 1660, 'therapy': 1661, 'reassure': 1662, 'harmlessness': 1663, 'warp': 1664, 'speedplease': 1665, 'fail': 1666, 'warned': 1667, 'president': 1668, 'pushed': 1669, 'speaking': 1670, 'department': 1671, 'justice': 1672, 'website': 1673, 'unfortunate': 1674, 'normally': 1675, 'study': 1676, 'spends': 1677, 'eventually': 1678, 'faster': 1679, 'spy': 1680, 'complaining': 1681, 'wearing': 1682, 'piss': 1683, 'posing': 1684, 'late': 1685, 'j': 1686, 'usedas': 1687, 'influence': 1688, 'name': 1689, 'suggests': 1690, 'predict': 1691, 'mutant': 1692, 'unbelievable': 1693, 'ha': 1694, 'looking': 1695, 'liquidate': 1696, 'ideal': 1697, 'targets': 1698, 'listed': 1699, 'various': 1700, 'markets': 1701, 'pushing': 1702, 'finding': 1703, 'cures': 1704, 'push': 1705, 'identified': 1706, 'undoubtably': 1707, 'regulators': 1708, 'workso': 1709, 'lethal': 1710, 'takes': 1711, 'greater': 1712, 'vary': 1713, 'pperson': 1714, 'hence': 1715, 'neutrality': 1716, 'playing': 1717, 'unbelievably': 1718, 'clearconfirmed': 1719, 'tick': 1720, 'remembers': 1721, 'early': 1722, 'childhood': 1723, 'hcw': 1724, 'assuage': 1725, 'anxiety': 1726, 'regarding': 1727, 'liberty': 1728, 'worked': 1729, 'daft': 1730, 'hurts': 1731, 'ears': 1732, 'listening': 1733, 'impressive': 1734, 'retrovirus': 1735, 'sinopharm': 1736, 'ok': 1737, 'releases': 1738, 'kiss': 1739, 'ceased': 1740, 'passed': 1741, 'military': 1742, 'industrialists': 1743, 'main': 1744, 'objects': 1745, 'selection': 1746, 'tend': 1747, 'ignoramuses': 1748, 'charlatans': 1749, 'theorists': 1750, 'scarier': 1751, 'responsibility': 1752, 'okay': 1753, 'sceptical': 1754, 'pigs': 1755, 'california': 1756, 'nightgov': 1757, 'gav': 1758, 'total': 1759, 'distanced': 1760, 'staff': 1761, 'patiently': 1762, 'anymore': 1763, 'numbers': 1764, 'serving': 1765, 'cobaille': 1766, 'taxes': 1767, 'pisses': 1768, 'kill': 1769, 'arabian': 1770, 'peninsula': 1771, 'dromois': 1772, 'reserves': 1773, 'mid': 1774, 'july': 1775, 'complete': 1776, 'folks': 1777, 'eff': 1778, 'despite': 1779, 'rare': 1780, 'looks': 1781, 'expire': 1782, 'rages': 1783, 'tonight': 1784, 'flexing': 1785, 'anesthesia': 1786, 'surgeries': 1787, 'apart': 1788, 'introduced': 1789, 'b': 1790, 'recherches': 1791, 'nura': 1792, 'emir': 1793, 'festi': 1794, 'brave': 1795, 'often': 1796, 'regularly': 1797, 'office': 1798, 'prioritized': 1799, 'constantly': 1800, 'annihilate': 1801, 'imminent': 1802, 'paranormal': 1803, 'girl': 1804, 'challenge': 1805, 'ensure': 1806, 'treated': 1807, 'accessible': 1808, 'optimistic': 1809, 'polyethylene': 1810, 'glycol': 1811, 'heath': 1812, 'protocol': 1813, 'funerals': 1814, 'pucking': 1815, 'wht': 1816, 'states': 1817, 'survival': 1818, 'clearly': 1819, 'astrazaneca': 1820, 'unless': 1821, 'savinghuman': 1822, 'eu': 1823, 'hundreds': 1824, 'reasons': 1825, 'stella': 1826, 'maris': 1827, 'offered': 1828, 'recently': 1829, 'consider': 1830, 'thag': 1831, 'statistics': 1832, 'percentage': 1833, 'c': 1834, 'appearance': 1835, 'management': 1836, 'reinforced': 1837, 'pessimism': 1838, 'ehpad': 1839, 'testify': 1840, 'disappear': 1841, 'stabilitechs': 1842, 'intended': 1843, 'delivered': 1844, 'disruptive': 1845, 'capsule': 1846, 'efficacious': 1847, 'capsules': 1848, 'inexpensive': 1849, 'posted': 1850, 'beliefs': 1851, 'convictions': 1852, 'elsewhere': 1853, 'fragile': 1854, 'incredible': 1855, 'academic': 1856, 'critical': 1857, 'scared': 1858, 'privileged': 1859, 'dosis': 1860, 'memorial': 1861, 'mir': 1862, 'expectedcovid': 1863, 'superior': 1864, 'polishes': 1865, 'judgment': 1866, 'decades': 1867, 'smallpox': 1868, 'rome': 1869, 'warns': 1870, 'youre': 1871, 'held': 1872, 'warehouses': 1873, 'honored': 1874, 'gettin': 1875, 'induce': 1876, 'carried': 1877, 'difficulty': 1878, 'picking': 1879, 'solved': 1880, 'operator': 1881, 'failed': 1882, 'deliver': 1883, 'promises': 1884, 'nation': 1885, 'senate': 1886, 'republicans': 1887, 'investors': 1888, 'immigrant': 1889, 'muslim': 1890, 'couple': 1891, 'energy': 1892, 'shop': 1893, 'restaurant': 1894, 'achieve': 1895, 'mockery': 1896, 'misinformation': 1897, 'believing': 1898, 'aspire': 1899, 'favor': 1900, 'ship': 1901, 'missouris': 1902, 'quiet': 1903, 'madness': 1904, 'incite': 1905, 'thesis': 1906, 'convincing': 1907, 'contradictions': 1908, 'ill': 1909, 'benefit': 1910, 'suppository': 1911, 'faint': 1912, 'writing': 1913, 'book': 1914, 'masks': 1915, 'value': 1916, 'convince': 1917, 'worlds': 1918, 'pension': 1919, 'rolling': 1920, 'amazing': 1921, 'guidance': 1922, 'whilst': 1923, 'breastfeeding': 1924, 'urgently': 1925, 'needed': 1926, 'men': 1927, 'booked': 1928, 'molecules': 1929, 'treat': 1930, 'sham': 1931, 'againts': 1932, 'virusbecause': 1933, 'vacination': 1934, 'persones': 1935, 'drasticaly': 1936, 'reduced': 1937, 'courage': 1938, 'possi': 1939, 'start': 1940, 'desease': 1941, 'corp': 1942, 'rising': 1943, 'pharmaceuticals': 1944, 'doubled': 1945, 'safeguards': 1946, 'jacking': 1947, 'insisting': 1948, 'wors': 1949, 'mama': 1950, 'michel': 1951, 'march': 1952, 'helped': 1953, 'sydney': 1954, 'pandemie': 1955, 'privilege': 1956, 'oms': 1957, 'mortality': 1958, 'contract': 1959, 'transmit': 1960, 'damage': 1961, 'having': 1962, 'notbeen': 1963, 'glad': 1964, 'fauci': 1965, 'aner': 1966, 'defense': 1967, 'composition': 1968, 'thr': 1969, 'compagnie': 1970, 'pants': 1971, 'vacated': 1972, 'certified': 1973, 'contrary': 1974, 'directly': 1975, 'quebec': 1976, 'maimonides': 1977, 'among': 1978, 'seniors': 1979, 'lucrative': 1980, 'model': 1981, 'permanent': 1982, 'oripire': 1983, 'record': 1984, 'intriguing': 1985, 'outcome': 1986, 'fill': 1987, 'coffers': 1988, 'whatever': 1989, 'immunizes': 1990, 'arose': 1991, 'guys': 1992, 'eliminate': 1993, 'unbearable': 1994, 'ego': 1995, 'roof': 1996, 'dizzy': 1997, 'faints': 1998, 'tennessee': 1999, 'hospita': 2000, 'theyd': 2001, 'buy': 2002, 'extrapolated': 2003, 'cartels': 2004, 'payback': 2005, 'arise': 2006, 'thousands': 2007, 'malaria': 2008, 'shaken': 2009, 'becoming': 2010, 'international': 2011, 'affair': 2012, 'forget': 2013, 'tragic': 2014, 'episode': 2015, 'century': 2016, 'recover': 2017, 'call': 2018, 'dictatorship': 2019, 'although': 2020, 'designed': 2021, 'threatened': 2022, 'iran': 2023, 'helpfully': 2024, 'destined': 2025, 'limit': 2026, 'competition': 2027, 'recipe': 2028, 'motivated': 2029, 'european': 2030, 'union': 2031, 'harmless': 2032, 'comorbidity': 2033, 'whitout': 2034, 'oclock': 2035, 'freshly': 2036, 'victims': 2037, 'compensated': 2038, 'concerning': 2039, 'multinational': 2040, 'fuss': 2041, 'preferenceany': 2042, 'kissed': 2043, 'goodbye': 2044, 'beautiful': 2045, 'distance': 2046, 'allergies': 2047, 'tolerating': 2048, 'different': 2049, 'treats': 2050, 'leaving': 2051, 'surprising': 2052, 'sheet': 2053, 'providers': 2054, 'experiencing': 2055, 'similar': 2056, 'trusts': 2057, 'republic': 2058, 'commodity': 2059, 'primarily': 2060, 'miss': 2061, 'grandmother': 2062, 'tendency': 2063, 'europeans': 2064, 'expenditure': 2065, 'purposes': 2066, 'crap': 2067, 'massive': 2068, 'novel': 2069, 'minister': 2070, 'saw': 2071, 'presentation': 2072, 'jarvits': 2073, 'centre': 2074, 'superb': 2075, 'face': 2076, 'pieces': 2077, 'top': 2078, 'email': 2079, 'join': 2080, 'ranks': 2081, 'summary': 2082, 'evidence': 2083, 'particularly': 2084, 'helpful': 2085, 'primary': 2086, 'l': 2087, 'wanted': 2088, 'amazed': 2089, 'turnaround': 2090, 'mostly': 2091, 'spoke': 2092, 'dull': 2093, 'achey': 2094, 'sore': 2095, 'deltoid': 2096, 'giving': 2097, 'bar': 2098, 'fewer': 2099, 'naysayers': 2100, 'dog': 2101, 'chickens': 2102, 'underestimate': 2103, 'invented': 2104, 'capitalists': 2105, 'charade': 2106, 'contain': 2107, 'collect': 2108, 'issues': 2109, 'transporting': 2110, 'desired': 2111, 'basis': 2112, 'alternatives': 2113, 'grandmas': 2114, 'secrets': 2115, 'proper': 2116, 'bra': 2117, 'stole': 2118, 'orcas': 2119, 'rice': 2120, 'showed': 2121, 'uae': 2122, 'timely': 2123, 'oregon': 2124, 'becomes': 2125, 'deal': 2126, 'chemo': 2127, 'alzheimers': 2128, 'parkinsons': 2129, 'aids': 2130, 'miracle': 2131, 'pig': 2132, 'investigating': 2133, 'formally': 2134, 'casts': 2135, 'votes': 2136, 'surprised': 2137, 'learn': 2138, 'immunosuppressed': 2139, 'hurraah': 2140, 'disparity': 2141, 'clinical': 2142, 'aware': 2143, 'moments': 2144, 'sisters': 2145, 'daughter': 2146, 'propagation': 2147, 'somewhere': 2148, 'priority': 2149, 'queue': 2150, 'lack': 2151, 'hindsight': 2152, 'annoyed': 2153, 'proportion': 2154, 'disorders': 2155, 'whereas': 2156, 'hardly': 2157, 'began': 2158, 'jabs': 2159, 'chance': 2160, 'armor': 2161, 'excuse': 2162, 'coffin': 2163, 'poisons': 2164, 'left': 2165, 'flocking': 2166, 'tragedy': 2167, 'corporate': 2168, 'greed': 2169, 'interact': 2170, 'complain': 2171, 'saturate': 2172, 'sterile': 2173, 'importance': 2174, 'arriving': 2175, 'medicin': 2176, 'win': 2177, 'starts': 2178, 'hopes': 2179, 'launch': 2180, 'watchdog': 2181, 'rospotrebnadzor': 2182, 'proposing': 2183, 'scammers': 2184, 'headlines': 2185, 'precipitation': 2186, 'lung': 2187, 'obligation': 2188, 'guilty': 2189, 'hey': 2190, 'terfs': 2191, 'heard': 2192, 'trans': 2193, 'vax': 2194, 'lick': 2195, 'counters': 2196, 'transit': 2197, 'seats': 2198, 'boose': 2199, 'tough': 2200, 'myth': 2201, 'terf': 2202, 'meet': 2203, 'alarmed': 2204, 'mainly': 2205, 'massively': 2206, 'consideration': 2207, 'manufacturers': 2208, 'alongside': 2209, 'microchip': 2210, 'u2': 2211, 'album': 2212, 'capacity': 2213, 'resist': 2214, 'smells': 2215, 'war': 2216, 'concretely': 2217, 'motivates': 2218, 'inventors': 2219, 'technique': 2220, 'claiming': 2221, 'raised': 2222, 'organization': 2223, 'import': 2224, 'neonuclear': 2225, 'tan': 2226, 'taxpayer': 2227, 'curb': 2228, 'injections': 2229, 'prevents': 2230, 'worse': 2231, 'skeptics': 2232, 'evening': 2233, 'premiere': 2234, 'period': 2235, 'urgent': 2236, 'warnings': 2237, 'chaos': 2238, 'hunt': 2239, 'shitty': 2240, 'mot': 2241, 'tears': 2242, 'gave': 2243, 'joy': 2244}\n"
     ]
    }
   ],
   "source": [
    "# visualization of the result obtained after tokenization.\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print(f\"{Fore.GREEN}------------------- visualization of the result obtained after tokenization. ------------------- \")\n",
    "print(f\"{Fore.BLACK}\",word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    " Let's apply the tokenisation operation to each expression in column x. \n",
    "This will allow us to observe that each expression is identifiable by a group of numbers.\n",
    "\"\"\"\n",
    "\n",
    "train_sequences = tokenizer.texts_to_sequences(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we need to be vaccinated to protect all person around us\n",
      "\u001b[34m first sentence. ===>  we need to be vaccinated to protect all person around us\n",
      "\u001b[34m first sentence. ===>  [15, 34, 14, 16, 145, 13, 137, 31, 989, 138, 8, 301, 357, 85, 32, 990, 991, 467, 5, 86, 302, 357, 623, 358, 59, 992, 993, 994, 995, 996, 997, 40, 998, 111, 40, 999, 8, 1000, 1001, 467]\n",
      "\u001b[32m second sentence.  ===> it is a pleasure to see how the govement are working for our help i thing the vaccination is good for all of us\n",
      "\u001b[34m second sentence. ===>  [3, 50, 101, 1002, 1003, 261, 8, 94, 86, 359, 30, 18, 167, 2, 22, 80, 5, 126, 14]\n",
      "\u001b[35m third sentence.  ===>  negative\n",
      "\u001b[34m third sentence. ===>  [9, 211, 303, 20, 624, 146, 17, 1, 4, 1004, 625, 89, 76, 360, 626, 197]\n"
     ]
    }
   ],
   "source": [
    "# Let's see what the first three expressions of the document look like after the tokenisation operation.\n",
    "print(data.clean[0])\n",
    "print(f\"{Fore.BLUE} first sentence. ===> \",data.clean[0])\n",
    "print(f\"{Fore.BLUE} first sentence. ===> \",train_sequences[0])\n",
    "\n",
    "print(f\"{Fore.GREEN} second sentence.  ===>\",data.clean[1])\n",
    "print(f\"{Fore.BLUE} second sentence. ===> \",train_sequences[1])\n",
    "\n",
    "print(f\"{Fore.MAGENTA} third sentence.  ===> \",data.clean[2])\n",
    "print(f\"{Fore.BLUE} third sentence. ===> \",train_sequences[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We will try to transform each expression in the tokenizer to the length format defined above.\n",
    "This allows us to have expressions of the same length.\n",
    "\"\"\"\n",
    "\n",
    "train_padded = pad_sequences(train_sequences, maxlen=max_length, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m first sentence. ===>  [  15   34   14   16  145   13  137   31  989  138    8  301  357   85\n",
      "   32  990  991  467    5   86  302  357  623  358   59  992  993  994\n",
      "  995  996  997   40  998  111   40  999    8 1000 1001  467    0    0]\n",
      "\u001b[32m second sentence.  ===> [   3   50  101 1002 1003  261    8   94   86  359   30   18  167    2\n",
      "   22   80    5  126   14    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "\u001b[35m third sentence.  ===>  [   9  211  303   20  624  146   17    1    4 1004  625   89   76  360\n",
      "  626  197    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "# Let's see what the first three expressions of the document look like after the operation.\n",
    "\n",
    "print(f\"{Fore.BLUE} first sentence. ===> \",train_padded[0])\n",
    "print(f\"{Fore.GREEN} second sentence.  ===>\",train_padded[1])\n",
    "print(f\"{Fore.MAGENTA} third sentence.  ===> \",train_padded[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we repeat the same operations on the test sentences\n",
    "\n",
    "\"\"\"\n",
    "We will try to transform each expression in the tokenizer to the length format defined above.\n",
    "This allows us to have expressions of the same length.\n",
    "\"\"\"\n",
    "\n",
    "test_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "test_padded = pad_sequences(test_sequences, maxlen=max_length, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m Shape of train. ===>  {(818, 42)}\n",
      "\u001b[34m Shape of train. ===>  {(205, 42)}\n",
      "\u001b[32m This means that 80% of the training data corresponds to 817 sentences of 42 words each. \n"
     ]
    }
   ],
   "source": [
    "# how our training data is dimensioned.\n",
    "print(f\"{Fore.BLUE} Shape of train. ===> \",{train_padded.shape})\n",
    "print(f\"{Fore.BLUE} Shape of train. ===> \",{test_padded.shape})\n",
    "print(f\"{Fore.GREEN} This means that 80% of the training data corresponds to 817 sentences of 42 words each. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 42, 100)           254000    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 42, 100)           0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 42, 64)            42240     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 32)                12416     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 308,755\n",
      "Trainable params: 308,755\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "We will now create a model that will be adapted to binary data. That is, with two labels, positive and negative\n",
    "\n",
    "positive ==> [0 0 1]\n",
    "Neutral  ==> [1 0 0]\n",
    "Negative ==> [0 1 0]\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# define model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(num_words, 100, input_length=max_length))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.1))\n",
    "model.add(LSTM(32, dropout=0.2, recurrent_dropout=0.1))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "optimizer = Adam()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "52/52 - 49s - loss: 1.0280 - accuracy: 0.4303\n",
      "Epoch 2/10\n",
      "52/52 - 5s - loss: 1.0111 - accuracy: 0.4633\n",
      "Epoch 3/10\n",
      "52/52 - 5s - loss: 1.0041 - accuracy: 0.4474\n",
      "Epoch 4/10\n",
      "52/52 - 6s - loss: 0.9840 - accuracy: 0.4682\n",
      "Epoch 5/10\n",
      "52/52 - 5s - loss: 0.8453 - accuracy: 0.5672\n",
      "Epoch 6/10\n",
      "52/52 - 6s - loss: 0.6247 - accuracy: 0.7225\n",
      "Epoch 7/10\n",
      "52/52 - 7s - loss: 0.5419 - accuracy: 0.7787\n",
      "Epoch 8/10\n",
      "52/52 - 5s - loss: 0.4224 - accuracy: 0.8533\n",
      "Epoch 9/10\n",
      "52/52 - 5s - loss: 0.3031 - accuracy: 0.8985\n",
      "Epoch 10/10\n",
      "52/52 - 6s - loss: 0.2475 - accuracy: 0.9267\n",
      "\u001b[32m-------------------  The model was trained. ------------------- \n"
     ]
    }
   ],
   "source": [
    "# now we have to train the model \n",
    "model.fit(train_padded, y_train, epochs=10,batch_size=16,  verbose=2)\n",
    "print(f\"{Fore.GREEN}-------------------  The model was trained. ------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model :  62.93\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Now we test the model and we print the metrics data\n",
    "\"\"\"\n",
    "\n",
    "predictions = model.predict(test_padded)\n",
    "y_pred = (predictions > 0.5)\n",
    "print('Accuracy of the model : ', \"%.2f\" % (accuracy_score(y_pred, y_test)*100))\n",
    "# print(\"F1-score:  : \", \"%.2f\" %  (f1_score(y_pred, y_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m------------------- The simulation messages were successfully recorded.. ------------------- \n"
     ]
    }
   ],
   "source": [
    "#Simulate the model with unknow values\n",
    "\n",
    "\n",
    "# you cn write your own sentences on e and f nd check the result\n",
    "a = [\"a vaccine no i am not interested.\"]\n",
    "b = [\"There are times when I wonder why it is free. Anything that is free is dangerous. So i will never get it.\"]\n",
    "c = [\"I really don't know. I let time tell me.\"]\n",
    "d = [\" I don't think there's much difference with or without the vaccine, so I don't know what to do.\"]\n",
    "e = [\"I have my two doses and I am still alive. I am waiting for the others to find my freedom.\"]\n",
    "f = [\"Vaccination is very important. Also the vaccination against covid19.\"]\n",
    "\n",
    "print(f\"{Fore.GREEN}------------------- The simulation messages were successfully recorded.. ------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m------------------- The simulation messages cleaning operation is complete.. ------------------- \n"
     ]
    }
   ],
   "source": [
    "# clean the values\n",
    "clean_textA = clean_tweets(a)\n",
    "clean_textB = clean_tweets(b)\n",
    "clean_textC = clean_tweets(c)\n",
    "clean_textD = clean_tweets(d)\n",
    "clean_textE = clean_tweets(e)\n",
    "clean_textF = clean_tweets(f)\n",
    "\n",
    "print(f\"{Fore.GREEN}------------------- The simulation messages cleaning operation is complete.. ------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m 1.sentence. ===>  ['a vaccine no i am not interested.']\n",
      "\u001b[34m 1.sentence. ===>  [[  9   4  33   3  25   7 310   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0]]\n",
      "\u001b[32m 2.sentence. ===>  ['There are times when I wonder why it is free. Anything that is free is dangerous. So i will never get it.']\n",
      "\u001b[32m 2.sentence. ===>  [[ 54  16 944  71   3 312  67  10   6 108 423  17   6 108   6 778  26   3\n",
      "   20 102  21  10   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0]]\n",
      "\u001b[31m 3.sentence. ===>  [\"I really don't know. I let time tell me.\"]\n",
      "\u001b[31m 3.sentence. ===>  [[  3 117 754  84   3  98 100 445  44   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0]]\n",
      "\u001b[30m 4.sentence. ===>  [\" I don't think there's much difference with or without the vaccine, so I don't know what to do.\"]\n",
      "\u001b[30m 4.sentence. ===>  [[  3 754  64 664 136 406  32  40  94   1   4  26   3 754  84  89   2  23\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0]]\n",
      "\u001b[35m 5.sentence. ===>  ['I have my two doses and I am still alive. I am waiting for the others to find my freedom.']\n",
      "\u001b[35m 5.sentence. ===>  [[   3   24   22  123   80    8    3   25  105 1005    3   25  374   13\n",
      "     1  209    2  194   22  634    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0]]\n",
      "\u001b[34m 6.sentence. ===>  ['Vaccination is very important. Also the vaccination against covid19.']\n",
      "\u001b[34m 6.sentence. ===>  [[ 38   6  81 168 119   1  38  62 212   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "We will try to transform each expression in the tokenizer to the length format defined above.\n",
    "This allows us to have expressions of the same length.\n",
    "\"\"\"\n",
    "simulate_sentence_A = tokenizer.texts_to_sequences(clean_textA)\n",
    "simulate_sentence_B = tokenizer.texts_to_sequences(clean_textB)\n",
    "simulate_sentence_C = tokenizer.texts_to_sequences(clean_textC)\n",
    "simulate_sentence_D = tokenizer.texts_to_sequences(clean_textD)\n",
    "simulate_sentence_E = tokenizer.texts_to_sequences(clean_textE)\n",
    "simulate_sentence_F = tokenizer.texts_to_sequences(clean_textF)\n",
    "\n",
    "\n",
    "test_padded1 = pad_sequences(simulate_sentence_A, maxlen=max_length, padding='post', truncating='post')\n",
    "test_padded2 = pad_sequences(simulate_sentence_B, maxlen=max_length, padding='post', truncating='post')\n",
    "test_padded3 = pad_sequences(simulate_sentence_C, maxlen=max_length, padding='post', truncating='post')\n",
    "test_padded4 = pad_sequences(simulate_sentence_D, maxlen=max_length, padding='post', truncating='post')\n",
    "test_padded5 = pad_sequences(simulate_sentence_E, maxlen=max_length, padding='post', truncating='post')\n",
    "test_padded6 = pad_sequences(simulate_sentence_F, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "\n",
    "print(f\"{Fore.BLUE} 1.sentence. ===> \",a)\n",
    "print(f\"{Fore.BLUE} 1.sentence. ===> \",test_padded1)\n",
    "\n",
    "print(f\"{Fore.GREEN} 2.sentence. ===> \",b)\n",
    "print(f\"{Fore.GREEN} 2.sentence. ===> \",test_padded2)\n",
    "\n",
    "print(f\"{Fore.RED} 3.sentence. ===> \",c)\n",
    "print(f\"{Fore.RED} 3.sentence. ===> \",test_padded3)\n",
    "\n",
    "print(f\"{Fore.BLACK} 4.sentence. ===> \",d)\n",
    "print(f\"{Fore.BLACK} 4.sentence. ===> \",test_padded4)\n",
    "\n",
    "print(f\"{Fore.MAGENTA} 5.sentence. ===> \",e)\n",
    "print(f\"{Fore.MAGENTA} 5.sentence. ===> \",test_padded5)\n",
    "\n",
    "print(f\"{Fore.BLUE} 6.sentence. ===> \",f)\n",
    "print(f\"{Fore.BLUE} 6.sentence. ===> \",test_padded6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m------------------- Legend. ------------------- \n",
      "\u001b[31m negative ==> [1 0 0]\n",
      "\u001b[31m Neutral  ==> [0 1 0]\n",
      "\u001b[31m positive ==> [0 0 1]\n",
      "\u001b[32m#####################################################################################################\n",
      "\u001b[30m 1 --> display:  [[1. 0. 0.]]  instead of Negative [1 0 0]\n",
      "\u001b[30m 2 --> display:  [[0. 1. 0.]]  instead of Negative [1 0 0]\n",
      "\u001b[30m 3 --> display:  [[0. 1. 0.]]  instead of Neutral  [0 1 0]\n",
      "\u001b[30m 4 --> display:  [[0. 1. 0.]]  instead of Neutral  [0 1 0]\n",
      "\u001b[30m 5 --> display:  [[0. 0. 1.]]  instead of Positive [0 0 1]\n",
      "\u001b[30m 6 --> display:  [[0. 0. 1.]]  instead of Positive [0 0 1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pred1 = model.predict(test_padded1)\n",
    "pred2 = model.predict(test_padded2)\n",
    "pred3 = model.predict(test_padded3)\n",
    "pred4 = model.predict(test_padded4)\n",
    "pred5 = model.predict(test_padded5)\n",
    "pred6 = model.predict(test_padded6)\n",
    "\n",
    "print(f\"{Fore.BLUE}------------------- Legend. ------------------- \")\n",
    "print(f\"{Fore.RED} negative ==> [1 0 0]\")\n",
    "print(f\"{Fore.RED} Neutral  ==> [0 1 0]\")\n",
    "print(f\"{Fore.RED} positive ==> [0 0 1]\")\n",
    "\n",
    "print(f\"{Fore.GREEN}#####################################################################################################\")\n",
    "\n",
    "print(f\"{Fore.BLACK} 1 --> display: \", np.around(pred1, decimals=0),\" instead of Negative [1 0 0]\")\n",
    "print(f\"{Fore.BLACK} 2 --> display: \", np.around(pred2, decimals=0),\" instead of Negative [1 0 0]\")\n",
    "print(f\"{Fore.BLACK} 3 --> display: \", np.around(pred3, decimals=0),\" instead of Neutral  [0 1 0]\")\n",
    "print(f\"{Fore.BLACK} 4 --> display: \", np.around(pred4, decimals=0),\" instead of Neutral  [0 1 0]\")\n",
    "print(f\"{Fore.BLACK} 5 --> display: \", np.around(pred5, decimals=0),\" instead of Positive [0 0 1]\")\n",
    "print(f\"{Fore.BLACK} 6 --> display: \", np.around(pred6, decimals=0),\" instead of Positive [0 0 1]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m------------------- The firsst NN prototype is completed. ------------------- \n"
     ]
    }
   ],
   "source": [
    "print(f\"{Fore.GREEN}------------------- The firsst NN prototype is completed. ------------------- \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
