{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bachelorarbait-2021\n",
    "# Author: Michel Bosris Djifack\n",
    "# Matrikelnummer:7103963"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A sentiment analysis program will be designed to make predictions about the english written expressions to rank them and \n",
    "# determine which ones are in favor of the coronavirus vaccine and which are against.\n",
    "# Method: NN (Neural Network)\n",
    "\n",
    "# ===> Two classes (Binary) with NN\n",
    "\n",
    "# NN-Prototype-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m------------------- All libraries have been successfully imported.------------------- \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "import all libraries (Math-function, diagram-visualisation, regex, document and NLP functions)\n",
    "\n",
    "\"\"\"\n",
    "# NLP Libraries\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, LSTM, Embedding, Dropout, Activation, BatchNormalization\n",
    "from keras import optimizers\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "\n",
    "# Math, documents and visualisation Libraries\n",
    "import numpy as np\n",
    "import preprocessor as p\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import colorama\n",
    "from colorama import Fore\n",
    "\n",
    "print(f\"{Fore.MAGENTA}------------------- All libraries have been successfully imported.------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m------------------- The document has been successfully uploaded. ------------------- \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "upload The dataset, open it and check it.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# upload the DataSet\n",
    "file = open('covidVaccineAdvice_mldata_d2.csv',encoding=\"utf-8\")\n",
    "data = pd.read_csv(file,delimiter=\";\")\n",
    "print(f\"{Fore.MAGENTA}------------------- The document has been successfully uploaded. ------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m -------------------  overview of the dataset ------------------- \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>We need to be vaccinated to protect all person...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>it is a pleasure to see how the govement are w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>I do not know what to think about vaccines as ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>The most popular vaccine that i know is Modern...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            message  sentiment\n",
       "0   1  We need to be vaccinated to protect all person...          1\n",
       "1   3                                          Negative           0\n",
       "2   2  it is a pleasure to see how the govement are w...          1\n",
       "3   6  I do not know what to think about vaccines as ...          0\n",
       "4   4  The most popular vaccine that i know is Modern...          1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the document header.\n",
    "print(f\"{Fore.MAGENTA} -------------------  overview of the dataset ------------------- \")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m -------------------  The document has 1022 rows and 3 columns ------------------- \n"
     ]
    }
   ],
   "source": [
    "#count the data set\n",
    "print(f\"{Fore.MAGENTA} -------------------  The document has\", data.shape[0], \"rows and\", data.shape[1],\"columns ------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m------------------- the number and percentage of missing values in the data set. ------------------- \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>message</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count  Percentage\n",
       "id             0         0.0\n",
       "message        0         0.0\n",
       "sentiment      0         0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check missing values\n",
    "count =data.isnull().sum().sort_values(ascending=False)\n",
    "percentage =((data.isnull().sum()/len(data)*100)).sort_values(ascending=False)\n",
    "missing_data =pd.concat([count,percentage],axis=1,keys=['count','Percentage'])\n",
    "\n",
    "print(f\"{Fore.MAGENTA}------------------- the number and percentage of missing values in the data set. ------------------- \")\n",
    "missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#check the Distributin of Sentiments\n",
    "category = ['Negative','Positive']\n",
    "values = [data.sentiment.astype(str).str.count(str(0)).sum(),data.sentiment.astype(str).str.count(str(1)).sum()]\n",
    "plt.pie(values, labels= category,autopct ='%0.2f%%')\n",
    "plt.title('------------------- percentage Distribution by Sentiment Category -------------------',fontsize=20,color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m------------------- Special characters and punctuation cleaning operations completed. ------------------- \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "We will now clean the data by removing the special characters.\n",
    "\n",
    "\"\"\"\n",
    "#set up punctuations we want to be replaced\n",
    "REPLACE_NO_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\')|(\\?)|(\\,)|(\\\")|(\\|)|(\\()|(\\))|(\\[)|(\\])|(\\%)|(\\$)|(\\>)|(\\<)|(\\{)|(\\})|(\\=)|(\\#)|(\\§)\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s/><br\\s/?)|(-)|(/)|(:).\")\n",
    "print(f\"{Fore.BLUE}------------------- Special characters and punctuation cleaning operations completed. ------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m------------------- preparation of the cleaning functions completed. ------------------- \n"
     ]
    }
   ],
   "source": [
    "# custum function to clean the dataset (combining tweet_preprocessor and reguar expression)\n",
    "def clean_tweets(df):\n",
    "  tempArr = []\n",
    "  for line in df:\n",
    "    # send to tweet_processor\n",
    "    tmpL = p.clean(line)\n",
    "    # remove puctuation\n",
    "    tmpL = REPLACE_NO_SPACE.sub(\"\", tmpL.lower()) # convert all tweets to lower cases\n",
    "    tmpL = REPLACE_WITH_SPACE.sub(\" \", tmpL)\n",
    "    tempArr.append(tmpL)\n",
    "  return tempArr\n",
    "\n",
    "print(f\"{Fore.BLUE}------------------- preparation of the cleaning functions completed. ------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m------------------- The message cleaning operation is complete. ------------------- \n"
     ]
    }
   ],
   "source": [
    "# Cleaning up tweets\n",
    "clean_tweet = clean_tweets(data[\"message\"])\n",
    "print(f\"{Fore.BLUE}------------------- The message cleaning operation is complete. ------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m------------------- The clean data column has been successfully added to the dataset. ------------------- \n"
     ]
    }
   ],
   "source": [
    "# append cleaned tweets to the training data\n",
    "clean_tweet = pd.DataFrame(clean_tweet)\n",
    "data[\"clean\"] = clean_tweet\n",
    "print(f\"{Fore.BLUE}------------------- The clean data column has been successfully added to the dataset. ------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m------------------- overview of the dataset with the clean_data column. ------------------- \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>We need to be vaccinated to protect all person...</td>\n",
       "      <td>1</td>\n",
       "      <td>we need to be vaccinated to protect all person...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>it is a pleasure to see how the govement are w...</td>\n",
       "      <td>1</td>\n",
       "      <td>it is a pleasure to see how the govement are w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>I do not know what to think about vaccines as ...</td>\n",
       "      <td>0</td>\n",
       "      <td>i do not know what to think about vaccines as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>The most popular vaccine that i know is Modern...</td>\n",
       "      <td>1</td>\n",
       "      <td>the most popular vaccine that i know is modern...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            message  sentiment  \\\n",
       "0   1  We need to be vaccinated to protect all person...          1   \n",
       "1   3                                          Negative           0   \n",
       "2   2  it is a pleasure to see how the govement are w...          1   \n",
       "3   6  I do not know what to think about vaccines as ...          0   \n",
       "4   4  The most popular vaccine that i know is Modern...          1   \n",
       "\n",
       "                                               clean  \n",
       "0  we need to be vaccinated to protect all person...  \n",
       "1                                           negative  \n",
       "2  it is a pleasure to see how the govement are w...  \n",
       "3  i do not know what to think about vaccines as ...  \n",
       "4  the most popular vaccine that i know is modern...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare the cleaned and uncleaned tweets\n",
    "print(f\"{Fore.BLUE}------------------- overview of the dataset with the clean_data column. ------------------- \")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function who help to count unique words\n",
    "\n",
    "def wordCount(text):\n",
    "    count = Counter()\n",
    "    for i in text.values:\n",
    "        for word in i.split():\n",
    "            count[word]+=1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m------------------- The column 'clean' contains:  2570  unique words ------------------- \n"
     ]
    }
   ],
   "source": [
    "# count the number of unique words contained in the set of cleaned expressions. \n",
    "text= data.clean\n",
    "counter = wordCount(text)\n",
    "print(f\"{Fore.BLUE}------------------- The column 'clean' contains: \",len(counter),\" unique words ------------------- \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m------------------- Operations completed. ------------------- \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "We will now define the maximum length of a sentence in terms of the number of words it can contain.\n",
    "But first, we define the word count as the number of unique words.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# define the number of words.\n",
    "num_words = len(counter)\n",
    "# maximum number of words in a sentence.\n",
    "max_length = 42\n",
    "\n",
    "print(f\"{Fore.GREEN}------------------- Operations completed. ------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m------------------- The data was successfully split. ------------------- \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "In this section, we will divide the file (the 'clean' column) \n",
    "into two parts: one part for training and one part for testing.\n",
    "\n",
    "X_train ==> train_sentences\n",
    "X_test ==> test_sentences\n",
    "y_train ==> train_labels\n",
    "y_test ==> test_labels\n",
    "\n",
    "\"\"\"\n",
    "# train size 80% of the dataset\n",
    "train_size= int(data.shape[0]*0.8)\n",
    "\n",
    "# x_train ==> train_sentence\n",
    "X_train = data.clean[:train_size]\n",
    "y_train = data.sentiment[:train_size]\n",
    "\n",
    "X_test = data.clean[:train_size]\n",
    "y_test = data.sentiment[:train_size]\n",
    "\n",
    "print(f\"{Fore.GREEN}------------------- The data was successfully split. ------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m------------------- tokenization process complete. ------------------- \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "We will now tokenize the text ('clean' column):\n",
    "This means that a unique number is associated with each unique word in the text.\n",
    "\"\"\"\n",
    "\n",
    "tokenizer = Tokenizer(num_words=num_words, split=\" \")\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "print(f\"{Fore.GREEN}------------------- tokenization process complete. ------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m------------------- visualization of the result obtained after tokenization. ------------------- \n",
      "\u001b[30m {'the': 1, 'to': 2, 'i': 3, 'vaccine': 4, 'not': 5, 'is': 6, 'of': 7, 'and': 8, 'a': 9, 'it': 10, 'vaccinated': 11, 'in': 12, 'vaccines': 13, 'for': 14, 'are': 15, 'be': 16, 'this': 17, 'that': 18, 'do': 19, 'get': 20, 'will': 21, 'covid': 22, 'have': 23, 'am': 24, 'we': 25, 'my': 26, 'so': 27, 'you': 28, 'all': 29, 'with': 30, 'as': 31, 'no': 32, 'but': 33, 'people': 34, 'us': 35, 'they': 36, 'if': 37, 'effects': 38, 'on': 39, 'or': 40, 'who': 41, 'can': 42, 'want': 43, 'side': 44, 'at': 45, 'vaccination': 46, 'take': 47, 'me': 48, '19': 49, 'about': 50, 'think': 51, 'there': 52, 'good': 53, 'these': 54, 'was': 55, 'more': 56, 'because': 57, 'first': 58, 'been': 59, 'against': 60, 'has': 61, 'should': 62, 'virus': 63, 'our': 64, 'when': 65, 'what': 66, 'by': 67, 'their': 68, 'does': 69, 'pfizer': 70, 'one': 71, 'why': 72, 'doses': 73, 'know': 74, 'lives': 75, 'let': 76, 'everyone': 77, 'like': 78, 'any': 79, 'your': 80, 'getting': 81, 'from': 82, 'just': 83, 'go': 84, 'very': 85, 'after': 86, 'going': 87, 'would': 88, 'make': 89, 'without': 90, 'those': 91, 'many': 92, 'only': 93, 'time': 94, 'still': 95, 'than': 96, 'how': 97, 'even': 98, 'never': 99, 'them': 100, 'an': 101, 'need': 102, 'coronavirus': 103, 'disease': 104, 'now': 105, 'other': 106, 'two': 107, 'thing': 108, 'stop': 109, 'life': 110, 'some': 111, 'health': 112, 'save': 113, 'vaccinate': 114, 'free': 115, 'being': 116, 'world': 117, 'were': 118, 'see': 119, 'years': 120, 'really': 121, 'dose': 122, 'well': 123, 'enough': 124, 'companies': 125, 'wait': 126, 'trust': 127, 'which': 128, 'had': 129, 'also': 130, 'today': 131, 'up': 132, 'much': 133, 'out': 134, 'sure': 135, 'corona': 136, 'believe': 137, 'way': 138, 'case': 139, 'prices': 140, 'did': 141, 'nothing': 142, 'long': 143, 'children': 144, 'risk': 145, 'say': 146, 'pandemic': 147, 'money': 148, 'effective': 149, 'protect': 150, 'most': 151, 'better': 152, 'live': 153, 'bad': 154, 'yes': 155, 'choice': 156, 'received': 157, 'safe': 158, 'important': 159, 'far': 160, 'before': 161, 'its': 162, 'too': 163, 'afraid': 164, 'since': 165, 'big': 166, 'same': 167, 'maybe': 168, 'point': 169, 'prevent': 170, 'consequences': 171, 'find': 172, 'please': 173, 'year': 174, 'must': 175, 'whether': 176, 'news': 177, 'less': 178, 'end': 179, 'possible': 180, 'yet': 181, 'again': 182, 'problem': 183, 'moderna': 184, 'others': 185, 'pharmaceutical': 186, 'made': 187, 'best': 188, 'normal': 189, 'then': 190, 'soon': 191, 'day': 192, 'term': 193, 'anyone': 194, 'real': 195, 'thanks': 196, 'injection': 197, 'useful': 198, 'taking': 199, 'covid19': 200, 'ones': 201, 'got': 202, 'die': 203, 'astrazeneca': 204, 'serious': 205, 'order': 206, 'use': 207, 'propaganda': 208, 'laboratories': 209, 'taken': 210, 'caign': 211, 'immunity': 212, 'thank': 213, 'allergic': 214, 'help': 215, 'cure': 216, 'biontech': 217, 'future': 218, 'solution': 219, 'business': 220, 'said': 221, 'necessary': 222, 'finally': 223, 'personally': 224, 'makes': 225, 'given': 226, 'family': 227, 'new': 228, 'tests': 229, 'vaccinations': 230, 'effectiveness': 231, 'days': 232, 'back': 233, 'young': 234, 'person': 235, 'negative': 236, 'course': 237, 'country': 238, 'myself': 239, 'encourage': 240, 'testing': 241, 'human': 242, 'decision': 243, 'injected': 244, 'great': 245, 'yourself': 246, 'quickly': 247, 'drug': 248, 'alone': 249, 'able': 250, 'five': 251, 'hope': 252, 'his': 253, 'mind': 254, 'question': 255, 'decide': 256, 'fed': 257, 'last': 258, 'developed': 259, 'population': 260, 'own': 261, 'here': 262, 'few': 263, 'anti': 264, 'receive': 265, 'care': 266, 'cases': 267, 'second': 268, 'old': 269, 'safety': 270, 'severe': 271, 'working': 272, 'work': 273, 'already': 274, 'done': 275, 'test': 276, 'continue': 277, 'option': 278, 'could': 279, 'media': 280, 'come': 281, 'always': 282, 'science': 283, 'g': 284, 'africa': 285, 'respect': 286, 'supermarket': 287, 'food': 288, 'public': 289, 'frankly': 290, 'fear': 291, 'government': 292, 'give': 293, 'scientists': 294, 'keep': 295, 'information': 296, 'variant': 297, 'rather': 298, 'set': 299, 'shows': 300, 'happy': 301, 'danger': 302, 'remain': 303, 'authorities': 304, 'might': 305, 'almost': 306, 'deaths': 307, 'such': 308, 'reaction': 309, 'around': 310, 'shot': 311, 'certainly': 312, 'vaccin': 313, 'risks': 314, 'matter': 315, 'excited': 316, 'positive': 317, 'difference': 318, 'situation': 319, 'research': 320, 'wonder': 321, 'prefer': 322, 'favour': 323, 'least': 324, 'until': 325, 'seen': 326, 'feel': 327, 'ourselves': 328, 'follow': 329, 'exle': 330, 'million': 331, 'lot': 332, 'reduce': 333, 'cannot': 334, 'system': 335, 'avoid': 336, 'form': 337, 'share': 338, 'every': 339, 'ready': 340, 'clear': 341, 'stock': 342, 'kind': 343, 'drugs': 344, 'put': 345, 'right': 346, 'through': 347, 'travel': 348, 'consumer': 349, 'countries': 350, 'develop': 351, 'pharma': 352, 'while': 353, 'force': 354, 'turn': 355, 'spread': 356, 'into': 357, 'anything': 358, 'barrier': 359, 'refuse': 360, 'leave': 361, 'adverse': 362, 'interested': 363, 'infected': 364, 'months': 365, 'between': 366, 'fact': 367, 'rid': 368, 'hospitals': 369, 'emergency': 370, 'later': 371, 'arrived': 372, 'idea': 373, 'difficult': 374, 'everything': 375, 'look': 376, 'dying': 377, 'stand': 378, 'variants': 379, 'he': 380, 'story': 381, 'opinion': 382, 'works': 383, 'social': 384, 'reason': 385, 'humanity': 386, 'view': 387, 'lose': 388, 'available': 389, 'loved': 390, 'natural': 391, 'yesterday': 392, 'true': 393, 'effect': 394, 'using': 395, 'control': 396, 'except': 397, 'known': 398, 'contamination': 399, 'advise': 400, 'allow': 401, 'immune': 402, 'developing': 403, 'doctors': 404, 'offering': 405, 'panic': 406, 'wants': 407, 'stay': 408, 'another': 409, 'means': 410, 'trials': 411, 'medical': 412, 'crisis': 413, 'hesitate': 414, 'access': 415, 'kiss': 416, 'nobody': 417, 'reliable': 418, 'self': 419, 'administered': 420, 'thats': 421, 'company': 422, 'price': 423, 'cost': 424, 'imagine': 425, 'happens': 426, 'next': 427, 'pseudo': 428, 'create': 429, 'tested': 430, 'approved': 431, 'fake': 432, 'needs': 433, 'doing': 434, 'millions': 435, 'off': 436, 'politicians': 437, 'treatment': 438, 'global': 439, 'etc': 440, 'tell': 441, 'found': 442, 'johnson': 443, 'him': 444, 'data': 445, 'taxpayers': 446, 't': 447, 'longer': 448, 'gestures': 449, 'took': 450, 'explain': 451, 'contagious': 452, 'both': 453, 'called': 454, 'over': 455, 'making': 456, 'waiting': 457, 'passport': 458, 'wouldnt': 459, 'reactions': 460, 'otherwise': 461, 'lie': 462, 'freedom': 463, 'afterwards': 464, 'doubt': 465, 'beginning': 466, 'told': 467, 'gives': 468, 'themselves': 469, 'ahead': 470, 'ive': 471, 'seems': 472, 'each': 473, 'shame': 474, 'together': 475, 'gates': 476, 'including': 477, 'impossible': 478, 'present': 479, 'confinement': 480, 'guinea': 481, 'wear': 482, 'conspiracy': 483, 'mean': 484, 'anyway': 485, 'cause': 486, 'third': 487, 'trump': 488, 'administration': 489, 'healthcare': 490, 'approves': 491, 'forms': 492, 'saves': 493, 'harmful': 494, 'stable': 495, 'naturally': 496, 'iwill': 497, 'opportunity': 498, 'helps': 499, 'contribute': 500, 'suspicious': 501, 'preserve': 502, 'whole': 503, 'scientific': 504, 'community': 505, 'fighting': 506, 'large': 507, 'moreover': 508, 'frightening': 509, 'production': 510, 'fight': 511, 'damn': 512, 'patients': 513, 'possibility': 514, 'hospital': 515, 'hear': 516, 'hesitation': 517, 'wary': 518, 'change': 519, 'month': 520, 'word': 521, 'technology': 522, 'talk': 523, 'pharmacists': 524, 'hours': 525, 'during': 526, 'show': 527, 'raise': 528, 'private': 529, 'profit': 530, 'goes': 531, 'bullshit': 532, 'mother': 533, 'potential': 534, 'produce': 535, 'kits': 536, 'times': 537, 'saved': 538, 'where': 539, 'grocery': 540, 'employees': 541, 'stores': 542, 'supply': 543, 'scammers': 544, 'week': 545, 'hand': 546, 'sanitizer': 547, 'honestly': 548, 'latest': 549, 'weeks': 550, 'gov': 551, 'ever': 552, 'rights': 553, 'russian': 554, 'measures': 555, 'race': 556, 'west': 557, 'coming': 558, 'likely': 559, 'capitalism': 560, 'democrats': 561, 'scams': 562, 'down': 563, 'false': 564, 'simply': 565, 'according': 566, 'remember': 567, 'fda': 568, 'products': 569, 'essential': 570, 'comes': 571, 'little': 572, 'allowed': 573, 'experts': 574, 'protection': 575, 'mask': 576, 'quality': 577, 'especially': 578, 'wont': 579, 'china': 580, 'market': 581, 'concern': 582, 'angry': 583, 'majority': 584, 'something': 585, 'home': 586, 'older': 587, 'wish': 588, 'inject': 589, 'governments': 590, 'sheep': 591, 'sick': 592, 'bosses': 593, 'dont': 594, 'despite': 595, 'strong': 596, 'body': 597, 'rest': 598, 'compulsory': 599, 'choose': 600, 'listen': 601, 'changed': 602, 'participate': 603, 'injections': 604, 'tired': 605, 'assure': 606, 'three': 607, 'number': 608, 'death': 609, 'friends': 610, 'state': 611, 'zero': 612, 'problems': 613, 'quite': 614, 'pessimistic': 615, 'suffer': 616, 'return': 617, 'commercial': 618, 'rate': 619, 'ridiculous': 620, 'bill': 621, 'advised': 622, 'questions': 623, 'room': 624, 'rush': 625, 'therefore': 626, 'scary': 627, 'industry': 628, 'diseases': 629, 'vaccinating': 630, 'usa': 631, 'fully': 632, 'someone': 633, 'honest': 634, 'whats': 635, 'unexpected': 636, 'conditions': 637, 'herd': 638, 'useless': 639, 'im': 640, 'past': 641, 'delta': 642, 'type': 643, 'approve': 644, 'authorizes': 645, 'minutes': 646, 'ingredients': 647, 'mrna': 648, 'pleasure': 649, 'popular': 650, 'early': 651, 'gets': 652, 'hearing': 653, 'saving': 654, 'doctor': 655, 'ok': 656, 'understand': 657, 'water': 658, 'awareness': 659, 'scale': 660, 'debate': 661, 'confined': 662, 'fast': 663, 'product': 664, 'credible': 665, 'ways': 666, 'plants': 667, 'certainty': 668, 'protects': 669, 'reliability': 670, 'specialy': 671, 'imperative': 672, 'worries': 673, 'proven': 674, 'mass': 675, 'press': 676, 'region': 677, 'relatives': 678, 'away': 679, 'paul': 680, 'announced': 681, 'woman': 682, 'says': 683, 'low': 684, 'harm': 685, 'invented': 686, 'chinese': 687, 'via': 688, 'damage': 689, 'leading': 690, 'resuscitation': 691, 'member': 692, 'close': 693, 'friend': 694, 'antibodies': 695, 'advice': 696, 'neighbours': 697, 'touch': 698, 'certain': 699, 'part': 700, 'special': 701, 'age': 702, 'knows': 703, 'epidemic': 704, 'start': 705, 'empty': 706, 'tomorrow': 707, 'condition': 708, 'jennifer': 709, 'haller': 710, 'history': 711, 'her': 712, 'may': 713, 'courage': 714, 'stories': 715, 'call': 716, 'needed': 717, 'january': 718, 'june': 719, 'residents': 720, 'hands': 721, 'mouth': 722, 'apparently': 723, 'cancer': 724, 'man': 725, 'gonna': 726, 'confirmed': 727, 'came': 728, 'county': 729, 'area': 730, 'across': 731, 'door': 732, 'claiming': 733, 'nhs': 734, 'purposes': 735, 'medication': 736, 'affordable': 737, 'thermally': 738, 'direct': 739, 'try': 740, 'friday': 741, 'multiple': 742, 'biggest': 743, 'drop': 744, 'russia': 745, 'launch': 746, 'currently': 747, 'illness': 748, 'animals': 749, 'transmitting': 750, 'inflated': 751, 'charge': 752, 'high': 753, 'patents': 754, 'none': 755, 'update': 756, 'humans': 757, 'stocks': 758, 'knew': 759, 'traditional': 760, 'breaking': 761, 'announces': 762, 'shut': 763, 'step': 764, 'common': 765, 'theres': 766, 'experimental': 767, 'she': 768, 'distancing': 769, 'fighter': 770, 'planes': 771, 'missiles': 772, 'weapons': 773, 'americans': 774, 'beware': 775, 'fraudulent': 776, 'treatments': 777, 'development': 778, 'workers': 779, 'happening': 780, 'vaxxers': 781, 'school': 782, 'bar': 783, 'personal': 784, 'strange': 785, 'react': 786, 'peace': 787, 'face': 788, 'top': 789, 'sent': 790, 'dangerous': 791, 'rodents': 792, 'eat': 793, 'support': 794, 'fought': 795, 'stopped': 796, 'warning': 797, 'careful': 798, 'medicines': 799, 'staff': 800, 'wanting': 801, 'sudden': 802, 'bacterial': 803, 'resistant': 804, 'worse': 805, 'trying': 806, 'ppe': 807, 'chain': 808, 'major': 809, 'design': 810, 'incentives': 811, 'ventilators': 812, 'economists': 813, 'navigate': 814, 'notget': 815, 'basic': 816, 'become': 817, 're': 818, 'procurement': 819, 'pay': 820, 'r': 821, 'd': 822, 'manufacturing': 823, 'makers': 824, 'lets': 825, 'investor': 826, 'paywall': 827, 'london': 828, 'linked': 829, 'respected': 830, 'giving': 831, 'responsibility': 832, 'moderne': 833, 'publicity': 834, 'warned': 835, 'african': 836, 'shape': 837, 'putting': 838, 'deplore': 839, 'caused': 840, 'things': 841, 'pity': 842, 'enjoy': 843, 'affect': 844, 'acquired': 845, 'saying': 846, 'confident': 847, 'particular': 848, 'men': 849, 'nonsense': 850, 'fine': 851, 'fragile': 852, 'containment': 853, 'sell': 854, 'guarantee': 855, 'mandatory': 856, 'house': 857, 'isnt': 858, 'destroy': 859, 'aware': 860, 'hesitating': 861, 'though': 862, 'ago': 863, 'unnecessary': 864, 'rna': 865, 'sufficiently': 866, 'law': 867, 'measure': 868, 'barier': 869, 'advance': 870, 'per': 871, 'tells': 872, 'created': 873, 'talking': 874, 'gain': 875, 'speed': 876, 'responsible': 877, 'hostile': 878, 'kills': 879, 'spirit': 880, 'hasnt': 881, 'glad': 882, 'starting': 883, 'prevention': 884, 'seem': 885, 'hurry': 886, 'caught': 887, 'protected': 888, 'once': 889, 'matters': 890, 'billions': 891, 'beat': 892, 'require': 893, 'operation': 894, 'indeed': 895, 'parents': 896, 'costs': 897, 'technological': 898, 'cobbled': 899, 'scam': 900, 'saturated': 901, 'respecting': 902, 'citizen': 903, 'run': 904, 'holiday': 905, 'asked': 906, 'bit': 907, 'hiv': 908, 'adolescents': 909, 'deadly': 910, 'green': 911, 'light': 912, 'hard': 913, 'favor': 914, 'contact': 915, 'adapt': 916, 'economy': 917, 'deeply': 918, 'researchers': 919, 'easier': 920, 'probably': 921, 'short': 922, 'impact': 923, 'arent': 924, 'actually': 925, 'hell': 926, 'everybody': 927, 'program': 928, 'grandmother': 929, 'agree': 930, 'success': 931, 'suffering': 932, 'scare': 933, 'moment': 934, 'convinced': 935, 'evil': 936, 'thinking': 937, 'becoming': 938, 'traumatic': 939, 'pig': 940, 'obligation': 941, 'happened': 942, 'peoples': 943, 'lost': 944, 'remains': 945, 'compared': 946, 'regarding': 947, 'record': 948, 'thousands': 949, 'teenagers': 950, 'masks': 951, 'pure': 952, 'labs': 953, 'judgment': 954, 'nurse': 955, 'prowess': 956, 'assume': 957, 'receiving': 958, 'pigs': 959, 'smallpox': 960, 'shown': 961, 'name': 962, 'suggests': 963, 'predict': 964, 'worst': 965, 'tetanus': 966, 'feeling': 967, 'ass': 968, 'autoimmune': 969, 'controlled': 970, 'increasing': 971, 'gene': 972, 'therapy': 973, 'refused': 974, 'protein': 975, 'chip': 976, 'unvaccinated': 977, 'importance': 978, 'rich': 979, 'inspire': 980, 'confidence': 981, 'listening': 982, 'object': 983, 'prevents': 984, 'hospitalized': 985, 'nice': 986, 'suffered': 987, 'lockdown': 988, 'affraid': 989, 'disadvantages': 990, 'anyways': 991, 'substance': 992, 'hopefully': 993, 'recommended': 994, 'achieve': 995, 'cant': 996, 'authorized': 997, 'wondering': 998, 'programme': 999, 'intend': 1000, 'shipments': 1001, 'proud': 1002, 'privileged': 1003, 'offered': 1004, 'shots': 1005, 'st': 1006, 'pfizers': 1007, 'toxic': 1008, 'distributed': 1009, 'canada': 1010, 'arrive': 1011, 'begins': 1012, 'poisson': 1013, 'easing': 1014, 'concerns': 1015, 'bion': 1016, 'socially': 1017, 'poison': 1018, 'unknown': 1019, 'wiser': 1020, 'worker': 1021, 'suffers': 1022, 'alaskan': 1023, 'govement': 1024, 'different': 1025, 'workso': 1026, 'beneficial': 1027, 'inform': 1028, 'observe': 1029, 'astra': 1030, 'astrazeneka': 1031, 'controversy': 1032, 'nor': 1033, 'merkel': 1034, 'inconvenients': 1035, 'propagation': 1036, 'supporter': 1037, 'greater': 1038, 'vary': 1039, 'pperson': 1040, 'hence': 1041, 'neutrality': 1042, 'sides': 1043, 'tolerated': 1044, 'sickness': 1045, 'itself': 1046, 'kill': 1047, 'corresponds': 1048, 'viruses': 1049, 'joe': 1050, 'biden': 1051, 'notbe': 1052, 'highly': 1053, 'risked': 1054, 'job': 1055, 'firefighters': 1056, 'fill': 1057, 'coffers': 1058, 'earth': 1059, 'dead': 1060, 'liveplease': 1061, 'congratulate': 1062, 'vloggers': 1063, 'promotion': 1064, 'promote': 1065, 'efficient': 1066, 'pretty': 1067, 'unfortunate': 1068, 'normally': 1069, 'study': 1070, 'spends': 1071, 'remedy': 1072, 'accepted': 1073, 'auditioned': 1074, 'visible': 1075, 'artemesia': 1076, 'officialized': 1077, 'organizations': 1078, 'interest': 1079, 'neglected': 1080, 'takes': 1081, 'desease': 1082, 'precipitation': 1083, 'l': 1084, 'capable': 1085, 'decimating': 1086, 'act': 1087, 'barely': 1088, 'requires': 1089, 'text': 1090, 'regions': 1091, 'nott': 1092, 'urge': 1093, 'however': 1094, 'willing': 1095, 'value': 1096, 'convince': 1097, 'ability': 1098, 'defend': 1099, 'biya': 1100, 'destined': 1101, 'energy': 1102, 'shop': 1103, 'restaurant': 1104, 'died': 1105, 'manufactured': 1106, 'thag': 1107, 'allergy': 1108, 'statistics': 1109, 'percentage': 1110, 'capitalists': 1111, 'charade': 1112, 'positiv': 1113, 'writing': 1114, 'book': 1115, 'hole': 1116, 'decates': 1117, 'deseases': 1118, 'astrazaneca': 1119, 'level': 1120, 'armed': 1121, 'views': 1122, 'limited': 1123, 'areas': 1124, 'australia': 1125, 'outbreak': 1126, 'woolworths': 1127, 'shopping': 1128, 'elderly': 1129, 'disabled': 1130, 'limits': 1131, 'hide': 1132, 'calm': 1133, 'guaranteed': 1134, 'besides': 1135, 'paranoid': 1136, 'litteraly': 1137, 'causes': 1138, 'shortage': 1139, 'desperately': 1140, 'sign': 1141, 'petition': 1142, 'demanding': 1143, 'reasearch': 1144, 'cheap': 1145, 'taxes': 1146, 'pisses': 1147, 'healthy': 1148, 'became': 1149, 'owe': 1150, 'debt': 1151, 'gratitude': 1152, 'participated': 1153, 'dictatorship': 1154, 'unfortunately': 1155, 'logistics': 1156, 'equipment': 1157, 'ehpad': 1158, 'testify': 1159, 'store': 1160, 'employee': 1161, 'respectfully': 1162, 'request': 1163, 'truck': 1164, 'drivers': 1165, 'managers': 1166, 'asap': 1167, 'continuation': 1168, 'properly': 1169, 'washed': 1170, 'nose': 1171, 'hate': 1172, 'gild': 1173, 'monthly': 1174, 'calling': 1175, 'higher': 1176, 'appears': 1177, 'positioned': 1178, 'releases': 1179, 'surrounding': 1180, 'aka': 1181, 'regionals': 1182, 'sullivan': 1183, 'flocked': 1184, 'purchase': 1185, 'cleaning': 1186, 'supplies': 1187, 'toilet': 1188, 'paper': 1189, 'goods': 1190, 'reports': 1191, 'colleagues': 1192, 'reported': 1193, 'providing': 1194, 'rushed': 1195, 'economic': 1196, 'remind': 1197, 'congressman': 1198, 'voted': 1199, 'allowing': 1200, 'negotiate': 1201, 'lower': 1202, 'pa': 1203, 'urgent': 1204, 'warnings': 1205, 'chaos': 1206, 'hunt': 1207, 'stabilitechs': 1208, 'intended': 1209, 'delivered': 1210, 'disruptive': 1211, 'capsule': 1212, 'efficacious': 1213, 'capsules': 1214, 'inexpensive': 1215, 'posted': 1216, 'heist': 1217, 'looting': 1218, 'half': 1219, 'africas': 1220, 'resources': 1221, 'competition': 1222, 'recipe': 1223, 'tp': 1224, 'hoarding': 1225, 'starts': 1226, 'hopes': 1227, 'watchdog': 1228, 'rospotrebnadzor': 1229, 'exposed': 1230, 'cimas': 1231, 'recommends': 1232, 'begun': 1233, 'prototype': 1234, 'laboratory': 1235, 'siberia': 1236, 'russias': 1237, 'regulator': 1238, 'having': 1239, 'arses': 1240, 'further': 1241, 'incentive': 1242, 'proposing': 1243, 'headlines': 1244, 'interact': 1245, 'expensive': 1246, 'soared': 1247, 'lying': 1248, 'winning': 1249, 'joke': 1250, 'nation': 1251, 'senate': 1252, 'republicans': 1253, 'investors': 1254, 'proliferate': 1255, 'watch': 1256, 'victim': 1257, 'donation': 1258, 'mule': 1259, 'recruitment': 1260, 'tactics': 1261, 'vogue': 1262, 'coronavirusdo': 1263, 'fooled': 1264, 'speaking': 1265, 'task': 1266, 'department': 1267, 'justice': 1268, 'website': 1269, 'listed': 1270, 'various': 1271, 'markets': 1272, 'pushing': 1273, 'finding': 1274, 'cures': 1275, 'push': 1276, 'identified': 1277, 'undoubtably': 1278, 'regulators': 1279, 'corporations': 1280, 'fund': 1281, 'senators': 1282, 'insider': 1283, 'trading': 1284, 'doubles': 1285, 'capitol': 1286, 'hill': 1287, 'folk': 1288, 'becerra': 1289, 'medicine': 1290, 'cdc': 1291, 'corp': 1292, 'rising': 1293, 'pharmaceuticals': 1294, 'doubled': 1295, 'safeguards': 1296, 'jacking': 1297, 'hey': 1298, 'terfs': 1299, 'heard': 1300, 'trans': 1301, 'vax': 1302, 'lick': 1303, 'counters': 1304, 'transit': 1305, 'seats': 1306, 'boose': 1307, 'tough': 1308, 'myth': 1309, 'terf': 1310, 'meet': 1311, 'nuclear': 1312, 'issued': 1313, 'advising': 1314, 'rapidly': 1315, 'facilitate': 1316, 'neonuclear': 1317, 'governors': 1318, 'mayors': 1319, 'shops': 1320, 'concessions': 1321, 'hardware': 1322, 'determining': 1323, 'automatically': 1324, 'enters': 1325, 'bloodstream': 1326, 'wonders': 1327, 'certificate': 1328, 'fly': 1329, 'cruise': 1330, 'subway': 1331, 'concert': 1332, 'calls': 1333, 'emails': 1334, 'visitors': 1335, 'asking': 1336, 'usernames': 1337, 'pasords': 1338, 'links': 1339, 'horrible': 1340, 'marketing': 1341, 'misleading': 1342, 'produces': 1343, 'claim': 1344, 'built': 1345, 'composition': 1346, 'karens': 1347, 'antivaxxers': 1348, 'lining': 1349, 'saw': 1350, 'presentation': 1351, 'jarvits': 1352, 'centre': 1353, 'superb': 1354, 's': 1355, 'pieces': 1356, 'email': 1357, 'unless': 1358, 'looked': 1359, 'nonprofits': 1360, 'medicaid': 1361, 'thankfully': 1362, 'bogus': 1363, 'kit': 1364, 'offer': 1365, 'begin': 1366, 'september': 1367, 'officials': 1368, 'medicare': 1369, 'claims': 1370, 'identity': 1371, 'theft': 1372, 'schemes': 1373, 'senior': 1374, 'packages': 1375, 'ap': 1376, 'british': 1377, 'airways': 1378, 'suspend': 1379, 'encouraging': 1380, 'prediction': 1381, 'overuse': 1382, 'antibacterial': 1383, 'lead': 1384, 'mutations': 1385, 'treated': 1386, 'bacteria': 1387, 'forgot': 1388, 'idiot': 1389, 'hold': 1390, 'accountable': 1391, 'brothers': 1392, 'suspicion': 1393, 'mistrust': 1394, 'withholding': 1395, 'deliveries': 1396, 'producing': 1397, 'banning': 1398, 'exports': 1399, 'theyd': 1400, 'buy': 1401, 'extrapolated': 1402, 'cartels': 1403, 'theywill': 1404, 'payback': 1405, 'names': 1406, 'gloves': 1407, 'volatility': 1408, 'levels': 1409, 'growing': 1410, 'monopolies': 1411, 'unaffordable': 1412, 'vulnerable': 1413, 'amoral': 1414, 'dangerously': 1415, 'stupid': 1416, 'bc': 1417, 'defeat': 1418, 'announce': 1419, 'experiments': 1420, 'professor': 1421, 'eyeing': 1422, 'urges': 1423, 'canadians': 1424, 'decisions': 1425, 'molecules': 1426, 'treat': 1427, 'sham': 1428, 'bosnia': 1429, 'sinovac': 1430, 'confused': 1431, 'contradictory': 1432, 'circulating': 1433, 'four': 1434, 'experience': 1435, 'dread': 1436, 'fail': 1437, 'alive': 1438, 'looking': 1439, 'liquidate': 1440, 'ideal': 1441, 'targets': 1442, 'specialists': 1443, 'bien': 1444, 'contente': 1445, 'davoir': 1446, 'reu': 1447, 'mes': 1448, 'deux': 1449, 'malgr': 1450, 'ces': 1451, 'petits': 1452, 'effets': 1453, 'secondaires': 1454, 'vivement': 1455, 'cet': 1456, 'que': 1457, 'je': 1458, 'puisse': 1459, 'voyager': 1460, 'avec': 1461, 'mon': 1462, 'passeport': 1463, 'sanitaire': 1464, 'youre': 1465, 'difficulty': 1466, 'picking': 1467, 'solved': 1468, 'operator': 1469, 'sfr': 1470, 'recherches': 1471, 'coffin': 1472, 'reassuring': 1473, 'undecided': 1474, 'pressure': 1475, 'slowness': 1476, 'caigns': 1477, 'brussels': 1478, 'bureaucracy': 1479, 'move': 1480, 'mostly': 1481, 'council': 1482, 'communicate': 1483, 'warn': 1484, 'society': 1485, 'stole': 1486, 'orcas': 1487, 'rice': 1488, 'peaceful': 1489, 'mot': 1490, 'holidays': 1491, 'bonus': 1492, 'delighted': 1493, 'heath': 1494, 'small': 1495, 'summer': 1496, 'infection': 1497, 'neutral': 1498, 'shoot': 1499, 'tv': 1500, 'curb': 1501, 'forcing': 1502, 'full': 1503, 'fewer': 1504, 'naysayers': 1505, 'property': 1506, 'consent': 1507, 'listened': 1508, 'gp': 1509, 'morons': 1510, 'slaves': 1511, 'complaining': 1512, 'wearing': 1513, 'piss': 1514, 'suppository': 1515, 'funny': 1516, 'absolutely': 1517, 'contracting': 1518, 'civic': 1519, 'minded': 1520, 'desolation': 1521, 'bottom': 1522, 'billionaires': 1523, 'naivety': 1524, 'ill': 1525, 'benefit': 1526, 'crap': 1527, 'guys': 1528, 'eliminate': 1529, 'desired': 1530, 'pendemia': 1531, 'vehemently': 1532, 'opposed': 1533, 'partly': 1534, 'invite': 1535, 'regain': 1536, 'non': 1537, 'directly': 1538, 'usually': 1539, 'women': 1540, 'started': 1541, 'technique': 1542, 'street': 1543, 'regret': 1544, 'consideration': 1545, 'wife': 1546, 'motivated': 1547, 'disparity': 1548, 'messenger': 1549, 'advanced': 1550, 'provide': 1551, 'outdated': 1552, 'pain': 1553, 'shoulder': 1554, 'sister': 1555, 'sim': 1556, 'trouble': 1557, 'passing': 1558, 'f': 1559, 'affected': 1560, 'childrens': 1561, 'clinical': 1562, 'cameroon': 1563, 'againts': 1564, 'virusbecause': 1565, 'vacination': 1566, 'persones': 1567, 'drasticaly': 1568, 'reduced': 1569, 'revisit': 1570, 'museums': 1571, 'looks': 1572, 'rare': 1573, 'uses': 1574, 'seriously': 1575, 'eventually': 1576, 'god': 1577, 'project': 1578, 'conscience': 1579, 'shitty': 1580, 'notchange': 1581, 'emmanuel': 1582, 'macron': 1583, 'himself': 1584, 'images': 1585, 'broadcast': 1586, 'television': 1587, 'forget': 1588, 'tragic': 1589, 'episode': 1590, 'century': 1591, 'recover': 1592, 'citizens': 1593, 'families': 1594, 'underestimate': 1595, 'busting': 1596, 'balls': 1597, 'guide': 1598, 'needle': 1599, 'inserted': 1600, 'arm': 1601, 'quiet': 1602, 'accept': 1603, 'wrong': 1604, 'opted': 1605, 'hot': 1606, 'havent': 1607, 'excuse': 1608, 'hijacked': 1609, 'pants': 1610, 'vacated': 1611, 'thesis': 1612, 'convincing': 1613, 'contradictions': 1614, 'tourists': 1615, 'bring': 1616, 'usual': 1617, 'road': 1618, 'organisation': 1619, 'agns': 1620, 'buzyn': 1621, 'laugh': 1622, 'loud': 1623, 'ruining': 1624, 'prospect': 1625, 'practically': 1626, 'disappeared': 1627, 'specific': 1628, 'grey': 1629, 'dog': 1630, 'chickens': 1631, 'retrovirus': 1632, 'sinopharm': 1633, 'acceptable': 1634, 'survival': 1635, 'clearly': 1636, 'faster': 1637, 'spy': 1638, 'harmless': 1639, 'comorbidity': 1640, 'supposedly': 1641, 'itwill': 1642, 'notwork': 1643, 'advantage': 1644, 'advances': 1645, 'tiktok': 1646, 'losing': 1647, 'minds': 1648, 'misinformation': 1649, 'believing': 1650, 'optimistic': 1651, 'arose': 1652, 'george': 1653, 'soros': 1654, 'deprogramming': 1655, 'catastrophic': 1656, 'trusts': 1657, 'republic': 1658, 'annihilate': 1659, 'imminent': 1660, 'paranormal': 1661, 'girl': 1662, 'six': 1663, 'wanted': 1664, 'amazed': 1665, 'turnaround': 1666, 'deal': 1667, 'chemo': 1668, 'alzheimers': 1669, 'parkinsons': 1670, 'aids': 1671, 'miracle': 1672, 'altruists': 1673, '21': 1674, 'monthsall': 1675, 'tiring': 1676, 'victimisation': 1677, 'secret': 1678, 'deceiving': 1679, 'innocent': 1680, 'versus': 1681, 'playing': 1682, 'impression': 1683, 'maximum': 1684, 'leads': 1685, 'suppose': 1686, 'documents': 1687, 'id': 1688, 'interesting': 1689, 'capacity': 1690, 'resist': 1691, 'learned': 1692, 'africans': 1693, 'current': 1694, 'attacks': 1695, 'humanitarian': 1696, 'flu': 1697, 'magnitude': 1698, 'action': 1699, 'brake': 1700, 'types': 1701, 'brought': 1702, 'perfection': 1703, 'premiere': 1704, 'period': 1705, 'oh': 1706, 'freer': 1707, 'completely': 1708, 'sad': 1709, 'imagined': 1710, 'menstruation': 1711, 'catching': 1712, 'rotten': 1713, 'used': 1714, 'bribing': 1715, 'win': 1716, 'bothered': 1717, 'scarier': 1718, 'bothering': 1719, 'insist': 1720, 'anyones': 1721, 'previous': 1722, 'pessimist': 1723, 'existence': 1724, 'creation': 1725, 'atrocities': 1726, 'extent': 1727, 'figures': 1728, 'initiative': 1729, 'intrigued': 1730, 'grandchildren': 1731, 'protocol': 1732, 'funerals': 1733, 'lung': 1734, 'guilty': 1735, 'plan': 1736, 'questionable': 1737, 'traumatize': 1738, 'refusing': 1739, 'collective': 1740, 'suicide': 1741, 'cured': 1742, 'behaviour': 1743, 'appearance': 1744, 'management': 1745, 'reinforced': 1746, 'pessimism': 1747, 'oripire': 1748, 'intriguing': 1749, 'outcome': 1750, 'trustworthy': 1751, 'alternatives': 1752, 'grandmas': 1753, 'secrets': 1754, 'vacation': 1755, 'increase': 1756, 'restrictions': 1757, 'decrease': 1758, 'israel': 1759, 'conscious': 1760, 'sanitary': 1761, 'leaders': 1762, 'vacations': 1763, 'arise': 1764, 'malaria': 1765, 'shaken': 1766, 'international': 1767, 'affair': 1768, 'uncertain': 1769, 'grandparents': 1770, 'reasonable': 1771, 'whose': 1772, 'medium': 1773, 'altruism': 1774, 'imposed': 1775, 'fundamental': 1776, 'mine': 1777, 'choices': 1778, 'catch': 1779, 'bug': 1780, 'coma': 1781, 'beliefs': 1782, 'convictions': 1783, 'elsewhere': 1784, 'worlds': 1785, 'pension': 1786, 'starvation': 1787, 'malnutrition': 1788, 'invention': 1789, 'polished': 1790, 'theories': 1791, 'heavily': 1792, 'convicted': 1793, 'fraud': 1794, 'stake': 1795, 'madness': 1796, 'incite': 1797, 'miss': 1798, 'mortality': 1799, 'contract': 1800, 'transmit': 1801, 'impressive': 1802, 'concentrate': 1803, 'credibility': 1804, 'concussion': 1805, 'tend': 1806, 'ignoramuses': 1807, 'charlatans': 1808, 'theorists': 1809, 'mankind': 1810, 'wreaked': 1811, 'havoc': 1812, 'centuries': 1813, 'adults': 1814, 'foreseen': 1815, 'count': 1816, 'experiment': 1817, 'chloroquine': 1818, 'eyes': 1819, 'surprising': 1820, 'crowded': 1821, 'rots': 1822, 'opt': 1823, 'hurt': 1824, 'rusty': 1825, 'piece': 1826, 'iron': 1827, 'financial': 1828, 'scandal': 1829, 'kissed': 1830, 'goodbye': 1831, 'beautiful': 1832, 'distance': 1833, 'expire': 1834, 'incredible': 1835, 'laughing': 1836, 'thought': 1837, 'schools': 1838, 'closed': 1839, 'carriers': 1840, 'aged': 1841, 'pre': 1842, 'existing': 1843, 'include': 1844, 'hypertension': 1845, 'diabetes': 1846, 'asthma': 1847, 'respiratory': 1848, 'liver': 1849, 'kidney': 1850, 'stabilised': 1851, 'chronic': 1852, 'expenditure': 1853, 'dromois': 1854, 'keeping': 1855, 'reserves': 1856, 'mid': 1857, 'july': 1858, 'complete': 1859, 'reassure': 1860, 'harmlessness': 1861, 'whatever': 1862, 'immunizes': 1863, 'polishes': 1864, 'decades': 1865, 'contains': 1866, 'spike': 1867, 'pristine': 1868, 'aspire': 1869, 'fall': 1870, 'flies': 1871, 'complain': 1872, 'saturate': 1873, 'victims': 1874, 'compensated': 1875, 'concerning': 1876, 'numbers': 1877, 'serving': 1878, 'cobaille': 1879, 'sterile': 1880, 'purpose': 1881, 'several': 1882, 'tinkered': 1883, 'marketed': 1884, 'pandemie': 1885, 'atshmatic': 1886, 'mucus': 1887, 'key': 1888, 'conceived': 1889, 'haste': 1890, 'aim': 1891, 'pretend': 1892, 'reputation': 1893, 'premature': 1894, 'single': 1895, 'prejorative': 1896, 'denial': 1897, 'preventive': 1898, 'curative': 1899, 'infancy': 1900, 'skeptics': 1901, 'although': 1902, 'designed': 1903, 'threatened': 1904, 'treats': 1905, 'leaving': 1906, 'extreme': 1907, 'reassured': 1908, 'exists': 1909, 'scenario': 1910, 'ligma': 1911, 'ten': 1912, 'taxpayer': 1913, 'consider': 1914, 'smells': 1915, 'war': 1916, 'concretely': 1917, 'motivates': 1918, 'inventors': 1919, 'politicized': 1920, 'play': 1921, 'anyhow': 1922, 'whitout': 1923, 'ie': 1924, 'knowing': 1925, 'played': 1926, 'role': 1927, 'ceased': 1928, 'passed': 1929, 'military': 1930, 'industrialists': 1931, 'main': 1932, 'objects': 1933, 'march': 1934, 'certified': 1935, 'greatest': 1936, 'contrary': 1937, 'bravery': 1938, 'limit': 1939, 'totally': 1940, 'irresponsible': 1941, 'sometimes': 1942, 'kinda': 1943, 'noway': 1944, 'chipped': 1945, 'europe': 1946, 'okay': 1947, 'sceptical': 1948, 'experiencing': 1949, 'potentially': 1950, 'dunno': 1951, 'necessity': 1952, 'marginal': 1953, 'somewhere': 1954, 'priority': 1955, 'queue': 1956, 'minimal': 1957, 'immense': 1958, 'worried': 1959, 'warm': 1960, 'spreading': 1961, 'often': 1962, 'regularly': 1963, 'office': 1964, 'prioritized': 1965, 'constantly': 1966, 'realy': 1967, 'advantages': 1968, 'outweigh': 1969, 'appointment': 1970, 'shall': 1971, 'secondary': 1972, 'complicated': 1973, 'football': 1974, 'stadium': 1975, 'arms': 1976, 'safest': 1977, 'decided': 1978, 'rd': 1979, 'th': 1980, 'poorly': 1981, 'researched': 1982, 'realise': 1983, 'super': 1984, 'manufacturers': 1985, 'multinational': 1986, 'fuss': 1987, 'heh': 1988, 'purely': 1989, 'write': 1990, 'pays': 1991, 'neutralfor': 1992, 'usedas': 1993, 'influence': 1994, 'lucrative': 1995, 'model': 1996, 'permanent': 1997, 'total': 1998, 'disappear': 1999, 'proposals': 2000, 'syringes': 2001, 'clever': 2002, 'gone': 2003, 'deceived': 2004, 'evening': 2005, 'meanwhile': 2006, 'significant': 2007, 'astraastrazeneka': 2008, 'departure': 2009, 'recalls': 2010, 'supposed': 2011, 'autumn': 2012, 'else': 2013, 'undergo': 2014, 'quarterly': 2015, 'definitely': 2016, 'lasts': 2017, 'forever': 2018, 'fourth': 2019, 'fifth': 2020, 'sixth': 2021, 'seventh': 2022, 'loop': 2023, 'ends': 2024, 'cat': 2025, 'mouse': 2026, 'game': 2027, 'obviously': 2028, 'mockery': 2029, 'tick': 2030, 'remembers': 2031, 'childhood': 2032, 'newly': 2033, 'rages': 2034, 'helped': 2035, 'sydney': 2036, 'conflicting': 2037, 'beings': 2038, 'rushes': 2039, 'alarmed': 2040, 'mainly': 2041, 'massively': 2042, 'anymore': 2043, 'baby': 2044, 'constraints': 2045, 'lack': 2046, 'hindsight': 2047, 'annoyed': 2048, 'proportion': 2049, 'disorders': 2050, 'whereas': 2051, 'hardly': 2052, 'messing': 2053, 'heads': 2054, 'uphow': 2055, 'ride': 2056, 'pfeizer': 2057, 'collect': 2058, 'definition': 2059, 'vocation': 2060, 'mutating': 2061, '4': 2062, 'guidance': 2063, 'whilst': 2064, 'breastfeeding': 2065, 'rollout': 2066, 'united': 2067, 'states': 2068, 'night': 2069, 'failed': 2070, 'deliver': 2071, 'promises': 2072, 'paid': 2073, 'immigrant': 2074, 'muslim': 2075, 'couple': 2076, 'approval': 2077, 'uk': 2078, 'tol': 2079, 'sheet': 2080, 'providers': 2081, 'administering': 2082, 'evidence': 2083, 'poisons': 2084, 'left': 2085, 'flocking': 2086, 'tragedy': 2087, 'corporate': 2088, 'greed': 2089, 'building': 2090, 'trial': 2091, 'extending': 2092, 'effort': 2093, 'organization': 2094, 'import': 2095, 'oregon': 2096, 'concerned': 2097, 'check': 2098, 'recap': 2099, 'professionals': 2100, 'nurses': 2101, 'caregivers': 2102, 'ship': 2103, 'missouris': 2104, 'weekend': 2105, 'seeing': 2106, 'surprised': 2107, 'learn': 2108, 'immunosuppressed': 2109, 'daft': 2110, 'hurts': 2111, 'ears': 2112, 'icu': 2113, 'sandra': 2114, 'lindsay': 2115, 'ontarian': 2116, 'p': 2117, 'surreal': 2118, 'dropping': 2119, 'stepping': 2120, 'toll': 2121, 'above': 2122, 'legacy': 2123, 'registered': 2124, 'itll': 2125, 'proper': 2126, 'bra': 2127, 'receivers': 2128, 'momentous': 2129, 'kids': 2130, 'towards': 2131, 'recently': 2132, 'toronto': 2133, 'ontarios': 2134, 'read': 2135, 'report': 2136, 'california': 2137, 'nightgov': 2138, 'gav': 2139, 'liable': 2140, 'supervising': 2141, 'torn': 2142, 'firstish': 2143, 'encouraged': 2144, 'cold': 2145, 'pucking': 2146, 'wht': 2147, 'employer': 2148, 'warns': 2149, 'iv': 2150, 'transparent': 2151, 'graveling': 2152, 'feet': 2153, 'killed': 2154, 'k': 2155, 'appreciate': 2156, 'everywhere': 2157, 'results': 2158, 'entire': 2159, 'berlin': 2160, 'quebec': 2161, 'maimonides': 2162, 'among': 2163, 'seniors': 2164, 'preferenceany': 2165, 'authorization': 2166, 'developer': 2167, 'handled': 2168, 'worked': 2169, 'notice': 2170, 'picture': 2171, 'video': 2172, 'actual': 2173, 'repeat': 2174, 'mistake': 2175, 'jeopardized': 2176, 'initial': 2177, 'selected': 2178, 'ports': 2179, 'entry': 2180, 'sunday': 2181, 'patient': 2182, 'distanced': 2183, 'patiently': 2184, 'approvals': 2185, 'expects': 2186, 'december': 2187, 'contain': 2188, 'singapore': 2189, 'stick': 2190, 'formally': 2191, 'casts': 2192, 'votes': 2193, 'insisting': 2194, 'efficacy': 2195, 'wors': 2196, 'c': 2197, 'unsafe': 2198, 'phase': 2199, 'dec': 2200, 'iran': 2201, 'helpfully': 2202, 'nursing': 2203, 'homes': 2204, 'pennsylvania': 2205, 'prepare': 2206, 'distribut': 2207, 'ceo': 2208, 'firsti': 2209, 'takeanother': 2210, 'hcw': 2211, 'assuage': 2212, 'anxiety': 2213, 'liberty': 2214, 'models': 2215, 'based': 2216, 'unlike': 2217, 'pregnant': 2218, 'biontechs': 2219, 'urgently': 2220, 'article': 2221, 'batch': 2222, 'yay': 2223, 'congratulations': 2224, 'excellent': 2225, 'president': 2226, 'pushed': 2227, 'expected': 2228, 'officially': 2229, 'complications': 2230, 'o': 2231, 'unbelievably': 2232, 'clearconfirmed': 2233, 'persons': 2234, 'under': 2235, 'maturity': 2236, 'occurred': 2237, 'tuesday': 2238, 'bringing': 2239, 'fresh': 2240, 'air': 2241, 'clue': 2242, 'kuwait': 2243, 'discussing': 2244, 'unbearable': 2245, 'ego': 2246, 'roof': 2247, 'basis': 2248, 'approv': 2249, 'agency': 2250, 'eric': 2251, 'shawn': 2252, 'herein': 2253, 'raised': 2254, 'displays': 2255, 'heightened': 2256, 'propensity': 2257, 'initiate': 2258, 'origin': 2259, 'teach': 2260, 'cells': 2261, 'trigger': 2262, 'response': 2263, 'vi': 2264, 'academic': 2265, 'critical': 2266, 'dosis': 2267, 'memorial': 2268, 'mir': 2269, 'todayimpressive': 2270, 'resource': 2271, 'mobilization': 2272, 'canton': 2273, 'due': 2274, 'jan': 2275, 'pressuring': 2276, 'license': 2277, 'christmas': 2278, 'showed': 2279, 'cool': 2280, 'prepping': 2281, 'shipment': 2282, 'sites': 2283, 'als': 2284, 'oclock': 2285, 'pleased': 2286, 'possi': 2287, 'tiniest': 2288, 'soreness': 2289, 'site': 2290, 'distant': 2291, 'sue': 2292, 'honored': 2293, 'gettin': 2294, 'status': 2295, 'team': 2296, 'slip': 2297, 'animal': 2298, 'anesthesia': 2299, 'surgeries': 2300, 'apart': 2301, 'introduced': 2302, 'b': 2303}\n"
     ]
    }
   ],
   "source": [
    "# visualization of the result obtained after tokenization.\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print(f\"{Fore.GREEN}------------------- visualization of the result obtained after tokenization. ------------------- \")\n",
    "print(f\"{Fore.BLACK}\",word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    " Let's apply the tokenisation operation to each expression in column x. \n",
    "This will allow us to observe that each expression is identifiable by a group of numbers.\n",
    "\"\"\"\n",
    "\n",
    "train_sequences = tokenizer.texts_to_sequences(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we need to be vaccinated to protect all person around us\n",
      "\u001b[34m first sentence. ===>  we need to be vaccinated to protect all person around us\n",
      "\u001b[34m first sentence. ===>  [25, 102, 2, 16, 11, 2, 150, 29, 235, 310, 35]\n",
      "\u001b[32m second sentence.  ===> negative\n",
      "\u001b[34m second sentence. ===>  [236]\n",
      "\u001b[35m third sentence.  ===>  it is a pleasure to see how the govement are working for our help i thing the vaccination is good for all of us\n",
      "\u001b[34m third sentence. ===>  [10, 6, 9, 649, 2, 119, 97, 1, 1024, 15, 272, 14, 64, 215, 3, 108, 1, 46, 6, 53, 14, 29, 7, 35]\n"
     ]
    }
   ],
   "source": [
    "# Let's see what the first three expressions of the document look like after the tokenisation operation.\n",
    "print(data.clean[0])\n",
    "print(f\"{Fore.BLUE} first sentence. ===> \",data.clean[0])\n",
    "print(f\"{Fore.BLUE} first sentence. ===> \",train_sequences[0])\n",
    "\n",
    "print(f\"{Fore.GREEN} second sentence.  ===>\",data.clean[1])\n",
    "print(f\"{Fore.BLUE} second sentence. ===> \",train_sequences[1])\n",
    "\n",
    "print(f\"{Fore.MAGENTA} third sentence.  ===> \",data.clean[2])\n",
    "print(f\"{Fore.BLUE} third sentence. ===> \",train_sequences[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We will try to transform each expression in the tokenizer to the length format defined above.\n",
    "This allows us to have expressions of the same length.\n",
    "\"\"\"\n",
    "\n",
    "train_padded = pad_sequences(train_sequences, maxlen=max_length, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m first sentence. ===>  [ 25 102   2  16  11   2 150  29 235 310  35   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0]\n",
      "\u001b[32m second sentence.  ===> [236   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0]\n",
      "\u001b[35m third sentence.  ===>  [  10    6    9  649    2  119   97    1 1024   15  272   14   64  215\n",
      "    3  108    1   46    6   53   14   29    7   35    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "# Let's see what the first three expressions of the document look like after the operation.\n",
    "\n",
    "print(f\"{Fore.BLUE} first sentence. ===> \",train_padded[0])\n",
    "print(f\"{Fore.GREEN} second sentence.  ===>\",train_padded[1])\n",
    "print(f\"{Fore.MAGENTA} third sentence.  ===> \",train_padded[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we repeat the same operations on the test sentences\n",
    "\n",
    "\"\"\"\n",
    "We will try to transform each expression in the tokenizer to the length format defined above.\n",
    "This allows us to have expressions of the same length.\n",
    "\"\"\"\n",
    "\n",
    "test_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "test_padded = pad_sequences(test_sequences, maxlen=max_length, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m Shape of train. ===>  {(817, 42)}\n",
      "\u001b[34m Shape of train. ===>  {(817, 42)}\n",
      "\u001b[32m This means that 80% of the training data corresponds to 817 sentences of 42 words each. \n"
     ]
    }
   ],
   "source": [
    "# how our training data is dimensioned.\n",
    "print(f\"{Fore.BLUE} Shape of train. ===> \",{train_padded.shape})\n",
    "print(f\"{Fore.BLUE} Shape of train. ===> \",{test_padded.shape})\n",
    "print(f\"{Fore.GREEN} This means that 80% of the training data corresponds to 817 sentences of 42 words each. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 42, 32)            82240     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 90,593\n",
      "Trainable params: 90,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "We will now create a model that will be adapted to binary data. That is, with two labels, positive and negative\n",
    "\n",
    "positive ==> 1\n",
    "Negative ==> 0\n",
    "\"\"\"\n",
    "\n",
    "# create a Model\n",
    "model = Sequential()\n",
    "model.add(Embedding(num_words, 32, input_length=max_length))\n",
    "model.add(LSTM(32, dropout=0.1))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "optimizer = Adam(learning_rate=3e-4)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "26/26 - 31s - loss: 0.6934 - accuracy: 0.5006\n",
      "Epoch 2/20\n",
      "26/26 - 0s - loss: 0.6930 - accuracy: 0.5116\n",
      "Epoch 3/20\n",
      "26/26 - 1s - loss: 0.6929 - accuracy: 0.5177\n",
      "Epoch 4/20\n",
      "26/26 - 1s - loss: 0.6928 - accuracy: 0.5226\n",
      "Epoch 5/20\n",
      "26/26 - 0s - loss: 0.6934 - accuracy: 0.5055\n",
      "Epoch 6/20\n",
      "26/26 - 1s - loss: 0.6922 - accuracy: 0.5410\n",
      "Epoch 7/20\n",
      "26/26 - 1s - loss: 0.6914 - accuracy: 0.5777\n",
      "Epoch 8/20\n",
      "26/26 - 0s - loss: 0.6778 - accuracy: 0.7381\n",
      "Epoch 9/20\n",
      "26/26 - 1s - loss: 0.5285 - accuracy: 0.7797\n",
      "Epoch 10/20\n",
      "26/26 - 1s - loss: 0.4176 - accuracy: 0.8384\n",
      "Epoch 11/20\n",
      "26/26 - 0s - loss: 0.3282 - accuracy: 0.8837\n",
      "Epoch 12/20\n",
      "26/26 - 0s - loss: 0.2602 - accuracy: 0.9168\n",
      "Epoch 13/20\n",
      "26/26 - 1s - loss: 0.2216 - accuracy: 0.9278\n",
      "Epoch 14/20\n",
      "26/26 - 0s - loss: 0.1761 - accuracy: 0.9547\n",
      "Epoch 15/20\n",
      "26/26 - 0s - loss: 0.1465 - accuracy: 0.9621\n",
      "Epoch 16/20\n",
      "26/26 - 1s - loss: 0.1276 - accuracy: 0.9670\n",
      "Epoch 17/20\n",
      "26/26 - 1s - loss: 0.1170 - accuracy: 0.9670\n",
      "Epoch 18/20\n",
      "26/26 - 0s - loss: 0.0983 - accuracy: 0.9755\n",
      "Epoch 19/20\n",
      "26/26 - 0s - loss: 0.0832 - accuracy: 0.9792\n",
      "Epoch 20/20\n",
      "26/26 - 1s - loss: 0.0792 - accuracy: 0.9829\n",
      "\u001b[32m-------------------  The model was trained. ------------------- \n"
     ]
    }
   ],
   "source": [
    "# now we have to train the model \n",
    "model.fit(train_padded, y_train, epochs=20, verbose=2)\n",
    "print(f\"{Fore.GREEN}-------------------  The model was trained. ------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model :  98.78\n",
      "F1-score:  :  98.77\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Now we test the model and we print the metrics data\n",
    "\"\"\"\n",
    "\n",
    "predictions = model.predict(test_padded)\n",
    "y_pred = (predictions > 0.5)\n",
    "print('Accuracy of the model : ', \"%.2f\" % (accuracy_score(y_pred, y_test)*100))\n",
    "print(\"F1-score:  : \", \"%.2f\" %  (f1_score(y_pred, y_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m------------------- The simulation messages were successfully recorded.. ------------------- \n"
     ]
    }
   ],
   "source": [
    "#Simulate the model with unknow values\n",
    "\n",
    "# you cn write your own sentences on e and f nd check the result\n",
    "a = [\"a vaccine no i am not interested.\"]\n",
    "b = [\"There are times when I wonder why it is free. Anything that is free is dangerous. So i will never get it.\"]\n",
    "c = [\"I have my two doses and I am still alive. I am waiting for the others to find my freedom.\"]\n",
    "d = [\"Vaccination is very important. Also the vaccination against covid19.\"]\n",
    "\n",
    "print(f\"{Fore.GREEN}------------------- The simulation messages were successfully recorded.. ------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m------------------- The simulation messages cleaning operation is complete.. ------------------- \n"
     ]
    }
   ],
   "source": [
    "# clean the values\n",
    "clean_textA = clean_tweets(a)\n",
    "clean_textB = clean_tweets(b)\n",
    "clean_textC = clean_tweets(c)\n",
    "clean_textD = clean_tweets(d)\n",
    "\n",
    "\n",
    "print(f\"{Fore.GREEN}------------------- The simulation messages cleaning operation is complete.. ------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m 1.sentence. ===>  ['a vaccine no i am not interested.']\n",
      "\u001b[34m 1.sentence. ===>  [[  9   4  32   3  24   5 363   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0]]\n",
      "\u001b[32m 2.sentence. ===>  ['There are times when I wonder why it is free. Anything that is free is dangerous. So i will never get it.']\n",
      "\u001b[32m 2.sentence. ===>  [[ 52  15 537  65   3 321  72  10   6 115 358  18   6 115   6 791  27   3\n",
      "   21  99  20  10   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0]]\n",
      "\u001b[31m 3.sentence. ===>  ['I have my two doses and I am still alive. I am waiting for the others to find my freedom.']\n",
      "\u001b[31m 3.sentence. ===>  [[   3   23   26  107   73    8    3   24   95 1438    3   24  457   14\n",
      "     1  185    2  172   26  463    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0]]\n",
      "\u001b[30m 4.sentence. ===>  ['Vaccination is very important. Also the vaccination against covid19.']\n",
      "\u001b[30m 4.sentence. ===>  [[ 46   6  85 159 130   1  46  60 200   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "We will try to transform each expression in the tokenizer to the length format defined above.\n",
    "This allows us to have expressions of the same length.\n",
    "\"\"\"\n",
    "simulate_sentence_A = tokenizer.texts_to_sequences(clean_textA)\n",
    "simulate_sentence_B = tokenizer.texts_to_sequences(clean_textB)\n",
    "simulate_sentence_C = tokenizer.texts_to_sequences(clean_textC)\n",
    "simulate_sentence_D = tokenizer.texts_to_sequences(clean_textD)\n",
    "\n",
    "\n",
    "\n",
    "test_padded1 = pad_sequences(simulate_sentence_A, maxlen=max_length, padding='post', truncating='post')\n",
    "test_padded2 = pad_sequences(simulate_sentence_B, maxlen=max_length, padding='post', truncating='post')\n",
    "test_padded3 = pad_sequences(simulate_sentence_C, maxlen=max_length, padding='post', truncating='post')\n",
    "test_padded4 = pad_sequences(simulate_sentence_D, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "\n",
    "\n",
    "print(f\"{Fore.BLUE} 1.sentence. ===> \",a)\n",
    "print(f\"{Fore.BLUE} 1.sentence. ===> \",test_padded1)\n",
    "\n",
    "print(f\"{Fore.GREEN} 2.sentence. ===> \",b)\n",
    "print(f\"{Fore.GREEN} 2.sentence. ===> \",test_padded2)\n",
    "\n",
    "print(f\"{Fore.RED} 3.sentence. ===> \",c)\n",
    "print(f\"{Fore.RED} 3.sentence. ===> \",test_padded3)\n",
    "\n",
    "print(f\"{Fore.BLACK} 4.sentence. ===> \",d)\n",
    "print(f\"{Fore.BLACK} 4.sentence. ===> \",test_padded4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m------------------- Legend. ------------------- \n",
      "\u001b[31m 0  ===> negative.\n",
      "\u001b[31m 1  ===> positive.\n",
      "\u001b[32m#####################################################################################################\n",
      "\u001b[30m0  instead of Negative (0)\n",
      "\u001b[30m0  instead of Negative (0)\n",
      "\u001b[30m1  instead of Positive (1)\n",
      "\u001b[30m1  instead of Positive (1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pred1 = model.predict(test_padded1)\n",
    "pred2 = model.predict(test_padded2)\n",
    "pred3 = model.predict(test_padded3)\n",
    "pred4 = model.predict(test_padded4)\n",
    "\n",
    "\n",
    "print(f\"{Fore.BLUE}------------------- Legend. ------------------- \")\n",
    "print(f\"{Fore.RED} 0  ===> negative.\")\n",
    "print(f\"{Fore.RED} 1  ===> positive.\")\n",
    "print(f\"{Fore.GREEN}#####################################################################################################\")\n",
    "\n",
    "print(f\"{Fore.BLACK}%.f\" % pred1,\" instead of Negative (0)\")\n",
    "print(f\"{Fore.BLACK}%.f\" % pred2,\" instead of Negative (0)\")\n",
    "print(f\"{Fore.BLACK}%.f\" % pred3,\" instead of Positive (1)\")\n",
    "print(f\"{Fore.BLACK}%.f\" % pred4,\" instead of Positive (1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m------------------- The second NN prototype is completed. ------------------- \n"
     ]
    }
   ],
   "source": [
    "print(f\"{Fore.GREEN}------------------- The second NN prototype is completed. ------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
